{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6VIJBiWr574F42oYvz3uJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daisysong76/AI--Machine--learning/blob/main/Advanced_Educational_Content_Generation_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yOvgAhakswaW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEfVG_pwsFHm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    GPT2LMHeadModel,\n",
        "    GPT2Tokenizer,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    BertForSequenceClassification,\n",
        "    BertTokenizer\n",
        ")\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import spacy\n",
        "import textstat\n",
        "import json\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "\n",
        "@dataclass\n",
        "class ContentMetrics:\n",
        "    readability_score: float\n",
        "    coherence_score: float\n",
        "    factual_accuracy: float\n",
        "    engagement_score: float\n",
        "    overall_score: float\n",
        "\n",
        "class ContentEvaluator:\n",
        "    def __init__(self):\n",
        "        # Load BERT model for coherence checking\n",
        "        self.coherence_model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "        self.coherence_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Load spaCy for linguistic analysis\n",
        "        self.nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "    def evaluate_readability(self, content: str) -> float:\n",
        "        \"\"\"Evaluate text readability using multiple metrics\"\"\"\n",
        "        flesch_score = textstat.flesch_reading_ease(content)\n",
        "        grade_level = textstat.coleman_liau_index(content)\n",
        "\n",
        "        # Normalize scores to 0-1 range\n",
        "        normalized_flesch = flesch_score / 100\n",
        "        normalized_grade = (20 - min(grade_level, 20)) / 20\n",
        "\n",
        "        return (normalized_flesch + normalized_grade) / 2\n",
        "\n",
        "    def evaluate_coherence(self, content: str) -> float:\n",
        "        \"\"\"Evaluate text coherence using BERT\"\"\"\n",
        "        inputs = self.coherence_tokenizer(\n",
        "            content,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.coherence_model(**inputs)\n",
        "            coherence_score = torch.sigmoid(outputs.logits).item()\n",
        "\n",
        "        return coherence_score\n",
        "\n",
        "    def evaluate_factual_accuracy(self, content: str) -> float:\n",
        "        \"\"\"\n",
        "        Evaluate factual accuracy using NER and relationship checking\n",
        "        This is a simplified version - in production, you'd want to check against a knowledge base\n",
        "        \"\"\"\n",
        "        doc = self.nlp(content)\n",
        "\n",
        "        # Check for presence of facts (entities, numbers, dates)\n",
        "        facts_count = len([ent for ent in doc.ents])\n",
        "        sentences = len(list(doc.sents))\n",
        "\n",
        "        if sentences == 0:\n",
        "            return 0.0\n",
        "\n",
        "        facts_per_sentence = facts_count / sentences\n",
        "        return min(facts_per_sentence / 3, 1.0)  # Normalize to 0-1\n",
        "\n",
        "    def evaluate_engagement(self, content: str) -> float:\n",
        "        \"\"\"\n",
        "        Evaluate potential engagement based on various factors\n",
        "        \"\"\"\n",
        "        doc = self.nlp(content)\n",
        "\n",
        "        # Check for interactive elements\n",
        "        question_count = len([sent for sent in doc.sents\n",
        "                            if sent.text.strip().endswith('?')])\n",
        "\n",
        "        # Check for variety in sentence structure\n",
        "        sentence_lengths = [len(sent) for sent in doc.sents]\n",
        "        length_variety = np.std(sentence_lengths) if sentence_lengths else 0\n",
        "\n",
        "        # Normalize scores\n",
        "        question_score = min(question_count / 5, 1.0)\n",
        "        variety_score = min(length_variety / 20, 1.0)\n",
        "\n",
        "        return (question_score + variety_score) / 2\n",
        "\n",
        "class ContentGenerator:\n",
        "    def __init__(self):\n",
        "        # Load GPT-2 for creative content generation\n",
        "        self.gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2-medium')\n",
        "        self.gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
        "\n",
        "        # Load T5 for structured content generation\n",
        "        self.t5_model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "        self.t5_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "        # Initialize evaluator\n",
        "        self.evaluator = ContentEvaluator()\n",
        "\n",
        "    def generate_content(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        target_audience: str,\n",
        "        content_type: str,\n",
        "        min_length: int = 200,\n",
        "        max_length: int = 800\n",
        "    ) -> Tuple[str, ContentMetrics]:\n",
        "        \"\"\"Generate educational content with specified parameters\"\"\"\n",
        "\n",
        "        # Construct enhanced prompt\n",
        "        enhanced_prompt = f\"\"\"\n",
        "        Create {content_type} content about: {prompt}\n",
        "        Target audience: {target_audience}\n",
        "        Make it engaging and educational.\n",
        "        Include examples and explanations.\n",
        "        \"\"\"\n",
        "\n",
        "        # Generate initial content using GPT-2\n",
        "        inputs = self.gpt2_tokenizer.encode(\n",
        "            enhanced_prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=100\n",
        "        )\n",
        "\n",
        "        outputs = self.gpt2_model.generate(\n",
        "            inputs,\n",
        "            min_length=min_length,\n",
        "            max_length=max_length,\n",
        "            num_return_sequences=3,\n",
        "            no_repeat_ngram_size=3,\n",
        "            top_p=0.95,\n",
        "            temperature=0.7,\n",
        "            do_sample=True\n",
        "        )\n",
        "\n",
        "        generated_contents = [\n",
        "            self.gpt2_tokenizer.decode(output, skip_special_tokens=True)\n",
        "            for output in outputs\n",
        "        ]\n",
        "\n",
        "        # Evaluate and select best content\n",
        "        best_content = None\n",
        "        best_metrics = None\n",
        "        best_score = -1\n",
        "\n",
        "        for content in generated_contents:\n",
        "            metrics = self._evaluate_content(content)\n",
        "            if metrics.overall_score > best_score:\n",
        "                best_score = metrics.overall_score\n",
        "                best_content = content\n",
        "                best_metrics = metrics\n",
        "\n",
        "        # Refine content using T5 if needed\n",
        "        if best_metrics.overall_score < 0.7:\n",
        "            refined_content = self._refine_content(best_content)\n",
        "            refined_metrics = self._evaluate_content(refined_content)\n",
        "\n",
        "            if refined_metrics.overall_score > best_metrics.overall_score:\n",
        "                return refined_content, refined_metrics\n",
        "\n",
        "        return best_content, best_metrics\n",
        "\n",
        "    def _evaluate_content(self, content: str) -> ContentMetrics:\n",
        "        \"\"\"Evaluate content using multiple metrics\"\"\"\n",
        "        readability = self.evaluator.evaluate_readability(content)\n",
        "        coherence = self.evaluator.evaluate_coherence(content)\n",
        "        factual = self.evaluator.evaluate_factual_accuracy(content)\n",
        "        engagement = self.evaluator.evaluate_engagement(content)\n",
        "\n",
        "        # Calculate weighted overall score\n",
        "        weights = {\n",
        "            'readability': 0.25,\n",
        "            'coherence': 0.3,\n",
        "            'factual': 0.25,\n",
        "            'engagement': 0.2\n",
        "        }\n",
        "\n",
        "        overall = (\n",
        "            weights['readability'] * readability +\n",
        "            weights['coherence'] * coherence +\n",
        "            weights['factual'] * factual +\n",
        "            weights['engagement'] * engagement\n",
        "        )\n",
        "\n",
        "        return ContentMetrics(\n",
        "            readability_score=readability,\n",
        "            coherence_score=coherence,\n",
        "            factual_accuracy=factual,\n",
        "            engagement_score=engagement,\n",
        "            overall_score=overall\n",
        "        )\n",
        "\n",
        "    def _refine_content(self, content: str) -> str:\n",
        "        \"\"\"Refine content using T5 model\"\"\"\n",
        "        input_text = f\"refine educational content: {content}\"\n",
        "        inputs = self.t5_tokenizer.encode(\n",
        "            input_text,\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=1024,\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "        outputs = self.t5_model.generate(\n",
        "            inputs,\n",
        "            max_length=1024,\n",
        "            num_return_sequences=1,\n",
        "            no_repeat_ngram_size=3,\n",
        "            top_p=0.95,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "        refined_content = self.t5_tokenizer.decode(\n",
        "            outputs[0],\n",
        "            skip_special_tokens=True\n",
        "        )\n",
        "        return refined_content\n",
        "\n",
        "class EducationalContentPipeline:\n",
        "    def __init__(self, num_workers: int = 4):\n",
        "        self.generator = ContentGenerator()\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "        # Set up logging\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def generate_curriculum(\n",
        "        self,\n",
        "        topics: List[Dict],\n",
        "        target_audience: str\n",
        "    ) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Generate a complete curriculum of educational content\n",
        "\n",
        "        Args:\n",
        "            topics: List of dicts containing topic info\n",
        "            target_audience: Target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This advanced educational content generation system includes several sophisticated features:\n",
        "\n",
        "Multi-Model Approach:\n",
        "Uses GPT-2 for creative content generation\n",
        "Uses T5 for content refinement\n",
        "Uses BERT for coherence evaluation\n",
        "Uses spaCy for linguistic analysis\n",
        "\n",
        "\n",
        "Comprehensive Content Evaluation:\n",
        "Readability scoring using multiple metrics\n",
        "Coherence evaluation using BERT\n",
        "Factual accuracy checking using NER\n",
        "Engagement scoring based on interactive elements\n",
        "Weighted scoring system for overall quality\n",
        "\n",
        "\n",
        "Advanced Features:\n",
        "Parallel processing for curriculum generation\n",
        "Automatic content refinement when quality thresholds aren't met\n",
        "Detailed metrics and logging\n",
        "Support for different content types and audience levels\n",
        "Error handling and recovery\n",
        "\n",
        "\n",
        "Production-Ready Elements:\n",
        "Type hints for better code maintainability\n",
        "Logging system for monitoring and debugging\n",
        "Progress tracking with tqdm\n",
        "JSON output for easy integration\n",
        "Modular design for easy extension\n",
        "\n",
        "To use this system, you'll need to install the required dependencies:\n",
        "bashCopypip install transformers torch spacy textstat nltk tqdm\n",
        "python -m spacy download en_core_web_sm\n",
        "The system can be used to generate entire curriculums or individual pieces of content, with detailed quality metrics for each generation. Would you like me to explain any specific part in more detail or show how to customize it for particular use cases?"
      ],
      "metadata": {
        "id": "XICwwH7MsvO1"
      }
    }
  ]
}