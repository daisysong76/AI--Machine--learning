{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXgXxhJ/loj2vL3bnJKSlM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daisysong76/AI--Machine--learning/blob/main/Sentiment_Classification_Using_Adapters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "useing adapters for a sentiment classification task. Instead of fine-tuning all of BERT's parameters, I inserted adapter modules into the model, minimizing training time and memory requirements."
      ],
      "metadata": {
        "id": "bZUFfRCVyBDg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add Adapter layers after the feed-forward and attention layers of BERT.\n",
        "\n",
        "Keep the original model weights frozen.\n",
        "\n",
        "Fine-tune only the adapter layers for the new task."
      ],
      "metadata": {
        "id": "cKEAEVklyP5K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ipe991ykxr84"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from transformers import BertTokenizer, BertModel, BertConfig\n",
        "\n",
        "# Define the Adapter Module\n",
        "class Adapter(nn.Module):\n",
        "    def __init__(self, input_dim, adapter_dim=64):\n",
        "        super(Adapter, self).__init__()\n",
        "        self.down_projection = nn.Linear(input_dim, adapter_dim)\n",
        "        self.non_linearity = nn.ReLU()\n",
        "        self.up_projection = nn.Linear(adapter_dim, input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x  # Save the residual connection\n",
        "        x = self.down_projection(x)\n",
        "        x = self.non_linearity(x)\n",
        "        x = self.up_projection(x)\n",
        "        return x + residual  # Add residual connection\n",
        "\n",
        "\n",
        "# Define the Adapter-Enhanced BERT Model\n",
        "class BertWithAdapters(nn.Module):\n",
        "    def __init__(self, model_name=\"bert-base-uncased\", adapter_dim=64, num_labels=2):\n",
        "        super(BertWithAdapters, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(model_name)\n",
        "        self.bert.config.output_hidden_states = True  # To get intermediate layers\n",
        "\n",
        "        # Freeze BERT weights\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Add adapters to each transformer layer\n",
        "        self.adapters = nn.ModuleList(\n",
        "            [Adapter(self.bert.config.hidden_size, adapter_dim) for _ in range(self.bert.config.num_hidden_layers)]\n",
        "        )\n",
        "\n",
        "        # Classification head\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        hidden_states = outputs.hidden_states  # Get all hidden states from BERT\n",
        "\n",
        "        # Pass each layer's output through its corresponding adapter\n",
        "        adapted_outputs = []\n",
        "        for i, hidden_state in enumerate(hidden_states[1:]):  # Skip embedding layer (index 0)\n",
        "            adapted_output = self.adapters[i](hidden_state)\n",
        "            adapted_outputs.append(adapted_output)\n",
        "\n",
        "        # Use the last adapted layer's output for classification\n",
        "        final_output = adapted_outputs[-1][:, 0, :]  # CLS token output\n",
        "        logits = self.classifier(final_output)\n",
        "        return logits\n",
        "\n",
        "\n",
        "# Load Data and Train the Model\n",
        "from transformers import AdamW\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the tokenizer and dataset\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=True, max_length=128)\n",
        "\n",
        "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
        "encoded_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = torch.utils.data.DataLoader(encoded_dataset[\"train\"], batch_size=16, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(encoded_dataset[\"test\"], batch_size=16)\n",
        "\n",
        "# Initialize the model\n",
        "model = BertWithAdapters()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(3):  # Number of epochs\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}\")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy: {correct/total:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Features of This Implementation\n",
        "Adapters:\n",
        "Each transformer layer has its own adapter to introduce trainable parameters while keeping the core model frozen.\n",
        "They consist of a down-projection, a non-linearity, and an up-projection with residual connections.\n",
        "\n",
        "Freezing the Pre-Trained Model:\n",
        "Only adapters and the classification head are trained, making the approach efficient.\n",
        "\n",
        "Modularity:\n",
        "The adapter modules can be reused or extended for different transformer architectures or tasks.\n",
        "\n",
        "Flexibility:\n",
        "You can tune only specific layers, use different adapter dimensions, or extend adapters for tasks beyond classification."
      ],
      "metadata": {
        "id": "Ap3taCH4ybZU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "To ensure the adapter-based approach works effectively and meets the goals of your machine learning project, you must consider several factors and challenges. Here's a comprehensive guide:\n",
        "\n",
        "1. Ensuring the Adapter Works\n",
        "\n",
        "To verify that the adapter is functioning as intended:\n",
        "\n",
        "Baseline Comparison: Compare performance metrics (e.g., accuracy, F1 score) with and without the adapter to measure its impact.\n",
        "Frozen Backbone: Ensure the pre-trained model's weights remain frozen during training. If weights accidentally update, it can lead to inconsistent behavior.\n",
        "Loss Monitoring: Track the loss curve to confirm that the model is learning and not overfitting or underfitting.\n",
        "Task-Specific Metrics: Evaluate performance using metrics appropriate for the task (e.g., precision, recall, BLEU scores for text tasks).\n",
        "Visual Inspection: For tasks like image generation or sentiment analysis, inspect outputs qualitatively to ensure the adapter contributes meaningfully."
      ],
      "metadata": {
        "id": "q77MWeXb3Ifq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Challenges of the Adapter Approach\n",
        "\n",
        "A. Adapter Design\n",
        "Bottleneck Size (Adapter Dimensionality):\n",
        "\n",
        "The adapterâ€™s down-projection and up-projection dimensions must balance computational efficiency and representational capacity.\n",
        "Too small: The adapter may not capture sufficient task-specific knowledge.\n",
        "Too large: The model may overfit or lose the efficiency advantage.\n",
        "Placement:\n",
        "\n",
        "Deciding where to insert adapters (e.g., after attention layers, feed-forward layers, or both) affects their ability to fine-tune the model effectively.\n",
        "\n",
        "B. Limited Capacity\n",
        "Adapters can only adjust the model indirectly by modifying intermediate representations, which may limit their effectiveness on highly complex tasks requiring significant modifications to the backbone.\n",
        "\n",
        "C. Fine-Tuning Stability\n",
        "Adapters can cause instability during training, particularly if initialization or learning rates are not carefully managed.\n",
        "\n",
        "D. Dataset Size\n",
        "Adapters may underperform with very small datasets due to insufficient task-specific signals for fine-tuning, even though they are designed to work efficiently with fewer parameters.\n",
        "\n",
        "E. Model Compatibility\n",
        "Not all pre-trained models are inherently compatible with adapters, and adding adapters might require careful engineering of the forward pass."
      ],
      "metadata": {
        "id": "BWBelh4T3XeO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Considerations for Successful Deployment\n",
        "\n",
        "A. Hyperparameter Tuning\n",
        "Learning Rate: Adapters typically require a smaller learning rate than traditional fine-tuning since fewer parameters are updated.\n",
        "Adapter Dimension: Experiment with different adapter dimensions to balance capacity and efficiency.\n",
        "Batch Size: Use a reasonable batch size to stabilize gradient updates.\n",
        "\n",
        "B. Evaluation Pipeline\n",
        "Use a robust evaluation pipeline that includes cross-validation or hold-out testing to ensure reliable performance.\n",
        "C. Task-Specific Pretraining\n",
        "If the downstream task is too different from the pre-trained model's original tasks, consider task-specific pretraining to improve the adapter's effectiveness.\n",
        "\n",
        "D. Distributed Inference\n",
        "If deploying adapters in production, optimize inference using quantization or pruning to ensure low latency.\n",
        "E. Scalability\n",
        "Ensure that adapters scale efficiently across tasks, especially when deploying multiple models or working in multi-task scenarios.\n"
      ],
      "metadata": {
        "id": "8xJt915x37Y0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Best Practices\n",
        "\n",
        "Experiment with Placement:\n",
        "\n",
        "Adapters can be inserted after attention layers, feed-forward layers, or both. Experiment to identify the most impactful positions for your task.\n",
        "Leverage Pretrained Adapters:\n",
        "\n",
        "Consider using pretrained adapters from libraries like AdapterHub for common tasks to save time.\n",
        "\n",
        "Use Residual Connections:\n",
        "\n",
        "Residual connections in adapters help maintain stability and allow information flow from the frozen backbone.\n",
        "\n",
        "Monitor Performance Across Iterations:\n",
        "\n",
        "Continuously evaluate and refine the adapter design using metrics like validation accuracy and loss.\n",
        "\n",
        "Avoid Overfitting:\n",
        "\n",
        "Regularize training using dropout, weight decay, or early stopping to prevent overfitting, especially on small datasets.\n"
      ],
      "metadata": {
        "id": "7g36ME464D_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tools and Frameworks\n",
        "\n",
        "AdapterHub: A library for working with adapters in Hugging Face models.\n",
        "\n",
        "Hugging Face Transformers: Built-in support for integrating adapters in transformer-based models.\n",
        "\n",
        "Optuna or Ray Tune: Use these tools to automate hyperparameter optimization for adapter-specific parameters."
      ],
      "metadata": {
        "id": "n7FHQ86n4Mg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation Checklist\n",
        "\n",
        " Compare with baseline performance without adapters.\n",
        "\n",
        " Experiment with different adapter configurations (dimensionality, placement).\n",
        "\n",
        " Monitor training metrics (loss, validation accuracy) to confirm stable learning.\n",
        "\n",
        " Validate against real-world test cases or benchmarks.\n",
        "\n",
        " Ensure compatibility with deployment constraints (e.g., latency, memory)."
      ],
      "metadata": {
        "id": "HRjzfHAB5YfH"
      }
    }
  ]
}