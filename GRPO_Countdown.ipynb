{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daisysong76/AI--Machine--learning/blob/main/GRPO_Countdown.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWHvRcC3XKUG"
      },
      "source": [
        "### ⚠️ **Warning: Please note that running the GRPO training job in this notebook to completion has an estimated cost of over $300**.\n",
        "\n",
        "GRPO training runs for 1000 steps by default. You can stop your training job early via the UI after you're satisfied with seeing the performance. (For example after 50-100 steps is where you can start to see the model learning the rewards.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbOzfLz7cq6V"
      },
      "source": [
        "# Environment Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Cp8v47dHg4e2"
      },
      "outputs": [],
      "source": [
        "! pip uninstall -y numpy --quiet  # Temporary workaround for the incompatible default numpy version\n",
        "! pip install predibase\n",
        "! pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpG93vAeUoxO"
      },
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Note\n",
        "\n",
        "If you run into a numpy error creating the Predibase client in the cell below, restart the CoLab session (Runtime->Restart Session in the toolbar) and re-run the cells above."
      ],
      "metadata": {
        "id": "25TIpBol_tR9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjljqN-DhDjD"
      },
      "outputs": [],
      "source": [
        "from predibase import *\n",
        "\n",
        "pb = Predibase(api_token = \"{replace_with_token}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0nICMtqcej8"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9MyTb7phOD9"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"<|im_start|>system\n",
        "You are a helpful assistant. You first think about the reasoning process step by step and then provide the user with an answer.<|im_end|>\n",
        "<|im_start|>user\n",
        "Using the numbers {nums}, create an equation that equals {target}. You can use basic arithmetic operations (+, -, *, /) and parentheses, and each number can only be used once. Show your work in <think> </think> tags. And return the final equation and answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\n",
        "<|im_start|>assistant\n",
        "Let me solve this step by step.\n",
        "<think>\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkNVhskXaD25"
      },
      "outputs": [],
      "source": [
        "def format_row(row):\n",
        "    return template.format(\n",
        "        nums=row[\"nums\"],\n",
        "        target=row[\"target\"]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaU7PJHKahGK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"predibase/countdown\")\n",
        "train_df = pd.DataFrame(dataset[\"train\"])\n",
        "eval_df = pd.DataFrame(dataset[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMJ_HUY9auFj"
      },
      "outputs": [],
      "source": [
        "train_df[\"prompt\"] = train_df.apply(format_row, axis=1)\n",
        "eval_df[\"prompt\"] = eval_df.apply(format_row, axis=1)\n",
        "\n",
        "print(\"train_df\")\n",
        "print(train_df.head(5))\n",
        "print(eval_df.iloc[0][\"prompt\"])\n",
        "print(\"--------\")\n",
        "print(\"eval_df\")\n",
        "print(eval_df.head(5))\n",
        "print(eval_df.iloc[0][\"prompt\"])\n",
        "\n",
        "train_df.to_json(\"./countdown_train.jsonl\", lines=True, orient=\"records\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE_fA_YNeF7V"
      },
      "source": [
        "# Reward Functions\n",
        "Reward functions are how the model will determine how well it's doing during training. It's important to understand how they are defined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwQf0_wPeYzh"
      },
      "outputs": [],
      "source": [
        "import regex as re\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "# Check if the output is properly formatted\n",
        "def format_reward_func(prompt: str, completion: str, example: dict[str, str]) -> int:\n",
        "    # Imported packages must be inside each reward function\n",
        "    import re\n",
        "\n",
        "    reward = 0\n",
        "    try:\n",
        "        # Add synthetic <think> as it's already part of the prompt and prefilled\n",
        "        # for the assistant to more easily match the regex\n",
        "        completion = \"<think>\" + completion\n",
        "\n",
        "        # Check if the format matches expected pattern:\n",
        "        # <think> content </think> followed by <answer> content </answer>\n",
        "        regex = (\n",
        "            r\"^<think>\\s*([^<]*(?:<(?!/?think>)[^<]*)*)\\s*<\\/think>\\n\"\n",
        "            r\"<answer>\\s*([\\s\\S]*?)\\s*<\\/answer>$\"\n",
        "        )\n",
        "\n",
        "        # Search for the regex in the completion\n",
        "        match = re.search(regex, completion, re.DOTALL)\n",
        "        if match is not None and len(match.groups()) == 2:\n",
        "            reward = 1.0\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    print(f\"Format reward: {reward}\")\n",
        "    return reward\n",
        "\n",
        "# Check if the output contains the correct answer\n",
        "def equation_reward_func(prompt: str, completion: str, example: dict[str, str]) -> int:\n",
        "    # Imported packages must be inside each reward function\n",
        "    import re\n",
        "    import ast\n",
        "\n",
        "    reward = 0.0\n",
        "    try:\n",
        "        # add synthetic <think> as its already part of the prompt and prefilled\n",
        "        # for the assistant to more easily match the regex\n",
        "        completion = \"<think>\" + completion\n",
        "        match = re.search(r\"<answer>\\s*([\\s\\S]*?)\\s*<\\/answer>\", completion)\n",
        "        if not match:\n",
        "            print(\"No answer found in completion. Equation reward: 0.0\")\n",
        "            return 0.0\n",
        "\n",
        "        # Extract the \"answer\" part from the completion\n",
        "        equation = match.group(1).strip()\n",
        "        # Extract all numbers from the equation\n",
        "        used_numbers = [int(n) for n in re.findall(r'\\d+', equation)]\n",
        "\n",
        "        # Convert the example[\"nums\"] to a list if it's a string\n",
        "        # This is common for columns like lists in datasets\n",
        "        if isinstance(example[\"nums\"], str):\n",
        "            example[\"nums\"] = ast.literal_eval(example[\"nums\"])\n",
        "\n",
        "        # Check if all numbers are used exactly once\n",
        "        if sorted(used_numbers) != sorted(example[\"nums\"]):\n",
        "            print(\"Numbers used in equation not the same as in example. Equation reward: 0.0\")\n",
        "            return 0.0\n",
        "\n",
        "        # Define a regex pattern that only allows numbers, operators, parentheses, and whitespace\n",
        "        allowed_pattern = r'^[\\d+\\-*/().\\s]+$'\n",
        "        if not re.match(allowed_pattern, equation):\n",
        "            print(\"Equation contains invalid characters. Equation reward: 0.0\")\n",
        "            return 0.0\n",
        "\n",
        "        # Evaluate the equation with restricted globals and locals\n",
        "        result = eval(equation, {\"__builtins__\": None}, {})\n",
        "        # Check if the equation is correct and matches the ground truth\n",
        "        if abs(float(result) - float(example[\"target\"])) < 1e-5:\n",
        "            reward = 1.0\n",
        "        else:\n",
        "            print(\"Equation is incorrect. Equation reward: 0.0\")\n",
        "            return 0.0\n",
        "\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    print(f\"Equation reward: {reward}\")\n",
        "    return reward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLHSNWbLfede"
      },
      "source": [
        "Note the following:\n",
        "- `completions` are the model outputs for a given prompt and `examples` is a list of dicts, with each dict representing a row of the train dataset.\n",
        "- The reward for each completion is appended to the list `rewards`, so the output is a list of floats with the same length as our dataset\n",
        "- While the rewards in this case take on the binary values of 0.0 and 1.0, they can take on any float values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afHssqTsczMB"
      },
      "source": [
        "# Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBnb2QeebS41"
      },
      "outputs": [],
      "source": [
        "# Upload a dataset\n",
        "try:\n",
        "  dataset = pb.datasets.from_file(\"./countdown_train.jsonl\", name=\"countdown_train\")\n",
        "except:\n",
        "  dataset = pb.datasets.get(\"countdown_train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxW66ozBdmHn"
      },
      "outputs": [],
      "source": [
        "# Create a new repo/fetch an existing one\n",
        "repo = pb.repos.create(name=\"countdown\", description=\"GRPO Countdown Runs\", exists_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nb7fb_PWd8oE"
      },
      "outputs": [],
      "source": [
        "# Launch the finetuning job!\n",
        "adapter = pb.adapters.create(\n",
        "    config=GRPOConfig(\n",
        "        base_model=\"qwen2-5-7b-instruct\",\n",
        "        reward_fns=RewardFunctionsConfig(\n",
        "            functions={\n",
        "              \"format\": RewardFunction.from_callable(format_reward_func),\n",
        "              \"answer\": RewardFunction.from_callable(equation_reward_func),\n",
        "            }\n",
        "        ),\n",
        "        target_modules=[\n",
        "            'q_proj', 'v_proj', 'k_proj', 'o_proj',\n",
        "            'gate_proj', 'up_proj', 'down_proj'\n",
        "        ],\n",
        "        train_steps=200,\n",
        "    ),\n",
        "    dataset=\"countdown_train\",\n",
        "    repo=repo,\n",
        "    description=\"Countdown!\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_oXR5u0gO7K"
      },
      "source": [
        "# Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-quP9PtMgSiI"
      },
      "outputs": [],
      "source": [
        "pb.deployments.create(\n",
        "    name=\"my-qwen2-5-7b-instruct\",\n",
        "    config=DeploymentConfig(\n",
        "        base_model=\"qwen2-5-7b-instruct\",\n",
        "        cooldown_time=600,\n",
        "        min_replicas=0,\n",
        "        max_replicas=1\n",
        "    ),\n",
        "    description=\"Created with GRPO Countdown notebook\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPZD2qiOgzY_"
      },
      "outputs": [],
      "source": [
        "adapter_id = \"countdown/1\" # Change the version number as needed (you can find this in the UI)\n",
        "\n",
        "lorax_client = pb.deployments.client(\"my-qwen2-5-7b-instruct\")\n",
        "\n",
        "eval_outputs = []\n",
        "for i, row in eval_df.iterrows():\n",
        "  prompt = row[\"prompt\"]\n",
        "  completion = lorax_client.generate(prompt, adapter_id=adapter_id).generated_text\n",
        "  eval_outputs.append({\"prompt\": prompt, \"completion\": completion})\n",
        "\n",
        "eval_outputs = pd.DataFrame(eval_outputs)\n",
        "print(eval_outputs.head(5))\n",
        "\n",
        "eval_outputs.to_json(\"./eval_outputs.jsonl\", lines=True, orient=\"records\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}