{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPp7ZZEbDUMbJMCs+l+de/H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daisysong76/AI--Machine--learning/blob/main/Augmentation_%2B_Prompt_Engineering_bias_mitigation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… PART 1: Data Augmentation via Prompt Engineering\n",
        "This means generating diverse and balanced training samples by prompting an LLM (like GPT, LLaMA, Mistral, etc.) to output varied but meaningful versions of your input data.\n",
        "\n",
        "ðŸ§  Goal:\n",
        "Introduce semantic diversity\n",
        "Reduce stereotype reinforcement\n",
        "Enrich minority or underrepresented classes\n",
        "\n",
        "ðŸ“Œ Example Task: Sentiment classification or captioning with gender balance\n",
        "ðŸ”§ Code Example Using OpenAI GPT-3.5 API (You can adapt to LLaMA/LLM wrappers"
      ],
      "metadata": {
        "id": "xmlc7LJaMbBz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAc3QzXQMWCM"
      },
      "outputs": [],
      "source": [
        "\n",
        "import openai\n",
        "\n",
        "openai.api_key = 'your-api-key'\n",
        "\n",
        "# Original biased sentence\n",
        "original = \"The CEO walked into the room. He looked confident.\"\n",
        "\n",
        "# Prompt for counterfactual / augmentation\n",
        "prompt = f\"\"\"\n",
        "Rewrite the following sentence using gender-neutral or female-presenting language.\n",
        "Avoid stereotypes. Keep the tone and structure intact.\n",
        "\n",
        "Original: {original}\n",
        "Rewritten:\"\"\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "print(\"Augmented:\", response['choices'][0]['message']['content'].strip())\n",
        "ðŸ“Œ You can batch this to create large datasets:\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "texts = [\n",
        "    \"The nurse helped the doctor. She was tired.\",\n",
        "    \"The engineer fixed the car. He was quick.\",\n",
        "    \"The teacher explained math. She smiled.\"\n",
        "]\n",
        "\n",
        "augmented = []\n",
        "\n",
        "for text in texts:\n",
        "    prompt = f\"\"\"\n",
        "    Rewrite this sentence with a different gender or non-stereotypical roles.\n",
        "\n",
        "    Original: {text}\n",
        "    Rewritten:\"\"\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7\n",
        "    )\n",
        "    augmented.append(response['choices'][0]['message']['content'].strip())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… PART 2: Bias-Aware Prompt Engineering for Evaluation\n",
        "This is about evaluating your modelâ€™s bias by carefully designing prompts that reveal implicit patterns.\n",
        "\n",
        "ðŸŽ¯ Strategy:\n",
        "Create minimal pair prompts differing only in a sensitive attribute\n",
        "Analyze whether LLM completions change unfairly"
      ],
      "metadata": {
        "id": "v7J15u2fMW2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompts = [\n",
        "    \"The nurse said that he was tired.\",\n",
        "    \"The nurse said that she was tired.\"\n",
        "]\n",
        "\n",
        "for prompt in prompts:\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.5,\n",
        "        max_tokens=20\n",
        "    )\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(\"â†’\", response['choices'][0]['message']['content'].strip())"
      ],
      "metadata": {
        "id": "Rfi6-i8WMmci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then compare the outputsâ€”do they reinforce gender roles?\n",
        "You can scale this by:\n",
        "Using template strings and a demographic dictionary\n",
        "Automating sentiment or toxicity scoring using Perspective API or TextBlob\n",
        "\n",
        "âœ… Optional: Fine-tuning with Augmented Data\n",
        "If youâ€™re fine-tuning your own LLM/VLM:\n",
        "Use this augmented data\n",
        "Tokenize using HuggingFace tokenizer\n",
        "Train with LoRA or PEFT (Parameter Efficient Fine-Tuning)\n",
        "Let me know and I can help you write that training loop too.\n",
        "\n",
        "ðŸ§  Summary\n",
        "Step\tGoal\tTools\n",
        "Prompt-Based Augmentation\tGenerate diverse and less-biased samples\tOpenAI / LLaMA / TGI\n",
        "Bias-Aware Prompt Design\tReveal implicit bias\tPaired prompts + LLM\n",
        "Scaled Generation\tBuild datasets fast\tPython loops, templates\n",
        "Optional Fine-tuning\tTrain fairer models\tHuggingFace + LoRA\n",
        "Would you like a Jupyter notebook template that wraps all this together, ready for use with HuggingFace models like Mistral or Zephyr?"
      ],
      "metadata": {
        "id": "nOwqlRebMwp1"
      }
    }
  ]
}