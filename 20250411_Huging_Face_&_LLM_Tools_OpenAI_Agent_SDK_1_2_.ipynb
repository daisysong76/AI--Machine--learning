{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daisysong76/AI--Machine--learning/blob/main/20250411_Huging_Face_%26_LLM_Tools_OpenAI_Agent_SDK_1_2_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRP7lL0AdRxb"
      },
      "source": [
        "# Hugging Face & LLM Tools Study Group\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo-with-title.png\" width=\"600\">    \n",
        "\n",
        "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2023/07/langchain3.png\" width=\"200\">\n",
        "\n",
        "<img src=\"https://devio2023-media.developers.io/wp-content/uploads/2023/03/eyecatch-llamdaindex-960x504.png\" width=\"200\">\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://www.marktechpost.com/wp-content/uploads/2024/01/Screenshot-2024-01-16-at-12.30.59-PM.png\" width=\"200\">\n",
        "\n",
        "<img src=\"https://media.theresanaiforthat.com/icons/ollama.svg\" width=\"200\">\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Gx7VhGYaBgxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CIE-SF Annual Conference**\n",
        "\n",
        "---\n",
        "**AI for Everyone: Shaping Tomorrow's World**  \n",
        "Time: 2025 6/7 Sat. 12:45 pm  \n",
        "Address: 800 North Mary Avenue, Sunnyvale, CA  \n",
        "Synopsys Sunnyvale Campus  \n",
        "Building 1 Auditorium  \n",
        "\n",
        "**Eventbrite:**\n",
        "https://www.eventbrite.com/e/1288716378379?aff=oddtdtcreator\n",
        "\n",
        "---\n",
        "\n",
        "Speakers:\n",
        "- VP of Synopsys, AI using in Chip design\n",
        "- Sr. Director of Meta, llama models\n",
        "- Start-up Advisor of Stanford, AI impact PM jobs and star-ups\n",
        "- Lead Architect AI/ML of Trend Micro, AI for Security & Security for AI\n"
      ],
      "metadata": {
        "id": "yLMoJR3BBHNx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMiDJCDUOroX"
      },
      "source": [
        "# Study Group Line Group Link\n",
        "\n",
        "https://line.me/ti/g2/ewvZJBa7bOJzCtwhZpHv4yUqJhGDOPRWwA1UWA\n",
        "\n",
        "由於最近自學小組的 LINE 群組內出現過多垃圾貼文，我已經建立了一個新的 LINE 社群，名為「AI 自學小組 LLM Tools」。LINE 社群相較於群組具有更完善的管理功能，不僅可以請走張貼不當內容的成員，還能直接移除垃圾貼文。此外，未來也可以針對新參加者進行審查通過。\n",
        "\n",
        "我已經將過去一年多的貼文搬移到新的 LINE 社群。社群的一個優勢是，新加入的成員可以瀏覽之前的歷史貼文，便於快速掌握小組的討論和學習進展。期待大家一起在新社群中繼續交流和成長！\n",
        "\n",
        "但我們發現一些美國的朋友無法加入這個社群，我向LINE詢問的結果得到下面的答覆：  \n",
        "  - 「目前社群服務提供國家為：日本、台灣、泰國，其它地區並未提供該項服務。」\n",
        "\n",
        "在 LINE 改變作法以前，我們還能用 LINE group 與 WeChat Group 來溝通。我們目前把  LINE group 設定成只能由成員邀請加入，不開放 QR code 加入， WeChat Group 每次產生的 QR code 有一個時限。你可以在我們的 Zoom meeting 的時段請人拉你進入。如果你的LINE帳號是 日本、台灣、泰國 區域，那建議你直接加入社群。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSa0AdtRpC5F"
      },
      "source": [
        "# Courses of this Week\n",
        "\n",
        "Week 46 OpenAI Agent SDK 1/2 begining\n",
        "\n",
        "1. OpenAI 全新 AI Agents：Responses API 完整指南 https://tenten.co/learning/openai-agent-responses-api/\n",
        "\n",
        "2. How to Build an Agent with the OpenAI Agents SDK https://www.youtube.com/watch?v=0Z7u6DTDZ8o\n",
        "  - https://colab.research.google.com/drive/17XLmT81pBxHHf6zONgcCatTjpgzHKvae?usp=sharing\n",
        "  - https://github.com/samwit/llm-tutorials\n",
        "\n",
        "3. OpenAI’s BRAND NEW Agents SDK (Crash Course) https://www.youtube.com/watch?v=e7qvd2bOITc\n",
        "  - https://github.com/coleam00/ottomator-agents/tree/main/openai-sdk-agent\n",
        "  - https://github.com/openai/openai-agents-python/tree/main\n",
        "  - https://openai.github.io/openai-agents-python/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI Agent SDK\n",
        "\n",
        "![OpenAI Agent]( https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQI9Ppy_J3po8PoxDtbPZ--ES6g0GtwT1EUcA&s )\n",
        "\n",
        "\n",
        "https://github.com/openai/openai-agents-python/tree/main"
      ],
      "metadata": {
        "id": "jSl1RaPs4UBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- New tools for building agents https://openai.com/index/new-tools-for-building-agents/\n",
        "\n",
        "  - The new [Responses API](https://platform.openai.com/docs/quickstart?api-mode=responses) , combining the simplicity of the Chat Completions API with the tool use capabilities of the Assistants API for building agents\n",
        "  - Built-in tools including [web search](https://platform.openai.com/docs/guides/tools-web-search?api-mode=responses), [file search](https://platform.openai.com/docs/guides/tools-file-search), and [computer use](https://platform.openai.com/docs/guides/tools-computer-use)\n",
        "  - The new Agents SDK⁠(opens in a new window) to orchestrate single-agent and multi-agent workflows\n",
        "  - Integrated observability tools⁠(opens in a new window) to trace and inspect agent workflow execution\n",
        "- OpenAI 全新 AI Agents：Responses API 完整指南 https://tenten.co/learning/openai-agent-responses-api/"
      ],
      "metadata": {
        "id": "mpXied7a5S_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Price\n",
        "\n",
        "Responses API  \n",
        "Our newest API combining the simplicity of Chat Completions with the built-in tool use of Assistants.\n",
        "\n",
        "Price  \n",
        "Responses API is not priced separately. Tokens are billed at the chosen language model’s input and output rates."
      ],
      "metadata": {
        "id": "vUevFufL8Sf6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare three OpenAI API\n",
        "\n",
        "## 1. Chat Completions API（聊天補全 API）\n",
        "\n",
        "### 🧠 概述\n",
        "Chat Completions API 是設計來支援完整對話流程的 API。它透過一組有「角色」（如 system、user、assistant）的訊息組成的陣列，來進行上下文對話補全。特別適合需要多輪互動且保持上下文一致的應用情境。\n",
        "\n",
        "### 🧪 Python 範例\n",
        "```python\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"你的 API 金鑰\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"你是一位樂於助人的助手。\"},\n",
        "        {\"role\": \"user\", \"content\": \"講個笑話給我聽。\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message[\"content\"])\n",
        "```\n",
        "\n",
        "### 🔑 關鍵特點\n",
        "- **訊息結構明確**：使用角色標註（system/user/assistant）區分對話階段。\n",
        "- **支援上下文記憶**：能追蹤多輪對話的上下文。\n",
        "- **互動彈性高**：適合用在需要連續互動的應用（如客服、聊天機器人等）。\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Assistants API（助手 API）\n",
        "\n",
        "### 🧠 概述\n",
        "Assistants API 是為了建立具有持久個性與記憶的虛擬助手所設計，適合需要長期交談與記錄的應用，例如智能助理。可以設定指令、檔案、持久記憶等功能。\n",
        "\n",
        "### 🧪 Python 範例（簡化版本）\n",
        "```python\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"你的 API 金鑰\"\n",
        "\n",
        "# 假設你已經建立 assistant 並取得 assistant_id\n",
        "response = openai.beta.threads.create_and_run(\n",
        "    assistant_id=\"你的_assistant_id\",\n",
        "    thread={\"messages\": [{\"role\": \"user\", \"content\": \"今天天氣怎麼樣？\"}]}\n",
        ")\n",
        "\n",
        "print(response)\n",
        "```\n",
        "\n",
        "### 🔑 關鍵特點\n",
        "- **個人化支援**：可以為助手設置持久個性與指令。\n",
        "- **支援記憶與對話線程（thread）**：適合需要長期互動的應用（如個人助理 App）。\n",
        "- **進階控制功能**：可管理工具（tools）、檔案、記憶體等功能。\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Responses API（回應 API）\n",
        "\n",
        "### 🧠 概述\n",
        "Responses API 是最新且精簡的 API，適合需要單次快速、格式清晰回答的應用場景。與 Chat Completions API 不同，它不需要維護訊息陣列上下文，主要用於一次性查詢。\n",
        "\n",
        "### 🧪 Python 範例\n",
        "```python\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"你的 API 金鑰\"\n",
        "\n",
        "response = openai.Response.create(\n",
        "    model=\"gpt-4\",\n",
        "    prompt=\"請解釋 AI 模型之間的差異。\"\n",
        ")\n",
        "\n",
        "print(response['data'][0]['content'])\n",
        "```\n",
        "\n",
        "> ⚠️ 請注意 `Response API` 尚屬較新功能，實際的 Python 函式名稱可能會隨 OpenAI SDK 更新而調整。建議參考 [官方文件](https://platform.openai.com/docs) 確認語法。\n",
        "\n",
        "### 🔑 關鍵特點\n",
        "- **操作簡單**：僅需傳入 `prompt`，無需多輪訊息結構。\n",
        "- **格式化輸出支援佳**：可更容易整合為 JSON、表格、API 回傳資料等格式。\n",
        "- **速度快、效能穩定**：非常適合 FAQ 查詢、單句生成、搜尋等任務。\n",
        "\n",
        "---\n",
        "\n",
        "## 4. API 比較總覽\n",
        "\n",
        "| 特性 / API       | Chat Completions | Assistants             | Responses              |\n",
        "|------------------|------------------|-------------------------|------------------------|\n",
        "| 對話上下文       | ✅ 支援多輪         | ✅ 支援多輪與記憶         | ❌ 需手動維持上下文        |\n",
        "| 狀態記憶         | ❌ 無記憶           | ✅ 具記憶功能              | ❌ 無記憶               |\n",
        "| 整合難易度       | 中等               | 較複雜（需建立助手）         | 最簡單（直接 prompt）      |\n",
        "| 建議應用場景     | 客服、智慧聊天機器人  | 行動助手、教育 App         | FAQ 機器人、搜尋摘要        |\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 建議使用情境\n",
        "\n",
        "- **Chat Completions API**：當你需要建構自然語言、多輪互動的對話應用。\n",
        "- **Assistants API**：當你要打造具備個性、工具整合、記憶力的長期 AI 助理。\n",
        "- **Responses API**：當你只需要快速、明確的一次性回答，例如搜尋結果、摘要、程式碼生成。\n",
        "\n"
      ],
      "metadata": {
        "id": "f_2FZvw6CU26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI Agents SDK\n",
        "\n",
        "https://openai.github.io/openai-agents-python/\n",
        "\n",
        "- **Agents**, which are LLMs equipped with instructions and tools\n",
        "- **Handoffs**, which allow agents to delegate to other agents for specific tasks\n",
        "- **Guardrails**, which enable the inputs to agents to be validated\n",
        "\n",
        "https://openai.github.io/openai-agents-python/agents/\n",
        "https://openai.github.io/openai-agents-python/running_agents/"
      ],
      "metadata": {
        "id": "SQ_9Dz2aJjgv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Web search\n",
        "\n",
        "\n",
        "\n",
        "Using the Responses API, you can enable web search by configuring it in the tools array in an API request to generate content. Like any other tool, the model can choose to search the web or not based on the content of the input prompt.\n",
        "\n",
        "```python\n",
        "# Web search tool example\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o\",\n",
        "    tools=[{\"type\": \"web_search_preview\"}],\n",
        "    input=\"What was a positive news story from today?\"\n",
        ")\n",
        "\n",
        "print(response.output_text)\n",
        "```\n"
      ],
      "metadata": {
        "id": "cw1BJUYX7bix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### File Search\n",
        "\n",
        "https://platform.openai.com/docs/guides/tools-file-search\n",
        "\n",
        "Prior to using file search with the Responses API, you need to have set up a knowledge base in a vector store and uploaded files to it.\n",
        "\n",
        "```python\n",
        "#from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"What is deep research by OpenAI?\",\n",
        "    tools=[{\n",
        "        \"type\": \"file_search\",\n",
        "        \"vector_store_ids\": [\"<vector_store_id>\"]\n",
        "    }]\n",
        ")\n",
        "print(response)\n",
        "```"
      ],
      "metadata": {
        "id": "LwMB0zyh-pr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computer use\n",
        "\n",
        "https://platform.openai.com/docs/guides/tools-computer-use\n",
        "\n",
        "受 Operator 產品啟發，允許 AI 代理在計算機或瀏覽器上執行任務，如點擊、滾動和輸入。這個工具仍處於早期階段，輸出通常是工具調用。\n",
        "它適合自動化需要多步操作的任務，例如為產品或客戶自動化計算機任務。雖然目前功能有限，但顯示出自動化複雜任務的巨大潛力，例如模擬用戶在瀏覽器上的交互。\n",
        "\n",
        "https://github.com/openai/openai-cua-sample-app\n",
        "\n",
        "> [!CAUTION]  \n",
        "> Computer use is in preview. Because the model is still in preview and may be susceptible to exploits and inadvertent mistakes, we discourage trusting it in authenticated environments or for high-stakes tasks."
      ],
      "metadata": {
        "id": "DAdJCoc9Lw1H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Master OpenAI's Agents SDK\n",
        "\n",
        "我找到一部很適合本週內容的影片，今天的會議上也會談一些裡面的重點。\n",
        "Master OpenAI's Agents SDK  \n",
        "https://www.youtube.com/watch?v=XP7nOVWI_HU\n",
        "\n",
        "GitHub Repository: https://github.com/theailifestyle/oai-agents-sdk\n",
        "\n",
        "\n",
        "# 4 Facets of OpenAI’s Agents SDK\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Agents  \n",
        "Agents are the core building block of the SDK. An agent is a large language model (LLM), configured with tools like web search, file access, and function calling.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Handoffs and Orchestration  \n",
        "Handoffs allow an agent to delegate tasks to another agent. This is particularly useful in scenarios where different agents specialize in different areas.  \n",
        "For example, one agent might handle customer support questions while another handles technical issues, such as software bugs, feature requests, refunds, FAQs, etc.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Guardrails  \n",
        "Guardrails operate alongside agents to validate user interactions.  \n",
        "They come in two types:  \n",
        "- input guardrails that screen inputs  \n",
        "- output guardrails that check final agent responses  \n",
        "\n",
        "Using either, those responsible for guardrails prevent misuse risks in LLM-powered systems.  \n",
        "Guardrails help improve security and ensure the system behaves as expected by restricting harmful, irrelevant, or unsafe responses.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Traceability  \n",
        "The Agents SDK includes built-in tracing, collecting a comprehensive record of events during an agent run:  \n",
        "- LLM generations  \n",
        "- tool calls  \n",
        "- handoffs  \n",
        "- guardrails  \n",
        "- even custom events that users track  \n",
        "\n",
        "Using the Traces dashboard, you can debug, visualize, and monitor your workflows during development and in production.\n",
        "\n",
        "\n",
        "\n",
        "### Overview\n",
        "\n",
        "Building agents involves assembling components across several domains—such as **models**, **tools**, **knowledge & memory**, **guardrails**, and **orchestration**—and OpenAI provides composable primitives for each.\n",
        "\n",
        "\n",
        "| **Domain**             | **Description**                                                                 | **OpenAI Primitives**                                                                                  |\n",
        "|------------------------|---------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------|\n",
        "| **Models**             | Core intelligence capable of reasoning, making decisions, and processing different modalities. | `o1`, `o3-mini`, `GPT-4.5`, `GPT-4o`, `GPT-4o-mini`                                                    |\n",
        "| **Tools**              | Interface to the world, interact with environment, function calling, built-in tools, etc. | [Function calling](#), [Web search](#), [File search](#), [Computer use](#)                             |\n",
        "| **Knowledge & memory** | Augment agents with external and persistent knowledge.                          | [Vector stores](#), [File search](#), [Embeddings](#)                                                  |\n",
        "| **Guardrails**         | Prevent irrelevant, harmful, or undesirable behavior.                           | [Moderation](#), [Instruction hierarchy](#)                                                             |\n",
        "| **Orchestration**      | Develop, deploy, monitor, and improve agents.                                   | [Agents SDK](#), [Tracing](#), [Evaluations](#), [Fine-tuning](#)                                      |\n"
      ],
      "metadata": {
        "id": "MkCblFZkJX8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AgentOps.ai\n",
        "\n",
        "https://docs.agentops.ai/v1/introduction\n",
        "\n",
        "https://www.agentops.ai/#pricing"
      ],
      "metadata": {
        "id": "wcWXE_19Bc-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent Example In-N-Out Burger\n",
        "\n",
        ". How to Build an Agent with the OpenAI Agents SDK\n",
        "https://www.youtube.com/watch?v=0Z7u6DTDZ8o\n",
        "\n",
        "\n",
        "- https://colab.research.google.com/drive/17XLmT81pBxHHf6zONgcCatTjpgzHKvae?usp=sharing#scrollTo=Q2HFn4FzWXZt"
      ],
      "metadata": {
        "id": "kx6mne_LlcbZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example code"
      ],
      "metadata": {
        "id": "VssP89MwIwBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install openai-agents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmjCwtH7HCP_",
        "outputId": "4cffb1db-486b-4e1a-94b2-3f664fe2ca82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/107.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.2/129.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "\n",
        "# Verify that the key is set\n",
        "print(f\"OpenAI API key set: {bool(openai_api_key)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gt9ZGjFJHcq1",
        "outputId": "05e58160-820d-4d46-e6ac-77cce5bede04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API key set: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import markdown\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Example usage\n",
        "markdown_text = \"\"\"\n",
        "# In‑N‑Out Burger Chatbot\n",
        "\"\"\"\n",
        "\n",
        "display(Markdown(markdown_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "GwuTomVOHGMa",
        "outputId": "057df725-6959-404a-ba82-0a6790d68efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n# In‑N‑Out Burger Chatbot\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "0TpoaMT5HhQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MENU_PRICES = \"\"\"\n",
        "\n",
        "# In‑N‑Out Burger Menu (2025)\n",
        "\n",
        "**Prices are approximate and subject to change.**\n",
        "\n",
        "## Burgers & Combos\n",
        "\n",
        "| Item                                    | Price  |\n",
        "|-----------------------------------------|--------|\n",
        "| Additional Burger Patty (per extra)     | $1.30  |\n",
        "| Additional Cheese Slice (per extra)     | $0.50  |\n",
        "| **Hamburger**                           | $3.60  |\n",
        "| **Hamburger Combo**                     | $8.15  |\n",
        "| **Cheeseburger**                        | $4.10  |\n",
        "| **Cheeseburger Combo**                  | $8.65  |\n",
        "| **Double Double®**                      | $5.90  |\n",
        "| **Double Double® Combo**                | $10.45 |\n",
        "| **French Fries**                        | $2.30  |\n",
        "\n",
        "## Beverages\n",
        "\n",
        "| Item                                        | Price  |\n",
        "|---------------------------------------------|--------|\n",
        "| **Coffee**                                  | $1.35  |\n",
        "| **Hot Cocoa**                               | $2.25  |\n",
        "| **Milk**                                    | $0.99  |\n",
        "| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\n",
        "| **Soda (Small)**                            | $2.10  |\n",
        "| **Soda (Medium)**                           | $2.25  |\n",
        "| **Soda (Large)**                            | $2.45  |\n",
        "| **Soda (X‑Large)**                          | $2.65  |\n",
        "\n",
        "## Not‑So‑Secret Menu Options\n",
        "\n",
        "- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\n",
        "- **Animal Style:** Burger or fries served with a mustard‑cooked beef patty, extra spread, pickles, and grilled onions.\n",
        "\n",
        "tax not included\n",
        "\n",
        "tax is 7.25%\n",
        "\n",
        "---\"\"\""
      ],
      "metadata": {
        "id": "hyCg6c1P4PqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner\n",
        "\n",
        "agent = Agent(name=\"In-N-Out Cashier Assistant\",\n",
        "              instructions=f\"You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n{MENU_PRICES}\",\n",
        "              model=\"gpt-4o-mini\"\n",
        "              )"
      ],
      "metadata": {
        "id": "BqYnuVEnH3RU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = Runner.run_sync(agent, \"How much is a Double Double?.\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZDfieblI22f",
        "outputId": "55c703f5-0874-4b97-83bc-aacb3060bdf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Double Double® is priced at $5.90.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(agent, \"How much is a Double Double combo?.\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrscnTW3KNpw",
        "outputId": "3fb96a3e-e95e-40bf-8053-52e6e9b18bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Double Double® Combo is $10.45.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(agent, \"How much is a Double Double and french fries?.\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4Ty9TXekD0F",
        "outputId": "2b5e781a-5978-483d-f9f6-a8686d769a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Double Double® is $5.90, and French Fries are $2.30. \n",
            "\n",
            "So, the total before tax would be $8.20. With tax (7.25%), it would be approximately $8.80.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(agent, \"How much is a Double Double and french fries?.\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWQr2GN9kgze",
        "outputId": "a79daeac-b903-4c99-b680-fcb6eff2800c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Double Double® costs $5.90, and French Fries cost $2.30. \n",
            "\n",
            "So, the total before tax would be $8.20. With a tax of 7.25%, the final amount would be approximately $8.80.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(agent, \"How much is 32 Double Doubles each with french fries with tax?.\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikED24bGkhrZ",
        "outputId": "82ba1016-8a83-4b2d-d71e-2e9581f507a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To calculate the total cost for 32 Double Doubles and French Fries, we first determine the cost before tax:\n",
            "\n",
            "- **Double Double®:** $5.90 each \n",
            "- **French Fries:** $2.30 each \n",
            "\n",
            "Now, let's calculate the total:\n",
            "\n",
            "1. Cost of 32 Double Doubles:\n",
            "   \\[\n",
            "   32 \\times 5.90 = 188.80\n",
            "   \\]\n",
            "\n",
            "2. Cost of 32 French Fries:\n",
            "   \\[\n",
            "   32 \\times 2.30 = 73.60\n",
            "   \\]\n",
            "\n",
            "3. Total cost before tax:\n",
            "   \\[\n",
            "   188.80 + 73.60 = 262.40\n",
            "   \\]\n",
            "\n",
            "Now, let's calculate the tax (7.25%):\n",
            "\n",
            "4. Tax amount:\n",
            "   \\[\n",
            "   262.40 \\times 0.0725 \\approx 19.03\n",
            "   \\]\n",
            "\n",
            "5. Total cost including tax:\n",
            "   \\[\n",
            "   262.40 + 19.03 \\approx 281.43\n",
            "   \\]\n",
            "\n",
            "So, the total cost for 32 Double Doubles each with French fries, including tax, would be approximately **$281.43**.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Streaming"
      ],
      "metadata": {
        "id": "rjJTeTJzklNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from openai.types.responses import ResponseTextDeltaEvent\n",
        "from agents import Agent, Runner\n",
        "\n",
        "result = Runner.run_streamed(agent, input=\"How much is everything on the menu?.\")\n",
        "async for event in result.stream_events():\n",
        "    if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
        "        print(event.data.delta, end=\"\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH83Y1d1kpOt",
        "outputId": "4401ce2f-e457-4815-e985-6aa69f21ced3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here’s a breakdown of the prices on the In-N-Out Burger menu:\n",
            "\n",
            "### Burgers & Combos\n",
            "- Additional Burger Patty (per extra): $1.30\n",
            "- Additional Cheese Slice (per extra): $0.50\n",
            "- Hamburger: $3.60\n",
            "- Hamburger Combo: $8.15\n",
            "- Cheeseburger: $4.10\n",
            "- Cheeseburger Combo: $8.65\n",
            "- Double Double®: $5.90\n",
            "- Double Double® Combo: $10.45\n",
            "- French Fries: $2.30\n",
            "\n",
            "### Beverages\n",
            "- Coffee: $1.35\n",
            "- Hot Cocoa: $2.25\n",
            "- Milk: $0.99\n",
            "- Shakes (Chocolate, Strawberry, Vanilla): $3.00\n",
            "- Soda (Small): $2.10\n",
            "- Soda (Medium): $2.25\n",
            "- Soda (Large): $2.45\n",
            "- Soda (X-Large): $2.65\n",
            "\n",
            "If you'd like me to calculate the total price for all items combined (excluding tax), just let me know!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Code Explain\n",
        "\n",
        "```python\n",
        "result = Runner.run_streamed(agent, input=\"How much is everything on the menu?.\")\n",
        "async for event in result.stream_events():\n",
        "    if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
        "        print(event.data.delta, end=\"\", flush=True)\n",
        "```\n",
        "\n",
        "\n",
        "### 1. `result = Runner.run_streamed(...)`\n",
        "\n",
        "- **`Runner.run_streamed(agent, input=...)`**：這行程式碼呼叫 `Runner` 類別的 `run_streamed` 方法，啟動指定 `agent` 的串流執行，並傳入初始輸入（在此例中為 \"How much is everything on the menu?.\"）。該方法返回一個 `RunResultStreaming` 物件，允許您以異步方式監聽和處理執行過程中的事件。\n",
        "\n",
        "### 2. `async for event in result.stream_events():`\n",
        "\n",
        "- **`async for` 迴圈**：這是一個異步迴圈，用於遍歷 `result.stream_events()` 方法返回的事件流。由於事件是以異步方式產生的，使用 `async for` 可以在不阻塞主程序的情況下逐一處理每個事件。\n",
        "\n",
        "- **`result.stream_events()`**：這個方法返回一個異步生成器，產生執行過程中的各種事件，允許您即時監聽和處理這些事件。\n",
        "\n",
        "### 3. `if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):`\n",
        "\n",
        "- **事件過濾**：在迴圈內，這行程式碼檢查當前事件是否為類型為 `\"raw_response_event\"` 的事件，且其數據部分是否為 `ResponseTextDeltaEvent` 類型。這樣的檢查確保了僅處理特定類型的事件，避免對其他無關事件進行處理。\n",
        "\n",
        "### 4. `print(event.data.delta, end=\"\", flush=True)`\n",
        "\n",
        "- **輸出處理**：如果事件符合上述條件，則提取並輸出 `event.data.delta` 的內容。`delta` 包含了模型生成的文本增量，逐步構成完整的回應。使用 `end=\"\"` 確保輸出不換行，`flush=True` 則確保緩衝區的內容立即輸出，提供即時的反饋給使用者。\n",
        "\n",
        "這段程式碼的作用是以異步方式監聽並處理代理執行過程中的文本生成事件，並即時將生成的文本輸出到控制台。這種方式特別適合需要即時反饋的應用場景，例如聊天機器人或即時資訊展示。"
      ],
      "metadata": {
        "id": "h8V3bnJ8md3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrotdBJcmyX7",
        "outputId": "804f5581-3feb-495c-d36a-be22f0bca67d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RunResultStreaming(input='How much is everything on the menu?.', new_items=[MessageOutputItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# In‑N‑Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double Double®**                      | $5.90  |\\n| **Double Double® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (X‑Large)**                          | $2.65  |\\n\\n## Not‑So‑Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustard‑cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='msg_67f8371ac80081918ab5f39a208d2bdf0df95ae63143c515', content=[ResponseOutputText(annotations=[], text=\"Here’s a breakdown of the prices on the In-N-Out Burger menu:\\n\\n### Burgers & Combos\\n- Additional Burger Patty (per extra): $1.30\\n- Additional Cheese Slice (per extra): $0.50\\n- Hamburger: $3.60\\n- Hamburger Combo: $8.15\\n- Cheeseburger: $4.10\\n- Cheeseburger Combo: $8.65\\n- Double Double®: $5.90\\n- Double Double® Combo: $10.45\\n- French Fries: $2.30\\n\\n### Beverages\\n- Coffee: $1.35\\n- Hot Cocoa: $2.25\\n- Milk: $0.99\\n- Shakes (Chocolate, Strawberry, Vanilla): $3.00\\n- Soda (Small): $2.10\\n- Soda (Medium): $2.25\\n- Soda (Large): $2.45\\n- Soda (X-Large): $2.65\\n\\nIf you'd like me to calculate the total price for all items combined (excluding tax), just let me know!\", type='output_text')], role='assistant', status='completed', type='message'), type='message_output_item')], raw_responses=[ModelResponse(output=[ResponseOutputMessage(id='msg_67f8371ac80081918ab5f39a208d2bdf0df95ae63143c515', content=[ResponseOutputText(annotations=[], text=\"Here’s a breakdown of the prices on the In-N-Out Burger menu:\\n\\n### Burgers & Combos\\n- Additional Burger Patty (per extra): $1.30\\n- Additional Cheese Slice (per extra): $0.50\\n- Hamburger: $3.60\\n- Hamburger Combo: $8.15\\n- Cheeseburger: $4.10\\n- Cheeseburger Combo: $8.65\\n- Double Double®: $5.90\\n- Double Double® Combo: $10.45\\n- French Fries: $2.30\\n\\n### Beverages\\n- Coffee: $1.35\\n- Hot Cocoa: $2.25\\n- Milk: $0.99\\n- Shakes (Chocolate, Strawberry, Vanilla): $3.00\\n- Soda (Small): $2.10\\n- Soda (Medium): $2.25\\n- Soda (Large): $2.45\\n- Soda (X-Large): $2.65\\n\\nIf you'd like me to calculate the total price for all items combined (excluding tax), just let me know!\", type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=413, output_tokens=225, total_tokens=638), referenceable_id='resp_67f8371a792881918aad8b0d6899b4c00df95ae63143c515')], final_output=\"Here’s a breakdown of the prices on the In-N-Out Burger menu:\\n\\n### Burgers & Combos\\n- Additional Burger Patty (per extra): $1.30\\n- Additional Cheese Slice (per extra): $0.50\\n- Hamburger: $3.60\\n- Hamburger Combo: $8.15\\n- Cheeseburger: $4.10\\n- Cheeseburger Combo: $8.65\\n- Double Double®: $5.90\\n- Double Double® Combo: $10.45\\n- French Fries: $2.30\\n\\n### Beverages\\n- Coffee: $1.35\\n- Hot Cocoa: $2.25\\n- Milk: $0.99\\n- Shakes (Chocolate, Strawberry, Vanilla): $3.00\\n- Soda (Small): $2.10\\n- Soda (Medium): $2.25\\n- Soda (Large): $2.45\\n- Soda (X-Large): $2.65\\n\\nIf you'd like me to calculate the total price for all items combined (excluding tax), just let me know!\", input_guardrail_results=[], output_guardrail_results=[], current_agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# In‑N‑Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double Double®**                      | $5.90  |\\n| **Double Double® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (X‑Large)**                          | $2.65  |\\n\\n## Not‑So‑Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustard‑cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), current_turn=1, max_turns=10, is_complete=True)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import random\n",
        "from agents import Agent, ItemHelpers, Runner, function_tool\n",
        "\n",
        "result = Runner.run_streamed(\n",
        "    agent,\n",
        "    input=\"How much is 32 Double Doubles each with french fries?.\",\n",
        ")\n",
        "print(\"=== Run starting ===\")\n",
        "\n",
        "async for event in result.stream_events():\n",
        "    # We'll ignore the raw responses event deltas\n",
        "    if event.type == \"raw_response_event\":\n",
        "        continue\n",
        "    # When the agent updates, print that\n",
        "    elif event.type == \"agent_updated_stream_event\":\n",
        "        print(f\"Agent updated: {event.new_agent.name}\")\n",
        "        continue\n",
        "    # When items are generated, print them\n",
        "    elif event.type == \"run_item_stream_event\":\n",
        "        if event.item.type == \"tool_call_item\":\n",
        "            print(\"-- Tool was called\")\n",
        "        elif event.item.type == \"tool_call_output_item\":\n",
        "            print(f\"-- Tool output: {event.item.output}\")\n",
        "        elif event.item.type == \"message_output_item\":\n",
        "            print(f\"-- Message output:\\n {ItemHelpers.text_message_output(event.item)}\")\n",
        "        else:\n",
        "            pass  # Ignore other event types\n",
        "\n",
        "print(\"=== Run complete ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXxFTFa8nTgk",
        "outputId": "459e2cb0-f6c8-4f36-f4ce-85fd4c0c005d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Run starting ===\n",
            "Agent updated: In-N-Out Cashier Assistant\n",
            "-- Message output:\n",
            " To calculate the cost for 32 Double Doubles each with a French fry order:\n",
            "\n",
            "- **Double Double® price:** $5.90\n",
            "- **French Fries price:** $2.30\n",
            "\n",
            "**Total for one combo (Double Double® + French Fries):**\n",
            "- Double Double® + French Fries = $5.90 + $2.30 = $8.20\n",
            "\n",
            "**Total for 32 combos:**\n",
            "- 32 combos x $8.20 = $262.40\n",
            "\n",
            "Now, adding tax (7.25%):\n",
            "- Tax = $262.40 x 0.0725 = $19.02 (approx.)\n",
            "\n",
            "**Total cost including tax:**\n",
            "- $262.40 + $19.02 = $281.42 (approx.)\n",
            "\n",
            "So, the total cost for 32 Double Doubles with French fries, including tax, is approximately **$281.42**.\n",
            "=== Run complete ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### streaming\n",
        "\n",
        "### 1. 啟動代理的串流執行\n",
        "\n",
        "```python\n",
        "result = Runner.run_streamed(\n",
        "    agent,\n",
        "    input=\"How much is 32 Double Doubles each with french fries?.\",\n",
        ")\n",
        "```\n",
        "\n",
        "\n",
        "- **`Runner.run_streamed()`**：這個方法啟動指定代理的串流執行，並返回一個 `RunResultStreaming` 物件。\n",
        "- **`agent`**：代表要執行的代理實例。\n",
        "- **`input`**：提供給代理的輸入訊息。\n",
        "\n",
        "### 2. 非同步處理事件流\n",
        "\n",
        "```python\n",
        "async for event in result.stream_events():\n",
        "```\n",
        "\n",
        "\n",
        "- **`async for`**：使用非同步迴圈來遍歷事件流，允許在事件產生時即時處理。\n",
        "- **`result.stream_events()`**：返回一個非同步生成器，產生代理執行過程中的各種事件。\n",
        "\n",
        "### 3. 處理不同類型的事件\n",
        "\n",
        "#### a. 忽略原始回應事件\n",
        "\n",
        "```python\n",
        "if event.type == \"raw_response_event\":\n",
        "    continue\n",
        "```\n",
        "\n",
        "\n",
        "- **`raw_response_event`**：表示來自語言模型的原始回應事件，通常包含逐字生成的文本。\n",
        "- **`continue`**：跳過這些事件，不進行處理。\n",
        "\n",
        "#### b. 處理代理更新事件\n",
        "\n",
        "```python\n",
        "elif event.type == \"agent_updated_stream_event\":\n",
        "    print(f\"Agent updated: {event.new_agent.name}\")\n",
        "    continue\n",
        "```\n",
        "\n",
        "\n",
        "- **`agent_updated_stream_event`**：表示代理已更新，可能是由於任務轉交給其他代理。\n",
        "- **`event.new_agent.name`**：取得新的代理名稱並輸出。\n",
        "\n",
        "#### c. 處理執行項目事件\n",
        "\n",
        "```python\n",
        "elif event.type == \"run_item_stream_event\":\n",
        "    if event.item.type == \"tool_call_item\":\n",
        "        print(\"-- Tool was called\")\n",
        "    elif event.item.type == \"tool_call_output_item\":\n",
        "        print(f\"-- Tool output: {event.item.output}\")\n",
        "    elif event.item.type == \"message_output_item\":\n",
        "        print(f\"-- Message output:\\n {ItemHelpers.text_message_output(event.item)}\")\n",
        "    else:\n",
        "        pass  # Ignore other event types\n",
        "```\n",
        "\n",
        "\n",
        "- **`run_item_stream_event`**：表示代理執行過程中的具體項目事件。\n",
        "- **`tool_call_item`**：代理呼叫工具的事件，輸出提示。\n",
        "- **`tool_call_output_item`**：工具執行完成並返回結果的事件，輸出結果。\n",
        "- **`message_output_item`**：代理生成訊息的事件，使用 `ItemHelpers.text_message_output()` 方法格式化並輸出訊息內容。\n",
        "\n",
        "### 4. 結束執行\n",
        "\n",
        "```python\n",
        "print(\"=== Run complete ===\")\n",
        "```\n",
        "\n",
        "\n",
        "- 在所有事件處理完畢後，輸出執行完成的提示。\n",
        "\n",
        "這段程式碼的目的是即時監控代理的執行過程，並根據不同的事件類型輸出相應的資訊，這對於開發交互式應用或進行除錯非常有幫助。"
      ],
      "metadata": {
        "id": "EIQAFglhnijF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding Tools"
      ],
      "metadata": {
        "id": "iAkcyaqKpFxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, function_tool\n",
        "\n",
        "@function_tool\n",
        "async def calculate_tax(order_total: float, tax_rate: float) -> str:\n",
        "    print(f\"[debug] calculating tax function called order:{order_total} tax:{tax_rate}\")\n",
        "    \"\"\"Calculates the tax for a given order total based on the input amount (float) and tax rate (float).\n",
        "    Args:\n",
        "        order_total: The total amount of the order before tax.\n",
        "        location: The location of the order. Defaults to Los Angeles, CA.\n",
        "    \"\"\"\n",
        "    tax_rate = 0.0725  # Default tax rate for Los Angeles, CA\n",
        "    tax_amount = order_total * tax_rate\n",
        "    total_with_tax = order_total + tax_amount\n",
        "    return f\"The tax on your order is ${tax_amount:.2f}. Your total with tax is ${total_with_tax:.2f}.\""
      ],
      "metadata": {
        "id": "JKTVxtSppErf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = Agent(name=\"In-N-Out Cashier Assistant\",\n",
        "              instructions=f\"You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n{MENU_PRICES}\",\n",
        "              model=\"gpt-4o\",\n",
        "              tools=[calculate_tax]\n",
        "              )"
      ],
      "metadata": {
        "id": "xx7CpYpapQqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(agent, \"How much is 5 Double Doubles each with french fries?.\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9jb0gp7pZrd",
        "outputId": "ee0a2a0b-7f2c-4ce6-9ad1-d1cf0a81914d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[debug] calculating tax function called order:40.1 tax:7.25\n",
            "[debug] calculating tax function called order:11.5 tax:7.25\n",
            "The cost for 5 Double Doubles with French Fries each is $40.10 before tax. \n",
            "\n",
            "With a 7.25% tax, the total comes to $43.01.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "我在測試中 GPT-4o 曾經有計算錯 5 Double Doubles each with french fries 的價格"
      ],
      "metadata": {
        "id": "nwlqGWTsqQOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "41.0 *1.0725"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce1SDgQfprMg",
        "outputId": "47b58acc-962d-4907-b8cc-d8d544fa2438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43.972500000000004"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c082hu8zrgfK",
        "outputId": "e4c731b5-0fd9-46dc-a203-155b64b34205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RunResult(input='How much is 5 Double Doubles each with french fries?.', new_items=[ToolCallItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# In‑N‑Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double Double®**                      | $5.90  |\\n| **Double Double® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (X‑Large)**                          | $2.65  |\\n\\n## Not‑So‑Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustard‑cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"order_total\":40.1,\"tax_rate\":7.25}', call_id='call_Pwki0CEgV5ZbXCgHKyYBLyvN', name='calculate_tax', type='function_call', id='fc_67f83c4892e481918d3fb2a2e418458206f1996463c69815', status='completed'), type='tool_call_item'), ToolCallItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# In‑N‑Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double Double®**                      | $5.90  |\\n| **Double Double® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (X‑Large)**                          | $2.65  |\\n\\n## Not‑So‑Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustard‑cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"order_total\":11.5,\"tax_rate\":7.25}', call_id='call_z1wBBTZjhiuzrswaq5DhMGjV', name='calculate_tax', type='function_call', id='fc_67f83c48bf0481919ef1007bc288589206f1996463c69815', status='completed'), type='tool_call_item'), ToolCallOutputItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# In‑N‑Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double Double®**                      | $5.90  |\\n| **Double Double® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (X‑Large)**                          | $2.65  |\\n\\n## Not‑So‑Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustard‑cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_Pwki0CEgV5ZbXCgHKyYBLyvN', 'output': 'The tax on your order is $2.91. Your total with tax is $43.01.', 'type': 'function_call_output'}, output='The tax on your order is $2.91. Your total with tax is $43.01.', type='tool_call_output_item'), ToolCallOutputItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# In‑N‑Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double Double®**                      | $5.90  |\\n| **Double Double® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (X‑Large)**                          | $2.65  |\\n\\n## Not‑So‑Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustard‑cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_z1wBBTZjhiuzrswaq5DhMGjV', 'output': 'The tax on your order is $0.83. Your total with tax is $12.33.', 'type': 'function_call_output'}, output='The tax on your order is $0.83. Your total with tax is $12.33.', type='tool_call_output_item'), MessageOutputItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# In‑N‑Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double Double®**                      | $5.90  |\\n| **Double Double® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (X‑Large)**                          | $2.65  |\\n\\n## Not‑So‑Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustard‑cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='msg_67f83c49677881918da25e377f8811aa06f1996463c69815', content=[ResponseOutputText(annotations=[], text='The cost for 5 Double Doubles with French Fries each is $40.10 before tax. \\n\\nWith a 7.25% tax, the total comes to $43.01.', type='output_text')], role='assistant', status='completed', type='message'), type='message_output_item')], raw_responses=[ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"order_total\":40.1,\"tax_rate\":7.25}', call_id='call_Pwki0CEgV5ZbXCgHKyYBLyvN', name='calculate_tax', type='function_call', id='fc_67f83c4892e481918d3fb2a2e418458206f1996463c69815', status='completed'), ResponseFunctionToolCall(arguments='{\"order_total\":11.5,\"tax_rate\":7.25}', call_id='call_z1wBBTZjhiuzrswaq5DhMGjV', name='calculate_tax', type='function_call', id='fc_67f83c48bf0481919ef1007bc288589206f1996463c69815', status='completed')], usage=Usage(requests=1, input_tokens=0, output_tokens=0, total_tokens=0), referenceable_id='resp_67f83c481c4c8191b82131980c819f9f06f1996463c69815'), ModelResponse(output=[ResponseOutputMessage(id='msg_67f83c49677881918da25e377f8811aa06f1996463c69815', content=[ResponseOutputText(annotations=[], text='The cost for 5 Double Doubles with French Fries each is $40.10 before tax. \\n\\nWith a 7.25% tax, the total comes to $43.01.', type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=562, output_tokens=41, total_tokens=603), referenceable_id='resp_67f83c4910948191b8075040da16271506f1996463c69815')], final_output='The cost for 5 Double Doubles with French Fries each is $40.10 before tax. \\n\\nWith a 7.25% tax, the total comes to $43.01.', input_guardrail_results=[], output_guardrail_results=[], _last_agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# In‑N‑Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double Double®**                      | $5.90  |\\n| **Double Double® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (X‑Large)**                          | $2.65  |\\n\\n## Not‑So‑Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustard‑cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in result.__dict__.items():\n",
        "  print(f\"{k}: {v}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HK09nabUrobq",
        "outputId": "f4247a2b-9076-4dcd-ba98-07dc05b8c947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: How much is 5 Double Doubles each with french fries?.\n",
            "new_items: [ToolCallItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# In‑N‑Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double Double®**                      | $5.90  |\\n| **Double Double® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (X‑Large)**                          | $2.65  |\\n\\n## Not‑So‑Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustard‑cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"order_total\":40.1,\"tax_rate\":7.25}', call_id='call_Pwki0CEgV5ZbXCgHKyYBLyvN', name='calculate_tax', type='function_call', id='fc_67f83c4892e481918d3fb2a2e418458206f1996463c69815', status='completed'), type='tool_call_item'), ToolCallItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# In‑N‑Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double Double®**                      | $5.90  |\\n| **Double Double® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (X‑Large)**                          | $2.65  |\\n\\n## Not‑So‑Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustard‑cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"order_total\":11.5,\"tax_rate\":7.25}', call_id='call_z1wBBTZjhiuzrswaq5DhMGjV', name='calculate_tax', type='function_call', id='fc_67f83c48bf0481919ef1007bc288589206f1996463c69815', status='completed'), type='tool_call_item'), ToolCallOutputItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# In‑N‑Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double Double®**                      | $5.90  |\\n| **Double Double® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (X‑Large)**                          | $2.65  |\\n\\n## Not‑So‑Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustard‑cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_Pwki0CEgV5ZbXCgHKyYBLyvN', 'output': 'The tax on your order is $2.91. Your total with tax is $43.01.', 'type': 'function_call_output'}, output='The tax on your order is $2.91. Your total with tax is $43.01.', type='tool_call_output_item'), ToolCallOutputItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# In‑N‑Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double Double®**                      | $5.90  |\\n| **Double Double® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (X‑Large)**                          | $2.65  |\\n\\n## Not‑So‑Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustard‑cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_z1wBBTZjhiuzrswaq5DhMGjV', 'output': 'The tax on your order is $0.83. Your total with tax is $12.33.', 'type': 'function_call_output'}, output='The tax on your order is $0.83. Your total with tax is $12.33.', type='tool_call_output_item'), MessageOutputItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# In‑N‑Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double Double®**                      | $5.90  |\\n| **Double Double® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (X‑Large)**                          | $2.65  |\\n\\n## Not‑So‑Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustard‑cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='msg_67f83c49677881918da25e377f8811aa06f1996463c69815', content=[ResponseOutputText(annotations=[], text='The cost for 5 Double Doubles with French Fries each is $40.10 before tax. \\n\\nWith a 7.25% tax, the total comes to $43.01.', type='output_text')], role='assistant', status='completed', type='message'), type='message_output_item')]\n",
            "raw_responses: [ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"order_total\":40.1,\"tax_rate\":7.25}', call_id='call_Pwki0CEgV5ZbXCgHKyYBLyvN', name='calculate_tax', type='function_call', id='fc_67f83c4892e481918d3fb2a2e418458206f1996463c69815', status='completed'), ResponseFunctionToolCall(arguments='{\"order_total\":11.5,\"tax_rate\":7.25}', call_id='call_z1wBBTZjhiuzrswaq5DhMGjV', name='calculate_tax', type='function_call', id='fc_67f83c48bf0481919ef1007bc288589206f1996463c69815', status='completed')], usage=Usage(requests=1, input_tokens=0, output_tokens=0, total_tokens=0), referenceable_id='resp_67f83c481c4c8191b82131980c819f9f06f1996463c69815'), ModelResponse(output=[ResponseOutputMessage(id='msg_67f83c49677881918da25e377f8811aa06f1996463c69815', content=[ResponseOutputText(annotations=[], text='The cost for 5 Double Doubles with French Fries each is $40.10 before tax. \\n\\nWith a 7.25% tax, the total comes to $43.01.', type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=562, output_tokens=41, total_tokens=603), referenceable_id='resp_67f83c4910948191b8075040da16271506f1996463c69815')]\n",
            "final_output: The cost for 5 Double Doubles with French Fries each is $40.10 before tax. \n",
            "\n",
            "With a 7.25% tax, the total comes to $43.01.\n",
            "input_guardrail_results: []\n",
            "output_guardrail_results: []\n",
            "_last_agent: Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# In‑N‑Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double Double®**                      | $5.90  |\\n| **Double Double® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (X‑Large)**                          | $2.65  |\\n\\n## Not‑So‑Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustard‑cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def extract_function_calls(run_result):\n",
        "    \"\"\"\n",
        "    Extracts function call items (both the call details and outputs)\n",
        "    from the run_result object.\n",
        "    \"\"\"\n",
        "    function_calls = {}\n",
        "    # Use attribute access instead of dict.get()\n",
        "    new_items = run_result.new_items if hasattr(run_result, 'new_items') else []\n",
        "\n",
        "    for item in new_items:\n",
        "        # Assuming each item has an attribute 'raw_item'\n",
        "        raw_item = item.raw_item if hasattr(item, 'raw_item') else {}\n",
        "\n",
        "        # Try to get the type from raw_item. It might be a dict or an object.\n",
        "        if isinstance(raw_item, dict):\n",
        "            item_type = raw_item.get(\"type\")\n",
        "            call_id = raw_item.get(\"call_id\")\n",
        "        else:\n",
        "            item_type = getattr(raw_item, \"type\", None)\n",
        "            call_id = getattr(raw_item, \"call_id\", None)\n",
        "\n",
        "        # Check if the item is a function call or its output\n",
        "        if item_type in [\"function_call\", \"function_call_output\"]:\n",
        "            if call_id not in function_calls:\n",
        "                function_calls[call_id] = {}\n",
        "            if item_type == \"function_call\":\n",
        "                # Get arguments as a JSON string and parse it\n",
        "                if isinstance(raw_item, dict):\n",
        "                    args = raw_item.get(\"arguments\")\n",
        "                    function_calls[call_id][\"name\"] = raw_item.get(\"name\")\n",
        "                else:\n",
        "                    args = getattr(raw_item, \"arguments\", None)\n",
        "                    function_calls[call_id][\"name\"] = getattr(raw_item, \"name\", None)\n",
        "                try:\n",
        "                    function_calls[call_id][\"arguments\"] = json.loads(args)\n",
        "                except Exception:\n",
        "                    function_calls[call_id][\"arguments\"] = args\n",
        "            elif item_type == \"function_call_output\":\n",
        "                if isinstance(raw_item, dict):\n",
        "                    function_calls[call_id][\"output\"] = raw_item.get(\"output\")\n",
        "                else:\n",
        "                    function_calls[call_id][\"output\"] = getattr(raw_item, \"output\", None)\n",
        "    return function_calls\n",
        "\n",
        "# Assuming `result` is your RunResult object:\n",
        "calls = extract_function_calls(result)\n",
        "\n",
        "# Print the extracted details\n",
        "for call_id, details in calls.items():\n",
        "    print(f\"Call ID: {call_id}\")\n",
        "    print(f\"Function Name: {details.get('name', 'N/A')}\")\n",
        "    print(\"Arguments:\")\n",
        "    for arg, value in details.get(\"arguments\", {}).items():\n",
        "        print(f\"  {arg}: {value}\")\n",
        "    print(\"Output:\")\n",
        "    print(f\"  {details.get('output', 'No output')}\")\n",
        "    print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4eGiXupryDq",
        "outputId": "58a8b656-b32f-4da6-f0f6-3034b2374a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Call ID: call_Pwki0CEgV5ZbXCgHKyYBLyvN\n",
            "Function Name: calculate_tax\n",
            "Arguments:\n",
            "  order_total: 40.1\n",
            "  tax_rate: 7.25\n",
            "Output:\n",
            "  The tax on your order is $2.91. Your total with tax is $43.01.\n",
            "----------------------------------------\n",
            "Call ID: call_z1wBBTZjhiuzrswaq5DhMGjV\n",
            "Function Name: calculate_tax\n",
            "Arguments:\n",
            "  order_total: 11.5\n",
            "  tax_rate: 7.25\n",
            "Output:\n",
            "  The tax on your order is $0.83. Your total with tax is $12.33.\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Websearch Tool"
      ],
      "metadata": {
        "id": "NVEE1MX-r7IL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, FileSearchTool, Runner, WebSearchTool"
      ],
      "metadata": {
        "id": "LgerrUHar5ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcdonalds_agent = Agent(name=\"McDonalds Assistant\",\n",
        "              instructions=f\"You are a helpful server at McDonalds, respond to questions by using the search tool\",\n",
        "              model=\"gpt-4o\",\n",
        "              tools=[WebSearchTool()]\n",
        "              )"
      ],
      "metadata": {
        "id": "AhOc8T7VsFRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(mcdonalds_agent, \"How much is BigMac?.\")\n",
        "\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJicFk0TsKfb",
        "outputId": "758556ba-1ef1-4850-b8a7-96960e2c95dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As of 2024, the average price of a McDonald's Big Mac in the United States is approximately $5.29, reflecting a 20.5% increase from $4.39 in 2019. ([wsaz.com](https://www.wsaz.com/2024/05/30/mcdonalds-says-18-big-mac-meal-was-an-exception-news-reports-overstated-its-price-increases/?utm_source=openai)) However, prices can vary by location due to factors like regional costs and franchisee pricing decisions. For instance, in Massachusetts, a Big Mac can cost as much as $7.09, while in North Carolina and Wyoming, it's priced at $4.19. ([zippia.com](https://www.zippia.com/advice/how-much-big-mac-costs-states/?utm_source=openai)) Additionally, McDonald's has introduced value deals, such as a $5 meal promotion, to offer more affordable options to customers. ([wsaz.com](https://www.wsaz.com/2024/05/30/mcdonalds-says-18-big-mac-meal-was-an-exception-news-reports-overstated-its-price-increases/?utm_source=openai)) \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.new_items[1].raw_item.content[0].annotations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq6bUIQBsUT8",
        "outputId": "8ff9b1a8-3e94-4a6a-a45e-2be4bef116c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AnnotationURLCitation(end_index=303, start_index=147, title=\"McDonald's says $18 Big Mac meal was an 'exception' and news reports overstated its price increases\", type='url_citation', url='https://www.wsaz.com/2024/05/30/mcdonalds-says-18-big-mac-meal-was-an-exception-news-reports-overstated-its-price-increases/?utm_source=openai'),\n",
              " AnnotationURLCitation(end_index=632, start_index=538, title='How Much A Big Mac Costs In Every State - Zippia', type='url_citation', url='https://www.zippia.com/advice/how-much-big-mac-costs-states/?utm_source=openai'),\n",
              " AnnotationURLCitation(end_index=918, start_index=762, title=\"McDonald's says $18 Big Mac meal was an 'exception' and news reports overstated its price increases\", type='url_citation', url='https://www.wsaz.com/2024/05/30/mcdonalds-says-18-big-mac-meal-was-an-exception-news-reports-overstated-its-price-increases/?utm_source=openai')]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agents as tools"
      ],
      "metadata": {
        "id": "oHHvBj0jsWKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner\n",
        "import asyncio\n",
        "\n",
        "\n",
        "\n",
        "orchestrator_agent = Agent(\n",
        "    name=\"orchestrator_agent\",\n",
        "    instructions=(\n",
        "        \"You are a DoorDash Agent who decides which tools or assistants to call \"\n",
        "        \"If asked for prices or menu items, you call the relevant tools.\"\n",
        "        \"if asked for info from. more than one source run multiple tools\"\n",
        "    ),\n",
        "    tools=[\n",
        "        agent.as_tool(\n",
        "            tool_name=\"in_n_out_burger_assistant\",\n",
        "            tool_description=\"Get prices with tax for In-N-Out Burger\",\n",
        "        ),\n",
        "        mcdonalds_agent.as_tool(\n",
        "            tool_name=\"mcdonalds_assistant\",\n",
        "            tool_description=\"Get prices for McDonalds\",\n",
        "        ),\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "janSLi3TsY70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(orchestrator_agent, input=\"How much is a Double Double at in-N-out?\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1hcPdsZsgRj",
        "outputId": "af545d87-37d3-41e0-85bf-72491b185d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Double Double® by itself is $5.90, and as a Combo with fries and a drink, it's $10.45.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(orchestrator_agent, input=\"what does McDonalds have for breakfast?\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfB5cG_tssT2",
        "outputId": "5f4b0989-0ab9-4110-8836-ef68006bcc56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "McDonald's breakfast menu includes a variety of delicious options:\n",
            "\n",
            "1. **Egg McMuffin®**: Freshly cracked egg, Canadian bacon, and American cheese on an English muffin (310 calories).\n",
            "\n",
            "2. **Sausage McMuffin® with Egg**: Sausage, American cheese, and a freshly cracked egg on an English muffin (480 calories).\n",
            "\n",
            "3. **Bacon, Egg & Cheese Biscuit**: Buttermilk biscuit with bacon, egg, and American cheese (450 calories).\n",
            "\n",
            "4. **Sausage, Egg & Cheese McGriddles®**: Sausage, egg, and cheese between maple-flavored griddle cakes (550 calories).\n",
            "\n",
            "5. **Hotcakes**: Three hotcakes with butter and syrup (590 calories).\n",
            "\n",
            "For more details, including prices and local availability, check with your local McDonald's or visit their [official breakfast menu](https://www.mcdonalds.com/us/en-us/full-menu/breakfast.html).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(orchestrator_agent, input=\"Is a BigMac or a DoubleDouble AnimalStyle cheaper?\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuUHUFh4sz-9",
        "outputId": "e12a4ae9-b1ce-426d-8b15-4445e190ba33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[debug] calculating tax function called order:5.9 tax:7.25\n",
            "The Double Double Animal Style at In-N-Out costs $6.33 with tax, while the average price of a Big Mac at McDonald's is around $5.29. Therefore, the Big Mac is generally cheaper.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYpVgsH-s3ac",
        "outputId": "42ccb547-08b5-49dd-c76c-6024b9dea6a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RunResult(input='Is a BigMac or a DoubleDouble AnimalStyle cheaper?', new_items=[ToolCallItem(agent=Agent(name='orchestrator_agent', instructions='You are a DoorDash Agent who decides which tools or assistants to call If asked for prices or menu items, you call the relevant tools.if asked for info from. more than one source run multiple tools', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='in_n_out_burger_assistant', description='Get prices with tax for In-N-Out Burger', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'in_n_out_burger_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1590ea0>, strict_json_schema=True), FunctionTool(name='mcdonalds_assistant', description='Get prices for McDonalds', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'mcdonalds_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1525080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"input\":\"Big Mac\"}', call_id='call_hKLyrzpSmH8lVzJ6df5ZeJWQ', name='mcdonalds_assistant', type='function_call', id='fc_67f83e4753948191a3ba0d5042244cdf05f5889c5a98b6a8', status='completed'), type='tool_call_item'), ToolCallItem(agent=Agent(name='orchestrator_agent', instructions='You are a DoorDash Agent who decides which tools or assistants to call If asked for prices or menu items, you call the relevant tools.if asked for info from. more than one source run multiple tools', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='in_n_out_burger_assistant', description='Get prices with tax for In-N-Out Burger', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'in_n_out_burger_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1590ea0>, strict_json_schema=True), FunctionTool(name='mcdonalds_assistant', description='Get prices for McDonalds', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'mcdonalds_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1525080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"input\":\"Double Double Animal Style\"}', call_id='call_sieCxHHI10ME6IWdCrGddscS', name='in_n_out_burger_assistant', type='function_call', id='fc_67f83e477f048191a424f82124b8637605f5889c5a98b6a8', status='completed'), type='tool_call_item'), ToolCallOutputItem(agent=Agent(name='orchestrator_agent', instructions='You are a DoorDash Agent who decides which tools or assistants to call If asked for prices or menu items, you call the relevant tools.if asked for info from. more than one source run multiple tools', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='in_n_out_burger_assistant', description='Get prices with tax for In-N-Out Burger', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'in_n_out_burger_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1590ea0>, strict_json_schema=True), FunctionTool(name='mcdonalds_assistant', description='Get prices for McDonalds', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'mcdonalds_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1525080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_hKLyrzpSmH8lVzJ6df5ZeJWQ', 'output': \"The Big Mac is one of McDonald's most iconic burgers. It features:\\n\\n- Two all-beef patties\\n- Special sauce (similar to Thousand Island dressing)\\n- Lettuce\\n- Cheese\\n- Pickles\\n- Onions\\n- Served on a sesame seed bun with an additional middle bun\\n\\nWould you like to know anything else about it?\", 'type': 'function_call_output'}, output=\"The Big Mac is one of McDonald's most iconic burgers. It features:\\n\\n- Two all-beef patties\\n- Special sauce (similar to Thousand Island dressing)\\n- Lettuce\\n- Cheese\\n- Pickles\\n- Onions\\n- Served on a sesame seed bun with an additional middle bun\\n\\nWould you like to know anything else about it?\", type='tool_call_output_item'), ToolCallOutputItem(agent=Agent(name='orchestrator_agent', instructions='You are a DoorDash Agent who decides which tools or assistants to call If asked for prices or menu items, you call the relevant tools.if asked for info from. more than one source run multiple tools', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='in_n_out_burger_assistant', description='Get prices with tax for In-N-Out Burger', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'in_n_out_burger_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1590ea0>, strict_json_schema=True), FunctionTool(name='mcdonalds_assistant', description='Get prices for McDonalds', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'mcdonalds_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1525080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_sieCxHHI10ME6IWdCrGddscS', 'output': 'The Double Double® Animal Style includes a mustard-cooked beef patty, extra spread, pickles, and grilled onions. The base price for a Double Double® is $5.90. Would you like me to calculate the total with tax for you?', 'type': 'function_call_output'}, output='The Double Double® Animal Style includes a mustard-cooked beef patty, extra spread, pickles, and grilled onions. The base price for a Double Double® is $5.90. Would you like me to calculate the total with tax for you?', type='tool_call_output_item'), ToolCallItem(agent=Agent(name='orchestrator_agent', instructions='You are a DoorDash Agent who decides which tools or assistants to call If asked for prices or menu items, you call the relevant tools.if asked for info from. more than one source run multiple tools', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='in_n_out_burger_assistant', description='Get prices with tax for In-N-Out Burger', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'in_n_out_burger_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1590ea0>, strict_json_schema=True), FunctionTool(name='mcdonalds_assistant', description='Get prices for McDonalds', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'mcdonalds_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1525080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"input\":\"Big Mac price\"}', call_id='call_0pgpU9lxW3NHLIPsJ2VdaTC8', name='mcdonalds_assistant', type='function_call', id='fc_67f83e4a429481919ae677f6d655eaa105f5889c5a98b6a8', status='completed'), type='tool_call_item'), ToolCallItem(agent=Agent(name='orchestrator_agent', instructions='You are a DoorDash Agent who decides which tools or assistants to call If asked for prices or menu items, you call the relevant tools.if asked for info from. more than one source run multiple tools', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='in_n_out_burger_assistant', description='Get prices with tax for In-N-Out Burger', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'in_n_out_burger_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1590ea0>, strict_json_schema=True), FunctionTool(name='mcdonalds_assistant', description='Get prices for McDonalds', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'mcdonalds_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1525080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"input\":\"Double Double Animal Style price with tax\"}', call_id='call_TihHAnux5U14safi5SvJeaSN', name='in_n_out_burger_assistant', type='function_call', id='fc_67f83e4a66288191bc25a1e01ada353905f5889c5a98b6a8', status='completed'), type='tool_call_item'), ToolCallOutputItem(agent=Agent(name='orchestrator_agent', instructions='You are a DoorDash Agent who decides which tools or assistants to call If asked for prices or menu items, you call the relevant tools.if asked for info from. more than one source run multiple tools', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='in_n_out_burger_assistant', description='Get prices with tax for In-N-Out Burger', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'in_n_out_burger_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1590ea0>, strict_json_schema=True), FunctionTool(name='mcdonalds_assistant', description='Get prices for McDonalds', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'mcdonalds_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1525080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_0pgpU9lxW3NHLIPsJ2VdaTC8', 'output': \"As of April 2025, the average price of a Big Mac in the United States is approximately $5.29, reflecting a 21% increase from $4.39 in 2019. ([cbsnews.com](https://www.cbsnews.com/news/mcdonalds-menu-price-hikes-fast-food/?utm_source=openai)) Prices can vary by location due to factors such as local operating costs and franchisee pricing decisions. For instance, in 2024, Hawaii had the highest average price at $6.75, while Mississippi offered the lowest at $4.75. ([mymcdonaldsmenuprices.com](https://mymcdonaldsmenuprices.com/how-much-does-a-big-mac-cost/?utm_source=openai)) It's important to note that these figures are averages, and actual prices may differ based on specific locations and current economic conditions. \", 'type': 'function_call_output'}, output=\"As of April 2025, the average price of a Big Mac in the United States is approximately $5.29, reflecting a 21% increase from $4.39 in 2019. ([cbsnews.com](https://www.cbsnews.com/news/mcdonalds-menu-price-hikes-fast-food/?utm_source=openai)) Prices can vary by location due to factors such as local operating costs and franchisee pricing decisions. For instance, in 2024, Hawaii had the highest average price at $6.75, while Mississippi offered the lowest at $4.75. ([mymcdonaldsmenuprices.com](https://mymcdonaldsmenuprices.com/how-much-does-a-big-mac-cost/?utm_source=openai)) It's important to note that these figures are averages, and actual prices may differ based on specific locations and current economic conditions. \", type='tool_call_output_item'), ToolCallOutputItem(agent=Agent(name='orchestrator_agent', instructions='You are a DoorDash Agent who decides which tools or assistants to call If asked for prices or menu items, you call the relevant tools.if asked for info from. more than one source run multiple tools', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='in_n_out_burger_assistant', description='Get prices with tax for In-N-Out Burger', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'in_n_out_burger_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1590ea0>, strict_json_schema=True), FunctionTool(name='mcdonalds_assistant', description='Get prices for McDonalds', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'mcdonalds_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1525080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_TihHAnux5U14safi5SvJeaSN', 'output': 'The price of a Double Double Animal Style with tax is $6.33.', 'type': 'function_call_output'}, output='The price of a Double Double Animal Style with tax is $6.33.', type='tool_call_output_item'), MessageOutputItem(agent=Agent(name='orchestrator_agent', instructions='You are a DoorDash Agent who decides which tools or assistants to call If asked for prices or menu items, you call the relevant tools.if asked for info from. more than one source run multiple tools', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='in_n_out_burger_assistant', description='Get prices with tax for In-N-Out Burger', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'in_n_out_burger_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1590ea0>, strict_json_schema=True), FunctionTool(name='mcdonalds_assistant', description='Get prices for McDonalds', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'mcdonalds_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1525080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='msg_67f83e4f5ed48191979e523989b5e5c505f5889c5a98b6a8', content=[ResponseOutputText(annotations=[], text=\"The Double Double Animal Style at In-N-Out costs $6.33 with tax, while the average price of a Big Mac at McDonald's is around $5.29. Therefore, the Big Mac is generally cheaper.\", type='output_text')], role='assistant', status='completed', type='message'), type='message_output_item')], raw_responses=[ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"input\":\"Big Mac\"}', call_id='call_hKLyrzpSmH8lVzJ6df5ZeJWQ', name='mcdonalds_assistant', type='function_call', id='fc_67f83e4753948191a3ba0d5042244cdf05f5889c5a98b6a8', status='completed'), ResponseFunctionToolCall(arguments='{\"input\":\"Double Double Animal Style\"}', call_id='call_sieCxHHI10ME6IWdCrGddscS', name='in_n_out_burger_assistant', type='function_call', id='fc_67f83e477f048191a424f82124b8637605f5889c5a98b6a8', status='completed')], usage=Usage(requests=1, input_tokens=0, output_tokens=0, total_tokens=0), referenceable_id='resp_67f83e4663e881918c79741a95851d0a05f5889c5a98b6a8'), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"input\":\"Big Mac price\"}', call_id='call_0pgpU9lxW3NHLIPsJ2VdaTC8', name='mcdonalds_assistant', type='function_call', id='fc_67f83e4a429481919ae677f6d655eaa105f5889c5a98b6a8', status='completed'), ResponseFunctionToolCall(arguments='{\"input\":\"Double Double Animal Style price with tax\"}', call_id='call_TihHAnux5U14safi5SvJeaSN', name='in_n_out_burger_assistant', type='function_call', id='fc_67f83e4a66288191bc25a1e01ada353905f5889c5a98b6a8', status='completed')], usage=Usage(requests=1, input_tokens=0, output_tokens=0, total_tokens=0), referenceable_id='resp_67f83e49740c81919d19dd33a4faf83c05f5889c5a98b6a8'), ModelResponse(output=[ResponseOutputMessage(id='msg_67f83e4f5ed48191979e523989b5e5c505f5889c5a98b6a8', content=[ResponseOutputText(annotations=[], text=\"The Double Double Animal Style at In-N-Out costs $6.33 with tax, while the average price of a Big Mac at McDonald's is around $5.29. Therefore, the Big Mac is generally cheaper.\", type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=609, output_tokens=46, total_tokens=655), referenceable_id='resp_67f83e4effc48191aa82193b3fb7fe2005f5889c5a98b6a8')], final_output=\"The Double Double Animal Style at In-N-Out costs $6.33 with tax, while the average price of a Big Mac at McDonald's is around $5.29. Therefore, the Big Mac is generally cheaper.\", input_guardrail_results=[], output_guardrail_results=[], _last_agent=Agent(name='orchestrator_agent', instructions='You are a DoorDash Agent who decides which tools or assistants to call If asked for prices or menu items, you call the relevant tools.if asked for info from. more than one source run multiple tools', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='in_n_out_burger_assistant', description='Get prices with tax for In-N-Out Burger', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'in_n_out_burger_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1590ea0>, strict_json_schema=True), FunctionTool(name='mcdonalds_assistant', description='Get prices for McDonalds', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'mcdonalds_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1525080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `agent.as_tool()` v.s. `handoffs`\n",
        "\n",
        "在 OpenAI Agents SDK 中，`agent.as_tool()` 和 `handoffs` 是兩種不同的代理（Agent）協作方式，各自適用於不同的場景。以下是它們的主要差異：\n",
        "\n",
        "---\n",
        "\n",
        "### 🔧 `agent.as_tool()`：將代理作為工具使用\n",
        "\n",
        "- **用途**將一個代理封裝為工具，使其他代理可以在其內部流程中調用它\n",
        "- **特點**：\n",
        "  -被調用的代理不會接管對話流程，而是執行特定任務後將結果返回給調用者\n",
        "  -適用於需要在主代理流程中嵌入特定功能的情境，例如計算、查詢等\n",
        "- **使用方式**：\n",
        "  -透過 `agent.as_tool()` 方法將代理轉換為工具\n",
        "  -在主代理的 `tools` 參數中加入該工具\n",
        "\n",
        "---\n",
        "\n",
        "### 🤝 `handoffs`：代理間的任務移交\n",
        "\n",
        "- **用途*：在代理之間移交對話控制權，讓專門的代理處理特定任。\n",
        "- **特點**：\n",
        "   被移交的代理接管對話流程，並根據其設計處理後續的對。\n",
        "   適用於需要根據用戶輸入動態決定由哪個代理處理的情境，例如語言識別後選擇相應語言的代。\n",
        "- **使用方式**：\n",
        "   在主代理的 `handoffs` 參數中指定可移交的代理列。\n",
        "   主代理根據對話內容決定是否進行移。\n",
        "\n",
        "---\n",
        "\n",
        "### 🆚 比較總結\n",
        "\n",
        "| 特性             | `agent.as_tool()`                           | `handoffs`                                 |\n",
        "|------------------|---------------------------------------------|--------------------------------------------|\n",
        "| 控制權          | 主代理保留制權                        | 控制權移交給被指定代理               |\n",
        "| 適用場景        | 嵌入特定功能或工調用                  | 根據對話內容動態選擇處代理           |\n",
        "| 對話歷史        | 被調用代理不接收完整對歷史            | 被移交代理接收完整對歷史             |\n",
        "| 使用方式        | 將代理轉換為工具並加入主代理的工列表  | 在主代理中指定可移交的代列表         |\n",
        "\n",
        "---\n",
        "\n",
        "### 📝 實際應用建議\n",
        "- 當需要在主代理流程中調用特定功能時，使用 `agent.as_tool()` 是較為合適選擇。\n",
        "- 當需要根據用戶輸入動態選擇處理代理，並讓其接管對話流程時，使用 `handoffs` 更適宜。\n",
        "\n",
        "這兩種方式可以根據實際需求靈活選擇，甚至在同一應用中結合使用，以實現更複雜的代理協流程。"
      ],
      "metadata": {
        "id": "5ADqsDCqe8nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Giving it a Chat Memory"
      ],
      "metadata": {
        "id": "7Rskid9Ts688"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = Agent(name=\"In-N-Out Cashier Assistant\",\n",
        "              instructions=f\"You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n{MENU_PRICES}\",\n",
        "              model=\"gpt-4o\",\n",
        "              tools=[calculate_tax]\n",
        "              )"
      ],
      "metadata": {
        "id": "iFPyTUC-s5pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(agent, \"ok first let me order a Double Doubles with french fries.\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGkMS5UQtCu1",
        "outputId": "e37b6858-0c56-4370-94fa-017e7aac1954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Would you like to make it a Combo for $10.45, or get the Double Double® and French Fries separately for a total of $8.20?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.to_input_list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5vwDde7tGb3",
        "outputId": "c87d7455-eb7b-4c9f-eb72-fcc49c1db10c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'content': 'ok first let me order a Double Doubles with french fries.',\n",
              "  'role': 'user'},\n",
              " {'id': 'msg_67f83e8a77ec819182c4e9dc0f9b41300db1a0ca547b7298',\n",
              "  'content': [{'annotations': [],\n",
              "    'text': 'Would you like to make it a Combo for $10.45, or get the Double Double® and French Fries separately for a total of $8.20?',\n",
              "    'type': 'output_text'}],\n",
              "  'role': 'assistant',\n",
              "  'status': 'completed',\n",
              "  'type': 'message'}]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### to_input_list()\n",
        "\n",
        "在 OpenAI Agents SDK 中，`result.to_input_list()` 方法的命名和功能設計，旨在簡化多輪對話的上下文管理。\n",
        "\n",
        "---\n",
        "\n",
        "### 🔄 `to_input_list()` 的命名含義\n",
        "`to_input_list()` 的命名直觀地表明其功能：將代理運行的結果轉換為一個輸入列表這個列表包括：\n",
        "\n",
        "1.原始的用戶輸入\n",
        "2.代理在運行過程中生成的所有新項目（如模型回應、工具調用、交接等）\n",
        "這樣的設計使得開發者能夠輕鬆地將一次代理運行的上下文作為下一次運行的輸入，實現對話的連貫性\n",
        "\n",
        "---\n",
        "\n",
        "### 🧠 為何需要 `to_input_list()`\n",
        "在多輪對話中，保持上下文的一致性至關重`to_input_list()` 方法提供了一種簡便的方式，將之前的對話歷史和代理生成的內容組合成新的輸入，供下一輪使。這避免了手動管理對話歷史的繁瑣，提高了開發效率。\n",
        "\n",
        "---\n",
        "\n",
        "### 🧩 與其他方法的關系\n",
        "\n",
        "`to_input_list()` 是 `RunResultBase` 類中的一個方法，該類是代理運行結果的。這意味著無論是同步運行還是異步運行的結果，都可以使用此方法來獲取新的輸入表。\n",
        "\n"
      ],
      "metadata": {
        "id": "xBVJkC19djV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assemble_conversation(result, new_input):\n",
        "    if result !=None:\n",
        "        new_input = result.to_input_list() + [{'content': new_input,\n",
        "                                                'role': 'user'}]\n",
        "    else:\n",
        "        new_input = new_input\n",
        "    return new_input"
      ],
      "metadata": {
        "id": "fn55qAtztLyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_prompt = \"Yes make it a combo please\""
      ],
      "metadata": {
        "id": "eScfQfXmtOqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_input = assemble_conversation(result, new_prompt)\n",
        "\n",
        "result = await Runner.run(agent, new_input)\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElrDcT5XtSLl",
        "outputId": "0115da20-0e84-4d18-f119-4c77752eaaa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[debug] calculating tax function called order:10.45 tax:7.25\n",
            "Your Double Double® Combo comes to $10.45, and with tax, the total is $11.21. Would you like to add anything else to your order?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_prompt = \"Yes can I get a coffee as well. thats all\" #coffee $1.35"
      ],
      "metadata": {
        "id": "0bAsBBmdtVsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_input = assemble_conversation(result, new_prompt)\n",
        "\n",
        "result = await Runner.run(agent, new_input)\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW9rCEU_tZid",
        "outputId": "d75e699f-1275-47d7-b2fb-7f8c79a10323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[debug] calculating tax function called order:1.35 tax:7.25\n",
            "The coffee is $1.35, and with tax, the total is $1.45.\n",
            "\n",
            "Your new order total, including the combo and coffee, is $12.66. Would you like to proceed with this order?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI’s BRAND NEW Agents SDK (Crash Course)\n",
        "\n",
        "OpenAI’s BRAND NEW Agents SDK (Crash Course) https://www.youtube.com/watch?v=e7qvd2bOITc\n",
        "  - https://github.com/coleam00/ottomator-agents/tree/main/openai-sdk-agent\n",
        "  - https://github.com/openai/openai-agents-python/tree/main\n",
        "  - https://openai.github.io/openai-agents-python/"
      ],
      "metadata": {
        "id": "MiIuxRxn0N55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Core concepts:\n",
        "\n",
        "1. [**Agents**](https://openai.github.io/openai-agents-python/agents): LLMs configured with instructions, tools, guardrails, and handoffs\n",
        "2. [**Handoffs**](https://openai.github.io/openai-agents-python/handoffs/): A specialized tool call used by the Agents SDK for transferring control between agents\n",
        "3. [**Guardrails**](https://openai.github.io/openai-agents-python/guardrails/): Configurable safety checks for input and output validation\n",
        "4. [**Tracing**](https://openai.github.io/openai-agents-python/tracing/): Built-in tracking of agent runs, allowing you to view, debug and optimize your workflows\n",
        "\n",
        "Explore the [examples](examples) directory to see the SDK in action, and read our [documentation](https://openai.github.io/openai-agents-python/) for more details.\n",
        "\n",
        "Notably, our SDK [is compatible](https://openai.github.io/openai-agents-python/models/) with any model providers that support the OpenAI Chat Completions API format."
      ],
      "metadata": {
        "id": "Ot9P4ekV050G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project Structure\n",
        "\n",
        "- `v1_basic_agent.py` - A simple agent example that generates a haiku about recursion\n",
        "- `v2_structured_output.py` - Travel agent with structured output using Pydantic models\n",
        "- `v3_tool_calls.py` - Travel agent with tool calls for weather forecasting\n",
        "- `v4_handoffs.py` - Travel agent with specialized sub-agents for flights and hotels\n",
        "- `v5_guardrails_and_context.py` - Travel agent with budget guardrails and user context\n",
        "- `v6_streamlit_agent.py` - A Streamlit web interface for the travel agent with chat memory"
      ],
      "metadata": {
        "id": "yC97bBKd1ysm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install openai-agents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a7ecd6-e3f5-4401-dbaf-8365174bacab",
        "id": "xn9iODB75JXl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/107.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/129.2 kB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.2/129.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "\n",
        "# Verify that the key is set\n",
        "print(f\"OpenAI API key set: {bool(openai_api_key)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5182c47-3ff3-4039-dbd9-08a60b63c558",
        "id": "LG3ibufL5JXl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API key set: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### v1_basic_agent"
      ],
      "metadata": {
        "id": "UUJMnuTh5XGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=\"You are a helpful assistant\",\n",
        "    model=\"gpt-4o-mini\"\n",
        ")\n",
        "\n",
        "result = Runner.run_sync(agent, \"Write a haiku about recursion in programming.\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M9PrPs_tcSt",
        "outputId": "031d7c49-c01c-4ba9-dfbf-86084fd8d67b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code calls back to itself,  \n",
            "Layers deep, a loop unfolds,  \n",
            "Endless paths converge.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### v2_structured_output"
      ],
      "metadata": {
        "id": "Dh2yVGeY5bof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "2H1-tvj56pZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from typing import List\n",
        "from pydantic import BaseModel, Field\n",
        "from agents import Agent, Runner\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "model = os.getenv('MODEL_CHOICE', 'gpt-4o-mini')\n",
        "\n",
        "# --- Models for structured outputs ---\n",
        "\n",
        "class TravelPlan(BaseModel):\n",
        "    destination: str\n",
        "    duration_days: int\n",
        "    budget: float\n",
        "    activities: List[str] = Field(description=\"List of recommended activities\")\n",
        "    notes: str = Field(description=\"Additional notes or recommendations\")\n",
        "\n",
        "# --- Main Travel Agent ---\n",
        "\n",
        "travel_agent = Agent(\n",
        "    name=\"Travel Planner\",\n",
        "    instructions=\"\"\"\n",
        "    You are a comprehensive travel planning assistant that helps users plan their perfect trip.\n",
        "\n",
        "    You can create personalized travel itineraries based on the user's interests and preferences.\n",
        "\n",
        "    Always be helpful, informative, and enthusiastic about travel. Provide specific recommendations\n",
        "    based on the user's interests and preferences.\n",
        "\n",
        "    When creating travel plans, consider:\n",
        "    - Local attractions and activities\n",
        "    - Budget constraints\n",
        "    - Travel duration\n",
        "    \"\"\",\n",
        "    model=model,\n",
        "    output_type=TravelPlan\n",
        ")\n",
        "\n",
        "# --- Main Function ---\n",
        "\n",
        "async def main():\n",
        "    # Example queries to test the system\n",
        "    queries = [\n",
        "        \"I'm planning a trip to Miami for 5 days with a budget of $2000. What should I do there?\",\n",
        "        \"I want to visit Tokyo for a week with a budget of $3000. What activities do you recommend?\"\n",
        "    ]\n",
        "\n",
        "    for query in queries:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"QUERY: {query}\")\n",
        "\n",
        "        result = await Runner.run(travel_agent, query)\n",
        "\n",
        "        print(\"\\nFINAL RESPONSE:\")\n",
        "        travel_plan = result.final_output\n",
        "\n",
        "        # Format the output in a nicer way\n",
        "        print(f\"\\n🌍 TRAVEL PLAN FOR {travel_plan.destination.upper()} 🌍\")\n",
        "        print(f\"Duration: {travel_plan.duration_days} days\")\n",
        "        print(f\"Budget: ${travel_plan.budget}\")\n",
        "\n",
        "        print(\"\\n🎯 RECOMMENDED ACTIVITIES:\")\n",
        "        for i, activity in enumerate(travel_plan.activities, 1):\n",
        "            print(f\"  {i}. {activity}\")\n",
        "\n",
        "        print(f\"\\n📝 NOTES: {travel_plan.notes}\")\\\n",
        "\n",
        "'''\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n",
        "'''\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE0GAuLs50E0",
        "outputId": "579a3c90-291d-438d-e2cd-abad02db07bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "QUERY: I'm planning a trip to Miami for 5 days with a budget of $2000. What should I do there?\n",
            "\n",
            "FINAL RESPONSE:\n",
            "\n",
            "🌍 TRAVEL PLAN FOR MIAMI, FLORIDA 🌍\n",
            "Duration: 5 days\n",
            "Budget: $2000.0\n",
            "\n",
            "🎯 RECOMMENDED ACTIVITIES:\n",
            "  1. Visit South Beach and relax on the iconic sandy shores\n",
            "  2. Explore the vibrant Art Deco Historic District\n",
            "  3. Take a stroll through the colorful Wynwood Walls\n",
            "  4. Enjoy a day at the Miami Seaquarium\n",
            "  5. Visit Little Havana for a taste of Cuban culture and cuisine\n",
            "  6. Take a boat tour of Biscayne Bay to see the luxurious islands\n",
            "  7. Explore the shops and cafes at Lincoln Road Mall\n",
            "  8. Visit the Pérez Art Museum Miami (PAMM) for contemporary art\n",
            "\n",
            "📝 NOTES: Consider dining at local food trucks or casual eateries to save on meals while enjoying authentic flavors. Check out happy hour specials for drinks and snacks. Make sure to pack sunscreen!\n",
            "\n",
            "==================================================\n",
            "QUERY: I want to visit Tokyo for a week with a budget of $3000. What activities do you recommend?\n",
            "\n",
            "FINAL RESPONSE:\n",
            "\n",
            "🌍 TRAVEL PLAN FOR TOKYO, JAPAN 🌍\n",
            "Duration: 7 days\n",
            "Budget: $3000.0\n",
            "\n",
            "🎯 RECOMMENDED ACTIVITIES:\n",
            "  1. Visit the historic Senso-ji Temple in Asakusa\n",
            "  2. Explore the bustling streets of Shibuya and take a photo at the famous Shibuya Crossing\n",
            "  3. Experience the vibrant Harajuku district and shop on Takeshita Street\n",
            "  4. Visit the Tokyo Skytree for panoramic views of the city\n",
            "  5. Spend a day in Akihabara, the center of otaku culture and electronics\n",
            "  6. Take a walk in Ueno Park and visit its museums, including the Tokyo National Museum\n",
            "  7. Explore the tranquil Meiji Shrine\n",
            "  8. Enjoy a sushi-making class or a local izakaya dining experience\n",
            "  9. Take a day trip to Nikko or Mount Fuji\n",
            "  10. Visit the teamLab Borderless digital art museum in Odaiba\n",
            "\n",
            "📝 NOTES: Consider purchasing a Japan Rail Pass for convenient travel. Don't forget to try local delicacies like ramen, sushi, and street food. Check for any cultural festivals or events during your visit!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### pydantic\n",
        "\n",
        "`TravelPlan` 類別繼承自 `pydantic.BaseModel`，這使得它成為一個結構化資料模型，能夠自動驗證和解析資料。\n",
        "\n",
        "使用 Pydantic 定義的模型可以確保資料的完整性和正確性，特別是在與大型語言模型（LLM）互動時，能夠將非結構化的輸出轉換為結構化的資料格式。https://www.youtube.com/watch?v=pZ4DIH2BVqg\n",
        "\n",
        "例如，當您使用 OpenAI 的 API 並指定 `response_model=TravelPlan` 時，返回的資料將自動被解析為 `TravelPlan` 的實例，並進行類型驗證。\n",
        "\n",
        "這種方式的優點包括：\n",
        "\n",
        "- **類型安全**：確保每個欄位的資料類型正確，否則會引發錯誤。\n",
        "- **資料驗證**：可以設置欄位的約束條件，例如數值範圍、字串格式等。\n",
        "- **易於整合**：結構化的資料更容易與其他系統或資料庫整合。\n",
        "\n",
        "總之，Pydantic 提供了一種強大且靈活的方式來處理和驗證資料，特別適合用於需要高可靠性和可維護性的應用場景。\n",
        "https://medium.com/%40bohachu/%E5%AB%8C%E6%A3%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9B%9E%E5%82%B3%E6%A0%BC%E5%BC%8F%E5%8F%AA%E6%9C%8980-%E6%A9%9F%E7%8E%87%E6%AD%A3%E7%A2%BA%E5%97%8E-python-instructor%E8%AE%93llm%E7%A9%A9%E5%AE%9A%E5%9B%9E%E5%82%B3pydantic%E7%B5%90%E6%A7%8B%E5%8C%96%E7%89%A9%E4%BB%B6-d5c4f7d909cc\n",
        "\n",
        "\n",
        "**我們在 Agent 定義了 output_type=TravelPlan  來限制輸出的格式**"
      ],
      "metadata": {
        "id": "hRQrQYDJILK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### v3_tool_calls"
      ],
      "metadata": {
        "id": "byMyfBLa7Ooh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "j6xDpYii7pz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import json\n",
        "from typing import List\n",
        "from pydantic import BaseModel, Field\n",
        "from agents import Agent, Runner, function_tool\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "model = os.getenv('MODEL_CHOICE', 'gpt-4o-mini')\n",
        "\n",
        "# --- Models for structured outputs ---\n",
        "\n",
        "class TravelPlan(BaseModel):\n",
        "    destination: str\n",
        "    duration_days: int\n",
        "    budget: float\n",
        "    activities: List[str] = Field(description=\"List of recommended activities\")\n",
        "    notes: str = Field(description=\"Additional notes or recommendations\")\n",
        "\n",
        "# --- Tools ---\n",
        "\n",
        "@function_tool\n",
        "def get_weather_forecast(city: str, date: str) -> str:\n",
        "    \"\"\"Get the weather forecast for a city on a specific date.\"\"\"\n",
        "    # In a real implementation, this would call a weather API\n",
        "    weather_data = {\n",
        "        \"New York\": {\"sunny\": 0.3, \"rainy\": 0.4, \"cloudy\": 0.3},\n",
        "        \"Los Angeles\": {\"sunny\": 0.8, \"rainy\": 0.1, \"cloudy\": 0.1},\n",
        "        \"Chicago\": {\"sunny\": 0.4, \"rainy\": 0.3, \"cloudy\": 0.3},\n",
        "        \"Miami\": {\"sunny\": 0.7, \"rainy\": 0.2, \"cloudy\": 0.1},\n",
        "        \"London\": {\"sunny\": 0.2, \"rainy\": 0.5, \"cloudy\": 0.3},\n",
        "        \"Paris\": {\"sunny\": 0.4, \"rainy\": 0.3, \"cloudy\": 0.3},\n",
        "        \"Tokyo\": {\"sunny\": 0.5, \"rainy\": 0.3, \"cloudy\": 0.2},\n",
        "    }\n",
        "\n",
        "    if city in weather_data:\n",
        "        conditions = weather_data[city]\n",
        "        # Simple simulation based on probabilities\n",
        "        highest_prob = max(conditions, key=conditions.get)\n",
        "        temp_range = {\n",
        "            \"New York\": \"15-25°C\",\n",
        "            \"Los Angeles\": \"20-30°C\",\n",
        "            \"Chicago\": \"10-20°C\",\n",
        "            \"Miami\": \"25-35°C\",\n",
        "            \"London\": \"10-18°C\",\n",
        "            \"Paris\": \"12-22°C\",\n",
        "            \"Tokyo\": \"15-25°C\",\n",
        "        }\n",
        "        return f\"The weather in {city} on {date} is forecasted to be {highest_prob} with temperatures around {temp_range.get(city, '15-25°C')}.\"\n",
        "    else:\n",
        "        return f\"Weather forecast for {city} is not available.\"\n",
        "\n",
        "# --- Main Travel Agent ---\n",
        "\n",
        "travel_agent = Agent(\n",
        "    name=\"Travel Planner\",\n",
        "    instructions=\"\"\"\n",
        "    You are a comprehensive travel planning assistant that helps users plan their perfect trip.\n",
        "\n",
        "    You can:\n",
        "    1. Provide weather information for destinations\n",
        "    2. Create personalized travel itineraries\n",
        "\n",
        "    Always be helpful, informative, and enthusiastic about travel. Provide specific recommendations\n",
        "    based on the user's interests and preferences.\n",
        "\n",
        "    When creating travel plans, consider:\n",
        "    - The weather at the destination\n",
        "    - Local attractions and activities\n",
        "    - Budget constraints\n",
        "    - Travel duration\n",
        "    \"\"\",\n",
        "    model=model,\n",
        "    tools=[get_weather_forecast],\n",
        "    output_type=TravelPlan\n",
        ")\n",
        "\n",
        "# --- Main Function ---\n",
        "\n",
        "async def main():\n",
        "    # Example queries to test the system\n",
        "    queries = [\n",
        "        \"I'm planning a trip to Miami for 5 days with a budget of $2000. What should I do there and what is the weather going to look like?\",\n",
        "        \"I want to visit Paris for a week with a budget of $3000. What activities do you recommend based on the weather?\"\n",
        "    ]\n",
        "\n",
        "    for query in queries:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"QUERY: {query}\")\n",
        "\n",
        "        result = await Runner.run(travel_agent, query)\n",
        "\n",
        "        print(\"\\nFINAL RESPONSE:\")\n",
        "        travel_plan = result.final_output\n",
        "\n",
        "        # Format the output in a nicer way\n",
        "        print(f\"\\n🌍 TRAVEL PLAN FOR {travel_plan.destination.upper()} 🌍\")\n",
        "        print(f\"Duration: {travel_plan.duration_days} days\")\n",
        "        print(f\"Budget: ${travel_plan.budget}\")\n",
        "\n",
        "        print(\"\\n🎯 RECOMMENDED ACTIVITIES:\")\n",
        "        for i, activity in enumerate(travel_plan.activities, 1):\n",
        "            print(f\"  {i}. {activity}\")\n",
        "\n",
        "        print(f\"\\n📝 NOTES: {travel_plan.notes}\")\n",
        "\n",
        "'''\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n",
        "'''\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CmJte8F7Tir",
        "outputId": "783609b1-e8b8-4199-b839-7c614e661fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "QUERY: I'm planning a trip to Miami for 5 days with a budget of $2000. What should I do there and what is the weather going to look like?\n",
            "\n",
            "FINAL RESPONSE:\n",
            "\n",
            "🌍 TRAVEL PLAN FOR MIAMI 🌍\n",
            "Duration: 5 days\n",
            "Budget: $2000.0\n",
            "\n",
            "🎯 RECOMMENDED ACTIVITIES:\n",
            "  1. Relax on South Beach\n",
            "  2. Visit the Art Deco Historic District\n",
            "  3. Explore Little Havana and try Cuban cuisine\n",
            "  4. Take a boat tour of Biscayne Bay\n",
            "  5. Spend a day at the Vizcaya Museum and Gardens\n",
            "  6. Enjoy nightlife at Ocean Drive\n",
            "  7. Visit the Miami Seaquarium\n",
            "\n",
            "📝 NOTES: The weather will be sunny with temperatures ranging from 25-35°C throughout your trip. Pack light, breathable clothing and sunscreen. Consider renting a bike for easy transportation around the beach and city!\n",
            "\n",
            "==================================================\n",
            "QUERY: I want to visit Paris for a week with a budget of $3000. What activities do you recommend based on the weather?\n",
            "\n",
            "FINAL RESPONSE:\n",
            "\n",
            "🌍 TRAVEL PLAN FOR PARIS 🌍\n",
            "Duration: 7 days\n",
            "Budget: $3000.0\n",
            "\n",
            "🎯 RECOMMENDED ACTIVITIES:\n",
            "  1. Visit the Eiffel Tower and enjoy the views from the top\n",
            "  2. Explore the Louvre Museum to see the Mona Lisa\n",
            "  3. Take a Seine River cruise for a scenic view of the city\n",
            "  4. Stroll through Montmartre and visit the Sacré-Cœur Basilica\n",
            "  5. Enjoy a picnic in Luxembourg Gardens\n",
            "  6. Sample pastries at a local patisserie\n",
            "  7. Explore the vibrant streets of Le Marais district\n",
            "  8. Take a day trip to Versailles to see the grand palace and gardens\n",
            "\n",
            "📝 NOTES: The weather in Paris for your visit will be sunny with mild temperatures ranging from 12-22°C, perfect for outdoor activities!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### V3 function\n",
        "\n",
        "### 🧭 功能概述\n",
        "\n",
        "- **代理（Agent）設定**定義了一個名為「Travel Planner」的代理，具備提供天氣資訊和個人化旅遊行程的能力\n",
        "\n",
        "- **工具整合**透過 `@function_tool` 裝飾器，將 `get_weather_forecast` 函式註冊為代理可用的工具，模擬提供特定城市和日期的天氣預報\n",
        "\n",
        "- **結構化輸出**使用 Pydantic 的 `TravelPlan` 模型，確保代理的輸出符合預定的結構，包括目的地、旅遊天數、預算、建議活動和備註\n",
        "\n",
        "- **非同步執行**在 `main` 函式中，透過非同步方式執行代理，處理多個查詢，並格式化輸出結果"
      ],
      "metadata": {
        "id": "p5uk6HYQF9Sw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `get_weather_forecast` `@function_tool`\n",
        "\n",
        "`@function_tool` 是 OpenAI Agents SDK 提供的裝飾器，用於將普通的 Python 函式轉換為代理可用的工具。它會自動解析函式的簽名和文檔字串（docstring），生成對應的 JSON 架構，供代理在需要時呼叫。\n",
        "\n",
        "以下是對程式碼的逐行解釋：\n",
        "\n",
        "```python\n",
        "@function_tool\n",
        "def get_weather_forecast(city: str, date: str) -> str:\n",
        "    \"\"\"Get the weather forecast for a city on a specific date.\"\"\"\n",
        "```\n",
        "\n",
        "- 這段定義了一個名為 `get_weather_forecast` 的函式，接受兩個參數：`city`（城市名稱）和 `date`（日期），並返回一個字串。\n",
        "- **函式的文檔字串提供了對函式功能的簡要說明，這些資訊會被 `@function_tool` 用來生成工具的描述。**\n",
        "\n",
        "```python\n",
        "    # In a real implementation, this would call a weather API\n",
        "    weather_data = {\n",
        "        \"New York\": {\"sunny\": 0.3, \"rainy\": 0.4, \"cloudy\": 0.3},\n",
        "        \"Tokyo\": {\"sunny\": 0.5, \"rainy\": 0.3, \"cloudy\": 0.2},\n",
        "    }\n",
        "```\n",
        "\n",
        "- 這是一個模擬的天氣資料字典，包含了多個城市及其對應的天氣狀況機率分佈。\n",
        "- 在實際應用中，這部分應該是呼叫外部的天氣 API 來獲取即時的天氣資訊。\n",
        "\n",
        "```python\n",
        "    if city in weather_data:\n",
        "        conditions = weather_data[city]\n",
        "        # Simple simulation based on probabilities\n",
        "        highest_prob = max(conditions, key=conditions.get)\n",
        "        temp_range = {\n",
        "            \"New York\": \"15-25°C\",\n",
        "            \"Tokyo\": \"15-25°C\",\n",
        "        }\n",
        "        return f\"The weather in {city} on {date} is forecasted to be {highest_prob} with temperatures around {temp_range.get(city, '15-25°C')}.\"\n",
        "    else:\n",
        "        return f\"Weather forecast for {city} is not available.\"\n",
        "```\n",
        "\n",
        "- 這部分程式碼首先檢查所提供的城市是否在 `weather_data` 中。\n",
        "- 如果存在，則根據天氣狀況的機率分佈，選擇機率最高的天氣狀況作為預報結果。\n",
        "- 然後，從 `temp_range` 字典中取得對應城市的溫度範圍，並組合成一個完整的天氣預報字串返回。\n",
        "- 如果城市不在 `weather_data` 中，則返回一個表示無法提供該城市天氣預報的訊息。\n",
        "\n",
        "透過這樣的設計，代理在處理與天氣相關的查詢時，可以呼叫 `get_weather_forecast` 工具，並根據使用者提供的城市和日期，返回對應的天氣預報資訊。"
      ],
      "metadata": {
        "id": "pgYF9fNFGxs3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### v4_handoffs"
      ],
      "metadata": {
        "id": "wo41FGl-7zJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "pxihh0AO8PjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import json\n",
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "from agents import Agent, Runner, function_tool\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "model = os.getenv('MODEL_CHOICE', 'gpt-4o-mini')\n",
        "\n",
        "# --- Models for structured outputs ---\n",
        "\n",
        "class FlightRecommendation(BaseModel):\n",
        "    airline: str\n",
        "    departure_time: str\n",
        "    arrival_time: str\n",
        "    price: float\n",
        "    direct_flight: bool\n",
        "    recommendation_reason: str\n",
        "\n",
        "class HotelRecommendation(BaseModel):\n",
        "    name: str\n",
        "    location: str\n",
        "    price_per_night: float\n",
        "    amenities: List[str]\n",
        "    recommendation_reason: str\n",
        "\n",
        "class TravelPlan(BaseModel):\n",
        "    destination: str\n",
        "    duration_days: int\n",
        "    budget: float\n",
        "    activities: List[str] = Field(description=\"List of recommended activities\")\n",
        "    notes: str = Field(description=\"Additional notes or recommendations\")\n",
        "\n",
        "# --- Tools ---\n",
        "\n",
        "@function_tool\n",
        "def get_weather_forecast(city: str, date: str) -> str:\n",
        "    \"\"\"Get the weather forecast for a city on a specific date.\"\"\"\n",
        "    # In a real implementation, this would call a weather API\n",
        "    weather_data = {\n",
        "        \"New York\": {\"sunny\": 0.3, \"rainy\": 0.4, \"cloudy\": 0.3},\n",
        "        \"Los Angeles\": {\"sunny\": 0.8, \"rainy\": 0.1, \"cloudy\": 0.1},\n",
        "        \"Chicago\": {\"sunny\": 0.4, \"rainy\": 0.3, \"cloudy\": 0.3},\n",
        "        \"Miami\": {\"sunny\": 0.7, \"rainy\": 0.2, \"cloudy\": 0.1},\n",
        "        \"London\": {\"sunny\": 0.2, \"rainy\": 0.5, \"cloudy\": 0.3},\n",
        "        \"Paris\": {\"sunny\": 0.4, \"rainy\": 0.3, \"cloudy\": 0.3},\n",
        "        \"Tokyo\": {\"sunny\": 0.5, \"rainy\": 0.3, \"cloudy\": 0.2},\n",
        "    }\n",
        "\n",
        "    if city in weather_data:\n",
        "        conditions = weather_data[city]\n",
        "        # Simple simulation based on probabilities\n",
        "        highest_prob = max(conditions, key=conditions.get)\n",
        "        temp_range = {\n",
        "            \"New York\": \"15-25°C\",\n",
        "            \"Los Angeles\": \"20-30°C\",\n",
        "            \"Chicago\": \"10-20°C\",\n",
        "            \"Miami\": \"25-35°C\",\n",
        "            \"London\": \"10-18°C\",\n",
        "            \"Paris\": \"12-22°C\",\n",
        "            \"Tokyo\": \"15-25°C\",\n",
        "        }\n",
        "        return f\"The weather in {city} on {date} is forecasted to be {highest_prob} with temperatures around {temp_range.get(city, '15-25°C')}.\"\n",
        "    else:\n",
        "        return f\"Weather forecast for {city} is not available.\"\n",
        "\n",
        "@function_tool\n",
        "def search_flights(origin: str, destination: str, date: str) -> str:\n",
        "    \"\"\"Search for flights between two cities on a specific date.\"\"\"\n",
        "    # In a real implementation, this would call a flight search API\n",
        "    flight_options = [\n",
        "        {\n",
        "            \"airline\": \"SkyWays\",\n",
        "            \"departure_time\": \"08:00\",\n",
        "            \"arrival_time\": \"10:30\",\n",
        "            \"price\": 350.00,\n",
        "            \"direct\": True\n",
        "        },\n",
        "        {\n",
        "            \"airline\": \"OceanAir\",\n",
        "            \"departure_time\": \"12:45\",\n",
        "            \"arrival_time\": \"15:15\",\n",
        "            \"price\": 275.50,\n",
        "            \"direct\": True\n",
        "        },\n",
        "        {\n",
        "            \"airline\": \"MountainJet\",\n",
        "            \"departure_time\": \"16:30\",\n",
        "            \"arrival_time\": \"21:45\",\n",
        "            \"price\": 225.75,\n",
        "            \"direct\": False\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    return json.dumps(flight_options)\n",
        "\n",
        "@function_tool\n",
        "def search_hotels(city: str, check_in: str, check_out: str, max_price: Optional[float] = None) -> str:\n",
        "    \"\"\"Search for hotels in a city for specific dates within a price range.\"\"\"\n",
        "    # In a real implementation, this would call a hotel search API\n",
        "    hotel_options = [\n",
        "        {\n",
        "            \"name\": \"City Center Hotel\",\n",
        "            \"location\": \"Downtown\",\n",
        "            \"price_per_night\": 199.99,\n",
        "            \"amenities\": [\"WiFi\", \"Pool\", \"Gym\", \"Restaurant\"]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Riverside Inn\",\n",
        "            \"location\": \"Riverside District\",\n",
        "            \"price_per_night\": 149.50,\n",
        "            \"amenities\": [\"WiFi\", \"Free Breakfast\", \"Parking\"]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Luxury Palace\",\n",
        "            \"location\": \"Historic District\",\n",
        "            \"price_per_night\": 349.99,\n",
        "            \"amenities\": [\"WiFi\", \"Pool\", \"Spa\", \"Fine Dining\", \"Concierge\"]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Filter by max price if provided\n",
        "    if max_price is not None:\n",
        "        filtered_hotels = [hotel for hotel in hotel_options if hotel[\"price_per_night\"] <= max_price]\n",
        "    else:\n",
        "        filtered_hotels = hotel_options\n",
        "\n",
        "    return json.dumps(filtered_hotels)\n",
        "\n",
        "# --- Specialized Agents ---\n",
        "\n",
        "flight_agent = Agent(\n",
        "    name=\"Flight Specialist\",\n",
        "    handoff_description=\"Specialist agent for finding and recommending flights\",\n",
        "    instructions=\"\"\"\n",
        "    You are a flight specialist who helps users find the best flights for their trips.\n",
        "\n",
        "    Use the search_flights tool to find flight options, and then provide personalized recommendations\n",
        "    based on the user's preferences (price, time, direct vs. connecting).\n",
        "\n",
        "    Always explain the reasoning behind your recommendations.\n",
        "\n",
        "    Format your response in a clear, organized way with flight details and prices.\n",
        "    \"\"\",\n",
        "    model=model,\n",
        "    tools=[search_flights],\n",
        "    output_type=FlightRecommendation\n",
        ")\n",
        "\n",
        "hotel_agent = Agent(\n",
        "    name=\"Hotel Specialist\",\n",
        "    handoff_description=\"Specialist agent for finding and recommending hotels and accommodations\",\n",
        "    instructions=\"\"\"\n",
        "    You are a hotel specialist who helps users find the best accommodations for their trips.\n",
        "\n",
        "    Use the search_hotels tool to find hotel options, and then provide personalized recommendations\n",
        "    based on the user's preferences (location, price, amenities).\n",
        "\n",
        "    Always explain the reasoning behind your recommendations.\n",
        "\n",
        "    Format your response in a clear, organized way with hotel details, amenities, and prices.\n",
        "    \"\"\",\n",
        "    model=model,\n",
        "    tools=[search_hotels],\n",
        "    output_type=HotelRecommendation\n",
        ")\n",
        "\n",
        "# --- Main Travel Agent ---\n",
        "\n",
        "travel_agent = Agent(\n",
        "    name=\"Travel Planner\",\n",
        "    instructions=\"\"\"\n",
        "    You are a comprehensive travel planning assistant that helps users plan their perfect trip.\n",
        "\n",
        "    You can:\n",
        "    1. Provide weather information for destinations\n",
        "    2. Create personalized travel itineraries\n",
        "    3. Hand off to specialists for flights and hotels when needed\n",
        "\n",
        "    Always be helpful, informative, and enthusiastic about travel. Provide specific recommendations\n",
        "    based on the user's interests and preferences.\n",
        "\n",
        "    When creating travel plans, consider:\n",
        "    - The weather at the destination\n",
        "    - Local attractions and activities\n",
        "    - Budget constraints\n",
        "    - Travel duration\n",
        "\n",
        "    If the user asks specifically about flights or hotels, hand off to the appropriate specialist agent.\n",
        "    \"\"\",\n",
        "    model=model,\n",
        "    tools=[get_weather_forecast],\n",
        "    handoffs=[flight_agent, hotel_agent],\n",
        "    output_type=TravelPlan\n",
        ")\n",
        "\n",
        "# --- Main Function ---\n",
        "\n",
        "async def main():\n",
        "    # Example queries to test different aspects of the system\n",
        "    queries = [\n",
        "        \"I need a flight from New York to Chicago tomorrow\",\n",
        "        \"Find me a hotel in Paris with a pool for under $300 per night\"\n",
        "    ]\n",
        "\n",
        "    for query in queries:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"QUERY: {query}\")\n",
        "\n",
        "        result = await Runner.run(travel_agent, query)\n",
        "\n",
        "        print(\"\\nFINAL RESPONSE:\")\n",
        "\n",
        "        # Format the output based on the type of response\n",
        "        if hasattr(result.final_output, \"airline\"):  # Flight recommendation\n",
        "            flight = result.final_output\n",
        "            print(\"\\n✈️ FLIGHT RECOMMENDATION ✈️\")\n",
        "            print(f\"Airline: {flight.airline}\")\n",
        "            print(f\"Departure: {flight.departure_time}\")\n",
        "            print(f\"Arrival: {flight.arrival_time}\")\n",
        "            print(f\"Price: ${flight.price}\")\n",
        "            print(f\"Direct Flight: {'Yes' if flight.direct_flight else 'No'}\")\n",
        "            print(f\"\\nWhy this flight: {flight.recommendation_reason}\")\n",
        "\n",
        "        elif hasattr(result.final_output, \"name\") and hasattr(result.final_output, \"amenities\"):  # Hotel recommendation\n",
        "            hotel = result.final_output\n",
        "            print(\"\\n🏨 HOTEL RECOMMENDATION 🏨\")\n",
        "            print(f\"Name: {hotel.name}\")\n",
        "            print(f\"Location: {hotel.location}\")\n",
        "            print(f\"Price per night: ${hotel.price_per_night}\")\n",
        "\n",
        "            print(\"\\nAmenities:\")\n",
        "            for i, amenity in enumerate(hotel.amenities, 1):\n",
        "                print(f\"  {i}. {amenity}\")\n",
        "\n",
        "            print(f\"\\nWhy this hotel: {hotel.recommendation_reason}\")\n",
        "\n",
        "        elif hasattr(result.final_output, \"destination\"):  # Travel plan\n",
        "            travel_plan = result.final_output\n",
        "            print(f\"\\n🌍 TRAVEL PLAN FOR {travel_plan.destination.upper()} 🌍\")\n",
        "            print(f\"Duration: {travel_plan.duration_days} days\")\n",
        "            print(f\"Budget: ${travel_plan.budget}\")\n",
        "\n",
        "            print(\"\\n🎯 RECOMMENDED ACTIVITIES:\")\n",
        "            for i, activity in enumerate(travel_plan.activities, 1):\n",
        "                print(f\"  {i}. {activity}\")\n",
        "\n",
        "            print(f\"\\n📝 NOTES: {travel_plan.notes}\")\n",
        "\n",
        "        else:  # Generic response\n",
        "            print(result.final_output)\n",
        "\n",
        "'''\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n",
        "'''\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "id": "vwjSyqvS74hA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f593c33-d386-4f3d-d4d4-13ae885d192d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "QUERY: I need a flight from New York to Chicago tomorrow\n",
            "\n",
            "FINAL RESPONSE:\n",
            "\n",
            "✈️ FLIGHT RECOMMENDATION ✈️\n",
            "Airline: OceanAir\n",
            "Departure: 12:45\n",
            "Arrival: 15:15\n",
            "Price: $275.5\n",
            "Direct Flight: Yes\n",
            "\n",
            "Why this flight: This flight is the most affordable direct option, with a reasonable departure time and a convenient arrival time.\n",
            "\n",
            "==================================================\n",
            "QUERY: Find me a hotel in Paris with a pool for under $300 per night\n",
            "\n",
            "FINAL RESPONSE:\n",
            "\n",
            "🏨 HOTEL RECOMMENDATION 🏨\n",
            "Name: City Center Hotel\n",
            "Location: Downtown\n",
            "Price per night: $199.99\n",
            "\n",
            "Amenities:\n",
            "  1. WiFi\n",
            "  2. Pool\n",
            "  3. Gym\n",
            "  4. Restaurant\n",
            "\n",
            "Why this hotel: The City Center Hotel is a great option as it offers a pool and is centrally located, making it easy to explore Paris. Priced at $199.99 per night, it fits well within your budget while also providing additional amenities such as a gym and restaurant.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Handoff\n",
        "\n",
        "```python\n",
        "\n",
        "travel_agent = Agent(\n",
        "    name=\"Travel Planner\",\n",
        "    instructions=\"\"\"\n",
        "    You are a comprehensive travel planning assistant that helps users plan their perfect trip.\n",
        "\n",
        "    You can:\n",
        "\n",
        "    3. Hand off to specialists for flights and hotels when needed\n",
        "    \"\"\",\n",
        "\n",
        "    model=model,\n",
        "    tools=[get_weather_forecast],\n",
        "    handoffs=[flight_agent, hotel_agent],\n",
        "    output_type=TravelPlan\n",
        ")\n",
        "```\n",
        "\n",
        "在 Agent instruction 裏提到這個能力，以及在  `handoffs=[flight_agent, hotel_agent]`"
      ],
      "metadata": {
        "id": "fuf90HBPKwH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### v5_guardrails_and_context"
      ],
      "metadata": {
        "id": "ufCySx-V8Sin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "hYhc3CUrQ6jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q logfire"
      ],
      "metadata": {
        "id": "MGNAoF3AT6Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import json\n",
        "from datetime import datetime\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "from agents import Agent, RunContextWrapper, Runner, function_tool, ModelSettings, InputGuardrail, GuardrailFunctionOutput, InputGuardrailTripwireTriggered\n",
        "from dotenv import load_dotenv\n",
        "import logfire\n",
        "import os\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Comment these lines out if you don't want Logfire tracing\n",
        "from google.colab import userdata\n",
        "LOGFIRE_TOKEN = userdata.get('LOGFIRE_TOKEN')\n",
        "\n",
        "logfire.configure(token=LOGFIRE_TOKEN)\n",
        "\n",
        "logfire.instrument_openai_agents()\n",
        "\n",
        "model = os.getenv('MODEL_CHOICE', 'gpt-4o-mini')\n",
        "\n",
        "# --- Models for structured outputs ---\n",
        "\n",
        "class FlightRecommendation(BaseModel):\n",
        "    airline: str\n",
        "    departure_time: str\n",
        "    arrival_time: str\n",
        "    price: float\n",
        "    direct_flight: bool\n",
        "    recommendation_reason: str\n",
        "\n",
        "class HotelRecommendation(BaseModel):\n",
        "    name: str\n",
        "    location: str\n",
        "    price_per_night: float\n",
        "    amenities: List[str]\n",
        "    recommendation_reason: str\n",
        "\n",
        "class TravelPlan(BaseModel):\n",
        "    destination: str\n",
        "    duration_days: int\n",
        "    budget: float\n",
        "    activities: List[str] = Field(description=\"List of recommended activities\")\n",
        "    notes: str = Field(description=\"Additional notes or recommendations\")\n",
        "\n",
        "class BudgetAnalysis(BaseModel):\n",
        "    is_realistic: bool\n",
        "    reasoning: str\n",
        "    suggested_budget: Optional[float] = None\n",
        "\n",
        "# --- Context Class ---\n",
        "\n",
        "@dataclass\n",
        "class UserContext:\n",
        "    user_id: str\n",
        "    preferred_airlines: List[str] = None\n",
        "    hotel_amenities: List[str] = None\n",
        "    budget_level: str = None\n",
        "    session_start: datetime = None\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.preferred_airlines is None:\n",
        "            self.preferred_airlines = []\n",
        "        if self.hotel_amenities is None:\n",
        "            self.hotel_amenities = []\n",
        "        if self.session_start is None:\n",
        "            self.session_start = datetime.now()\n",
        "\n",
        "# --- Tools ---\n",
        "\n",
        "@function_tool\n",
        "def get_weather_forecast(city: str, date: str) -> str:\n",
        "    \"\"\"Get the weather forecast for a city on a specific date.\"\"\"\n",
        "    # In a real implementation, this would call a weather API\n",
        "    weather_data = {\n",
        "        \"New York\": {\"sunny\": 0.3, \"rainy\": 0.4, \"cloudy\": 0.3},\n",
        "        \"Los Angeles\": {\"sunny\": 0.8, \"rainy\": 0.1, \"cloudy\": 0.1},\n",
        "        \"Chicago\": {\"sunny\": 0.4, \"rainy\": 0.3, \"cloudy\": 0.3},\n",
        "        \"Miami\": {\"sunny\": 0.7, \"rainy\": 0.2, \"cloudy\": 0.1},\n",
        "        \"London\": {\"sunny\": 0.2, \"rainy\": 0.5, \"cloudy\": 0.3},\n",
        "        \"Paris\": {\"sunny\": 0.4, \"rainy\": 0.3, \"cloudy\": 0.3},\n",
        "        \"Tokyo\": {\"sunny\": 0.5, \"rainy\": 0.3, \"cloudy\": 0.2},\n",
        "    }\n",
        "\n",
        "    if city in weather_data:\n",
        "        conditions = weather_data[city]\n",
        "        # Simple simulation based on probabilities\n",
        "        highest_prob = max(conditions, key=conditions.get)\n",
        "        temp_range = {\n",
        "            \"New York\": \"15-25°C\",\n",
        "            \"Los Angeles\": \"20-30°C\",\n",
        "            \"Chicago\": \"10-20°C\",\n",
        "            \"Miami\": \"25-35°C\",\n",
        "            \"London\": \"10-18°C\",\n",
        "            \"Paris\": \"12-22°C\",\n",
        "            \"Tokyo\": \"15-25°C\",\n",
        "        }\n",
        "        return f\"The weather in {city} on {date} is forecasted to be {highest_prob} with temperatures around {temp_range.get(city, '15-25°C')}.\"\n",
        "    else:\n",
        "        return f\"Weather forecast for {city} is not available.\"\n",
        "\n",
        "@function_tool\n",
        "async def search_flights(wrapper: RunContextWrapper[UserContext], origin: str, destination: str, date: str) -> str:\n",
        "    \"\"\"Search for flights between two cities on a specific date, taking user preferences into account.\"\"\"\n",
        "    # In a real implementation, this would call a flight search API\n",
        "    flight_options = [\n",
        "        {\n",
        "            \"airline\": \"SkyWays\",\n",
        "            \"departure_time\": \"08:00\",\n",
        "            \"arrival_time\": \"10:30\",\n",
        "            \"price\": 350.00,\n",
        "            \"direct\": True\n",
        "        },\n",
        "        {\n",
        "            \"airline\": \"OceanAir\",\n",
        "            \"departure_time\": \"12:45\",\n",
        "            \"arrival_time\": \"15:15\",\n",
        "            \"price\": 275.50,\n",
        "            \"direct\": True\n",
        "        },\n",
        "        {\n",
        "            \"airline\": \"MountainJet\",\n",
        "            \"departure_time\": \"16:30\",\n",
        "            \"arrival_time\": \"21:45\",\n",
        "            \"price\": 225.75,\n",
        "            \"direct\": False\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Apply user preferences if available\n",
        "    if wrapper and wrapper.context:\n",
        "        preferred_airlines = wrapper.context.preferred_airlines\n",
        "        if preferred_airlines:\n",
        "            # Move preferred airlines to the top of the list\n",
        "            flight_options.sort(key=lambda x: x[\"airline\"] not in preferred_airlines)\n",
        "\n",
        "            # Add a note about preference matching\n",
        "            for flight in flight_options:\n",
        "                if flight[\"airline\"] in preferred_airlines:\n",
        "                    flight[\"preferred\"] = True\n",
        "\n",
        "    return json.dumps(flight_options)\n",
        "\n",
        "@function_tool\n",
        "async def search_hotels(wrapper: RunContextWrapper[UserContext], city: str, check_in: str, check_out: str, max_price: Optional[float] = None) -> str:\n",
        "    \"\"\"Search for hotels in a city for specific dates within a price range, taking user preferences into account.\"\"\"\n",
        "    # In a real implementation, this would call a hotel search API\n",
        "    hotel_options = [\n",
        "        {\n",
        "            \"name\": \"City Center Hotel\",\n",
        "            \"location\": \"Downtown\",\n",
        "            \"price_per_night\": 199.99,\n",
        "            \"amenities\": [\"WiFi\", \"Pool\", \"Gym\", \"Restaurant\"]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Riverside Inn\",\n",
        "            \"location\": \"Riverside District\",\n",
        "            \"price_per_night\": 149.50,\n",
        "            \"amenities\": [\"WiFi\", \"Free Breakfast\", \"Parking\"]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Luxury Palace\",\n",
        "            \"location\": \"Historic District\",\n",
        "            \"price_per_night\": 349.99,\n",
        "            \"amenities\": [\"WiFi\", \"Pool\", \"Spa\", \"Fine Dining\", \"Concierge\"]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Filter by max price if provided\n",
        "    if max_price is not None:\n",
        "        filtered_hotels = [hotel for hotel in hotel_options if hotel[\"price_per_night\"] <= max_price]\n",
        "    else:\n",
        "        filtered_hotels = hotel_options\n",
        "\n",
        "    # Apply user preferences if available\n",
        "    if wrapper and wrapper.context:\n",
        "        preferred_amenities = wrapper.context.hotel_amenities\n",
        "        budget_level = wrapper.context.budget_level\n",
        "\n",
        "        # Sort hotels by preference match\n",
        "        if preferred_amenities:\n",
        "            # Calculate a score based on how many preferred amenities each hotel has\n",
        "            for hotel in filtered_hotels:\n",
        "                matching_amenities = [a for a in hotel[\"amenities\"] if a in preferred_amenities]\n",
        "                hotel[\"matching_amenities\"] = matching_amenities\n",
        "                hotel[\"preference_score\"] = len(matching_amenities)\n",
        "\n",
        "            # Sort by preference score (higher scores first)\n",
        "            filtered_hotels.sort(key=lambda x: x[\"preference_score\"], reverse=True)\n",
        "\n",
        "        # Apply budget level preferences if available\n",
        "        if budget_level:\n",
        "            if budget_level == \"budget\":\n",
        "                filtered_hotels.sort(key=lambda x: x[\"price_per_night\"])\n",
        "            elif budget_level == \"luxury\":\n",
        "                filtered_hotels.sort(key=lambda x: x[\"price_per_night\"], reverse=True)\n",
        "            # mid-range is already handled by the max_price filter\n",
        "\n",
        "    return json.dumps(filtered_hotels)\n",
        "\n",
        "# --- Guardrails ---\n",
        "\n",
        "budget_analysis_agent = Agent(\n",
        "    name=\"Budget Analyzer\",\n",
        "    instructions=\"\"\"\n",
        "    You analyze travel budgets to determine if they are realistic for the destination and duration.\n",
        "    Consider factors like:\n",
        "    - Average hotel costs in the destination\n",
        "    - Flight costs\n",
        "    - Food and entertainment expenses\n",
        "    - Local transportation\n",
        "\n",
        "    Provide a clear analysis of whether the budget is realistic and why.\n",
        "    If the budget is not realistic, suggest a more appropriate budget.\n",
        "    Don't be harsh at all, lean towards it being realistic unless it's really crazy.\n",
        "    If no budget was mentioned, just assume it is realistic.\n",
        "    \"\"\",\n",
        "    output_type=BudgetAnalysis,\n",
        "    model=model\n",
        ")\n",
        "\n",
        "async def budget_guardrail(ctx, agent, input_data):\n",
        "    \"\"\"Check if the user's travel budget is realistic.\"\"\"\n",
        "    # Parse the input to extract destination, duration, and budget\n",
        "    try:\n",
        "        analysis_prompt = f\"The user is planning a trip and said: {input_data}.\\nAnalyze if their budget is realistic for a trip to their destination for the length they mentioned.\"\n",
        "        result = await Runner.run(budget_analysis_agent, analysis_prompt, context=ctx.context)\n",
        "        final_output = result.final_output_as(BudgetAnalysis)\n",
        "\n",
        "        if not final_output.is_realistic:\n",
        "            print(f\"Your budget for your trip may not be realistic. {final_output.reasoning}\" if not final_output.is_realistic else None)\n",
        "\n",
        "        return GuardrailFunctionOutput(\n",
        "            output_info=final_output,\n",
        "            tripwire_triggered=not final_output.is_realistic,\n",
        "        )\n",
        "    except Exception as e:\n",
        "        # Handle any errors gracefully\n",
        "        return GuardrailFunctionOutput(\n",
        "            output_info=BudgetAnalysis(is_realistic=True, reasoning=f\"Error analyzing budget: {str(e)}\"),\n",
        "            tripwire_triggered=False\n",
        "        )\n",
        "\n",
        "# --- Specialized Agents ---\n",
        "\n",
        "flight_agent = Agent[UserContext](\n",
        "    name=\"Flight Specialist\",\n",
        "    handoff_description=\"Specialist agent for finding and recommending flights\",\n",
        "    instructions=\"\"\"\n",
        "    You are a flight specialist who helps users find the best flights for their trips.\n",
        "\n",
        "    Use the search_flights tool to find flight options, and then provide personalized recommendations\n",
        "    based on the user's preferences (price, time, direct vs. connecting).\n",
        "\n",
        "    The user's preferences are available in the context, including preferred airlines.\n",
        "\n",
        "    Always explain the reasoning behind your recommendations.\n",
        "\n",
        "    Format your response in a clear, organized way with flight details and prices.\n",
        "    \"\"\",\n",
        "    model=model,\n",
        "    tools=[search_flights],\n",
        "    output_type=FlightRecommendation\n",
        ")\n",
        "\n",
        "hotel_agent = Agent[UserContext](\n",
        "    name=\"Hotel Specialist\",\n",
        "    handoff_description=\"Specialist agent for finding and recommending hotels and accommodations\",\n",
        "    instructions=\"\"\"\n",
        "    You are a hotel specialist who helps users find the best accommodations for their trips.\n",
        "\n",
        "    Use the search_hotels tool to find hotel options, and then provide personalized recommendations\n",
        "    based on the user's preferences (location, amenities, price range).\n",
        "\n",
        "    The user's preferences are available in the context, including preferred amenities and budget level.\n",
        "\n",
        "    Always explain the reasoning behind your recommendations.\n",
        "\n",
        "    Format your response in a clear, organized way with hotel details, amenities, and prices.\n",
        "    \"\"\",\n",
        "    model=model,\n",
        "    tools=[search_hotels],\n",
        "    output_type=HotelRecommendation\n",
        ")\n",
        "\n",
        "conversational_agent = Agent[UserContext](\n",
        "    name=\"General Conversation Specialist\",\n",
        "    handoff_description=\"Specialist agent for giving basic responses to the user to carry out a normal conversation as opposed to structured output.\",\n",
        "    instructions=\"\"\"\n",
        "    You are a trip planning expert who answers basic user questions about their trip and offers any suggestions.\n",
        "    Act as a helpful assistant and be helpful in any way you can be.\n",
        "    \"\"\",\n",
        "    model=model\n",
        ")\n",
        "\n",
        "# --- Main Travel Agent ---\n",
        "\n",
        "travel_agent = Agent[UserContext](\n",
        "    name=\"Travel Planner\",\n",
        "    instructions=\"\"\"\n",
        "    You are a travel planning assistant who helps users plan their trips.\n",
        "\n",
        "    You can provide personalized travel recommendations based on the user's destination, duration, budget, and preferences.\n",
        "\n",
        "    The user's preferences are available in the context, which you can use to tailor your recommendations.\n",
        "\n",
        "    You can:\n",
        "    1. Get weather forecasts for destinations\n",
        "    2. Hand off to specialized agents for flight and hotel recommendations\n",
        "    3. Create comprehensive travel plans with activities and notes\n",
        "\n",
        "    Always be helpful, informative, and enthusiastic about travel.\n",
        "    \"\"\",\n",
        "    model=model,\n",
        "    tools=[get_weather_forecast],\n",
        "    handoffs=[flight_agent, hotel_agent, conversational_agent],\n",
        "    input_guardrails=[\n",
        "        InputGuardrail(guardrail_function=budget_guardrail),\n",
        "    ],\n",
        "    output_type=TravelPlan\n",
        ")\n",
        "\n",
        "# --- Main Function ---\n",
        "\n",
        "async def main():\n",
        "    # Create a user context with some preferences\n",
        "    user_context = UserContext(\n",
        "        user_id=\"user123\",\n",
        "        preferred_airlines=[\"SkyWays\", \"OceanAir\"],\n",
        "        hotel_amenities=[\"WiFi\", \"Pool\"],\n",
        "        budget_level=\"mid-range\"\n",
        "    )\n",
        "\n",
        "    # Example queries to test different aspects of the system\n",
        "    queries = [\n",
        "        \"I'm planning a trip to Miami for 5 days with a budget of $2000. What should I do there?\",\n",
        "        \"I'm planning a trip to Tokyo for a week, looking to spend under $5,000. Suggestions?\",\n",
        "        \"I need a flight from New York to Chicago tomorrow\",\n",
        "        \"Find me a hotel in Paris with a pool for under $400 per night\",\n",
        "        \"I want to go to Dubai for a week with only $300\"  # This should trigger the budget guardrail\n",
        "    ]\n",
        "\n",
        "    for query in queries:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"QUERY: {query}\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        try:\n",
        "            result = await Runner.run(travel_agent, query, context=user_context)\n",
        "\n",
        "            print(\"\\nFINAL RESPONSE:\")\n",
        "\n",
        "            # Format the output based on the type of response\n",
        "            if hasattr(result.final_output, \"airline\"):  # Flight recommendation\n",
        "                flight = result.final_output\n",
        "                print(\"\\n✈️ FLIGHT RECOMMENDATION ✈️\")\n",
        "                print(f\"Airline: {flight.airline}\")\n",
        "                print(f\"Departure: {flight.departure_time}\")\n",
        "                print(f\"Arrival: {flight.arrival_time}\")\n",
        "                print(f\"Price: ${flight.price}\")\n",
        "                print(f\"Direct Flight: {'Yes' if flight.direct_flight else 'No'}\")\n",
        "                print(f\"\\nWhy this flight: {flight.recommendation_reason}\")\n",
        "\n",
        "                # Show user preferences that influenced this recommendation\n",
        "                airlines = user_context.preferred_airlines\n",
        "                if airlines and flight.airline in airlines:\n",
        "                    print(f\"\\n👤 NOTE: This matches your preferred airline: {flight.airline}\")\n",
        "\n",
        "            elif hasattr(result.final_output, \"name\") and hasattr(result.final_output, \"amenities\"):  # Hotel recommendation\n",
        "                hotel = result.final_output\n",
        "                print(\"\\n🏨 HOTEL RECOMMENDATION 🏨\")\n",
        "                print(f\"Name: {hotel.name}\")\n",
        "                print(f\"Location: {hotel.location}\")\n",
        "                print(f\"Price per night: ${hotel.price_per_night}\")\n",
        "\n",
        "                print(\"\\nAmenities:\")\n",
        "                for i, amenity in enumerate(hotel.amenities, 1):\n",
        "                    print(f\"  {i}. {amenity}\")\n",
        "\n",
        "                # Highlight matching amenities from user preferences\n",
        "                preferred_amenities = user_context.hotel_amenities\n",
        "                if preferred_amenities:\n",
        "                    matching = [a for a in hotel.amenities if a in preferred_amenities]\n",
        "                    if matching:\n",
        "                        print(\"\\n👤 MATCHING PREFERRED AMENITIES:\")\n",
        "                        for amenity in matching:\n",
        "                            print(f\"  ✓ {amenity}\")\n",
        "\n",
        "                print(f\"\\nWhy this hotel: {hotel.recommendation_reason}\")\n",
        "\n",
        "            elif hasattr(result.final_output, \"destination\"):  # Travel plan\n",
        "                travel_plan = result.final_output\n",
        "                print(f\"\\n🌍 TRAVEL PLAN FOR {travel_plan.destination.upper()} 🌍\")\n",
        "                print(f\"Duration: {travel_plan.duration_days} days\")\n",
        "                print(f\"Budget: ${travel_plan.budget}\")\n",
        "\n",
        "                # Show budget level context\n",
        "                budget_level = user_context.budget_level\n",
        "                if budget_level:\n",
        "                    print(f\"Budget Category: {budget_level.title()}\")\n",
        "\n",
        "                print(\"\\n🎯 RECOMMENDED ACTIVITIES:\")\n",
        "                for i, activity in enumerate(travel_plan.activities, 1):\n",
        "                    print(f\"  {i}. {activity}\")\n",
        "\n",
        "                print(f\"\\n📝 NOTES: {travel_plan.notes}\")\n",
        "\n",
        "            else:  # Generic response\n",
        "                print(result.final_output)\n",
        "\n",
        "        except InputGuardrailTripwireTriggered as e:\n",
        "            print(\"\\n⚠️ GUARDRAIL TRIGGERED ⚠️\")\n",
        "\n",
        "'''\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n",
        "'''\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "id": "WBuj3oOv8X3A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7ad8127-7162-4f2d-8b5e-57ae609198e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19:32:24.049 Hello, World!\n",
            "\n",
            "==================================================\n",
            "QUERY: I'm planning a trip to Miami for 5 days with a budget of $2000. What should I do there?\n",
            "==================================================\n",
            "19:32:24.090 OpenAI Agents trace: Agent workflow\n",
            "19:32:24.095   Agent run: 'Travel Planner'\n",
            "19:32:24.097     Guardrail 'budget_guardrail' triggered=False\n",
            "19:32:24.099       Agent run: 'Budget Analyzer'\n",
            "19:32:24.104     Responses API with 'gpt-4o-mini'\n",
            "                 Guardrail 'budget_guardrail' triggered=False\n",
            "                   Agent run: 'Budget Analyzer'\n",
            "19:32:24.117         Responses API with 'gpt-4o-mini'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mLogfire\u001b[0m project URL: \u001b]8;id=338635;https://logfire-us.pydantic.dev/ssupinma/starter-project\u001b\\\u001b[4;36mhttps://logfire-us.pydantic.dev/ssupinma/starter-project\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Logfire</span> project URL: <a href=\"https://logfire-us.pydantic.dev/ssupinma/starter-project\" target=\"_blank\"><span style=\"color: #008080; text-decoration-color: #008080; text-decoration: underline\">https://logfire-us.pydantic.dev/ssupinma/starter-project</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FINAL RESPONSE:\n",
            "\n",
            "🌍 TRAVEL PLAN FOR MIAMI 🌍\n",
            "Duration: 5 days\n",
            "Budget: $2000.0\n",
            "Budget Category: Mid-Range\n",
            "\n",
            "🎯 RECOMMENDED ACTIVITIES:\n",
            "  1. Visit South Beach for sunbathing and swimming\n",
            "  2. Explore the Art Deco Historic District\n",
            "  3. Take a boat tour of Biscayne Bay\n",
            "  4. Visit Little Havana for Cuban culture and food\n",
            "  5. Spend a day at the Vizcaya Museum and Gardens\n",
            "  6. Enjoy nightlife in Wynwood and Brickell\n",
            "  7. Relax at Key Biscayne Beach\n",
            "  8. Discover the shops and restaurants at Lincoln Road Mall\n",
            "\n",
            "📝 NOTES: Consider renting a bike or scooter to explore the city easily. Book tours in advance for popular attractions. Check local events or festivals happening during your stay for additional entertainment options.\n",
            "\n",
            "==================================================\n",
            "QUERY: I'm planning a trip to Tokyo for a week, looking to spend under $5,000. Suggestions?\n",
            "==================================================\n",
            "19:32:31.224 OpenAI Agents trace: Agent workflow\n",
            "19:32:31.226   Agent run: 'Travel Planner'\n",
            "19:32:31.227     Guardrail 'budget_guardrail' triggered=False\n",
            "19:32:31.228       Agent run: 'Budget Analyzer'\n",
            "19:32:31.231     Responses API with 'gpt-4o-mini'\n",
            "                 Guardrail 'budget_guardrail' triggered=False\n",
            "                   Agent run: 'Budget Analyzer'\n",
            "19:32:31.242         Responses API with 'gpt-4o-mini'\n",
            "\n",
            "FINAL RESPONSE:\n",
            "\n",
            "🌍 TRAVEL PLAN FOR TOKYO 🌍\n",
            "Duration: 7 days\n",
            "Budget: $5000.0\n",
            "Budget Category: Mid-Range\n",
            "\n",
            "🎯 RECOMMENDED ACTIVITIES:\n",
            "  1. Visit the iconic Shibuya Crossing\n",
            "  2. Explore the historic Asakusa district and Senso-ji Temple\n",
            "  3. Shop in Harajuku and Omotesando\n",
            "  4. Experience the nightlife in Shinjuku\n",
            "  5. Visit Akihabara for electronic and anime culture\n",
            "  6. Take a day trip to Mount Fuji\n",
            "  7. Explore the Tokyo Skytree for panoramic views\n",
            "  8. Enjoy a traditional tea ceremony\n",
            "\n",
            "📝 NOTES: Consider purchasing a Japan Rail Pass for convenient travel across the city and beyond. Be mindful of peak tourist seasons to secure better deals on flights and accommodations.\n",
            "\n",
            "==================================================\n",
            "QUERY: I need a flight from New York to Chicago tomorrow\n",
            "==================================================\n",
            "19:32:34.486 OpenAI Agents trace: Agent workflow\n",
            "19:32:34.488   Agent run: 'Travel Planner'\n",
            "19:32:34.489     Guardrail 'budget_guardrail' triggered=False\n",
            "19:32:34.490       Agent run: 'Budget Analyzer'\n",
            "19:32:34.492     Responses API with 'gpt-4o-mini'\n",
            "                 Guardrail 'budget_guardrail' triggered=False\n",
            "                   Agent run: 'Budget Analyzer'\n",
            "19:32:34.501         Responses API with 'gpt-4o-mini'\n",
            "19:32:35.257     Handoff: Travel Planner → None\n",
            "19:32:37.094   Agent run: 'Flight Specialist'\n",
            "19:32:37.096     Responses API with 'gpt-4o-mini'\n",
            "19:32:38.384     Function: search_flights\n",
            "19:32:38.386     Responses API with 'gpt-4o-mini'\n",
            "\n",
            "FINAL RESPONSE:\n",
            "\n",
            "✈️ FLIGHT RECOMMENDATION ✈️\n",
            "Airline: OceanAir\n",
            "Departure: 12:45\n",
            "Arrival: 15:15\n",
            "Price: $275.5\n",
            "Direct Flight: Yes\n",
            "\n",
            "Why this flight: OceanAir offers the best balance of price and direct timing for your flight from New York to Chicago.\n",
            "\n",
            "👤 NOTE: This matches your preferred airline: OceanAir\n",
            "\n",
            "==================================================\n",
            "QUERY: Find me a hotel in Paris with a pool for under $400 per night\n",
            "==================================================\n",
            "19:32:40.376 OpenAI Agents trace: Agent workflow\n",
            "19:32:40.378   Agent run: 'Travel Planner'\n",
            "19:32:40.379     Guardrail 'budget_guardrail' triggered=False\n",
            "19:32:40.380       Agent run: 'Budget Analyzer'\n",
            "19:32:40.382     Responses API with 'gpt-4o-mini'\n",
            "                 Guardrail 'budget_guardrail' triggered=False\n",
            "                   Agent run: 'Budget Analyzer'\n",
            "19:32:40.391         Responses API with 'gpt-4o-mini'\n",
            "19:32:41.183     Handoff: Travel Planner → None\n",
            "19:32:43.777   Agent run: 'Hotel Specialist'\n",
            "19:32:43.779     Responses API with 'gpt-4o-mini'\n",
            "19:32:45.445     Function: search_hotels\n",
            "19:32:45.448     Responses API with 'gpt-4o-mini'\n",
            "\n",
            "FINAL RESPONSE:\n",
            "\n",
            "🏨 HOTEL RECOMMENDATION 🏨\n",
            "Name: City Center Hotel\n",
            "Location: Downtown\n",
            "Price per night: $199.99\n",
            "\n",
            "Amenities:\n",
            "  1. WiFi\n",
            "  2. Pool\n",
            "  3. Gym\n",
            "  4. Restaurant\n",
            "\n",
            "👤 MATCHING PREFERRED AMENITIES:\n",
            "  ✓ WiFi\n",
            "  ✓ Pool\n",
            "\n",
            "Why this hotel: Located in the heart of downtown Paris, this hotel features a pool and is well within your budget, offering great amenities for a comfortable stay.\n",
            "\n",
            "==================================================\n",
            "QUERY: I want to go to Dubai for a week with only $300\n",
            "==================================================\n",
            "19:32:47.802 OpenAI Agents trace: Agent workflow\n",
            "19:32:47.803   Agent run: 'Travel Planner'\n",
            "19:32:47.804     Guardrail 'budget_guardrail' triggered=False\n",
            "19:32:47.806       Agent run: 'Budget Analyzer'\n",
            "19:32:47.807     Responses API with 'gpt-4o-mini'\n",
            "                 Guardrail 'budget_guardrail' triggered=False\n",
            "                   Agent run: 'Budget Analyzer'\n",
            "19:32:47.817         Responses API with 'gpt-4o-mini'\n",
            "Your budget for your trip may not be realistic. Dubai is known for its luxury and high cost of living. The average cost for hotels can range from $50 to over $300 per night. For a week, even at the lower end, that totals about $350, which already exceeds the user's entire budget. Additionally, flights to Dubai, depending on the departure location, can be substantial, often starting around $500 to $700. Food and entertainment costs can also add up quickly, with meals often starting at $15 to $30 per person in a restaurant. Local transportation such as taxis or rideshares is another expense that would need to be considered. Overall, a budget of $300 is insufficient for a one-week trip to Dubai.\n",
            "\n",
            "⚠️ GUARDRAIL TRIGGERED ⚠️\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### guardrail\n",
        "\n",
        "`budget_guardrail` 是一個「輸入防護欄」（Input Guardrail）函式，專門用來檢查使用者輸入的旅遊預算是否合理。這個防護欄的設計目的是在主代理（`travel_agent`）處理使用者請求之前，先進行預算合理性的驗證，從而避免不切實際的預算導致後續的推薦結果不準確或無法實現。\n",
        "\n",
        "### 🧱 `budget_guardrail` 的運作流程\n",
        "\n",
        "1. **輸入解析與分析提示生成**：\n",
        "   當使用者輸入旅遊相關的請求給 Travel Agent 時，由於 Travel Agent 有 Input Guardrails ，因此觸發 `budget_guardrail` 會將這些輸入交給 `budget_analysis_agent` 進行預算分析\n",
        "\n",
        "2. **呼叫 `budget_analysis_agent` 進行預算分析**：\n",
        "   這個分析提示會被傳遞給一個名為 `budget_analysis_agent` 的代理。該代理的任務是根據提供的提示，判斷預算是否合理，並返回一個結構化的結果，包含：\n",
        "   -`is_realistic`：布林值，表示預算是否合理\n",
        "   -`reasoning`：文字說明，解釋為何預算被判定為合理或不合理\n",
        "   -`suggested_budget`（可選）：如果預算不合理，建議的合理預算金額\n",
        "\n",
        "3. **生成防護欄輸出結果**：\n",
        "   根據 `budget_analysis_agent` 的分析結果，`budget_guardrail` 會返回一個 `GuardrailFunctionOutput` 物件。如果預算被判定為不合理，則 `tripwire_triggered` 屬性會被設為 `True`，表示觸發了防護欄。\n",
        "\n",
        "### 🚨 防護欄觸發的處理機制\n",
        "在主程式中，當執行 `Runner.run(travel_agent, query, context=user_context)` 時，如果 `budget_guardrail` 判定預算不合理並觸發了防護欄，系統會拋出 `InputGuardrailTripwireTriggered` 例這個例外會被 `try-except` 區塊捕捉，並輸出警告訊息，例如：「⚠️ GUARDRAIL TRIGGERED ⚠️。\n",
        "\n",
        "### 🧠 為何使用代理進行預算分析\n",
        "\n",
        "將預算分析的邏輯封裝在一個專門的代理（`budget_analysis_agent`）中，有以下點：\n",
        "\n",
        "- **模組化設計*：使預算分析邏輯與主代理分離，便於維護和展。\n",
        "- **可重用性*：其他代理或功能模組也可以重用這個預算分析理。\n",
        "- **靈活性*：可以根據需要調整分析邏輯或模型，而不影響主代理的其他能。\n",
        "\n",
        "### 📌 結論\n",
        "\n",
        "`budget_guardrail` 作為一個輸入防護欄，透過專門的預算分析代理來評估使用者的預算是理。這種設計不僅提高了系統的健壯性，還提升了使用者體驗，確保後續的旅遊建議更貼近實情況。\n",
        "\n",
        "---\n",
        "\n",
        "在 OpenAI 的 Responses API 和 Agents SDK 中，**Guardrails（防護欄）** 是一種可配置的安全機制，用於在代理（Agent）執行前後對輸入和輸出進行驗證。這些防護欄有助於確保代理的行為符合預期，並防止潛在的錯誤或不當操作。\n",
        "\n",
        "---\n",
        "\n",
        "## 🛡️ Guardrails 的類型\n",
        "\n",
        "### 1. **輸入防護欄（Input Guardrails）**\n",
        "- **目的**在代理處理用戶輸入之前，檢查輸入的有效性和合理性\n",
        "- **應用場景**例如，在旅遊規劃應用中，檢查用戶提供的預算是否合理\n",
        "- **實現方式**使用 `InputGuardrail` 類別，並指定一個檢查函數（如 `budget_guardrail`），該函數返回一個 `GuardrailFunctionOutput` 物件，指示是否觸發防護欄\n",
        "\n",
        "### 2. **輸出防護欄（Output Guardrails）**\n",
        "- **目的**在代理生成回應後，檢查輸出的內容是否符合預期或安全標準\n",
        "- **應用場景**例如，防止代理輸出敏感或不適當的內容\n",
        "- **實現方式**類似於輸入防護欄，使用相應的類別和檢查函數對輸出進行驗證\n",
        "\n",
        "---\n",
        "\n",
        "## ⚙️ Guardrails 的運作機制\n",
        "\n",
        "1. **定義防護欄函數**開發者定義一個函數，用於檢查特定條件（例如預算合理性）\n",
        "\n",
        "2. **配置代理**在創建代理時，通過 `input_guardrails` 或 `output_guardrails` 參數，將防護欄函數與代理關聯\n",
        "\n",
        "3. **執行流程**：\n",
        "   -當代理接收到輸入時，首先執行輸入防護欄函數\n",
        "   -如果防護欄被觸發（即檢查未通過），則代理的執行會被中止，並引發 `InputGuardrailTripwireTriggered` 例外\n",
        "   -開發者可以捕捉這個例外，並提供相應的處理邏輯，例如提示用戶調整輸入\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## ✅ 優點與應用場景\n",
        "\n",
        "- **提升安全性*：防止代理處理不當或潛在危險的輸。\n",
        "- **提高可靠性*：確保代理的輸出符合預期，避免不一致或錯誤的回。\n",
        "- **增強用戶體驗*：提供即時的反饋，幫助用戶修正輸入，提高互動的流暢。\n",
        "\n"
      ],
      "metadata": {
        "id": "mrc9TUa1jkQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `UserContext`\n",
        "\n",
        "`UserContext` 類和 `Agent` 的結合使用提供了強大的個人化能力，使得代理能夠根據用戶的偏好和需求提供定制化的建議。以下是對這些組件的詳細解釋：\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 `UserContext` 類：封裝用戶偏好\n",
        "`UserContext` 是一個使用 `@dataclass` 裝飾器定義的數據類，用於存儲與用戶相關的偏好和資訊。這些資訊包括\n",
        "\n",
        "- **`user_id`**用戶的唯一識別碼\n",
        "- **`preferred_airlines`**用戶偏好的航空公司列表\n",
        "- **`hotel_amenities`**用戶偏好的飯店設施列表\n",
        "- **`budget_level`**用戶的預算等級（如 \"budget\"、\"mid-range\"、\"luxury\"）\n",
        "- **`session_start`**會話開始的時間戳\n",
        "`@dataclass` 裝飾器自動為這個類生成初始化方法和其他實用方法，簡化了代碼的撰寫和維護\n",
        "\n",
        "---\n",
        "\n",
        "## 🧩 `Agent` 如何使用 `UserContext`\n",
        "在這個系統中，`Agent` 是處理特定任務的智能代理，例如搜尋航班或飯店。每個代理都可以訪問 `UserContext`，從而根據用戶的偏好提供個性化的建。\n",
        "\n",
        "### ✈️ 航班代理 (`flight_agent`)\n",
        "`flight_agent` 使用 `search_flights` 工具來搜尋航班。在搜尋過程中，它會考慮 `UserContext` 中的 `preferred_airlines`，將用戶偏好的航空公司排在搜尋結果的前列，並標記為偏好選。\n",
        "\n",
        "### 🏨 飯店代理 (`hotel_agent`\n",
        "\n",
        "`hotel_agent` 使用 `search_hotels` 工具來搜尋飯店。它會根據 `UserContext` 中的 `hotel_amenities` 和 `budget_level`，篩選並排序搜尋結果。例如，若用戶偏好有游泳池的飯店，代理會優先推薦包含該設施的店。\n",
        "\n",
        "---\n",
        "\n",
        "## 🔄 `RunContextWrapper` 的色\n",
        "\n",
        "`RunContextWrapper` 是一個封裝器，用於在工具函數中傳遞 `UserContext`。當工具函數（如 `search_flights` 或 `search_hotels`）被呼叫時，它們可以通過這個封裝器訪問用戶的偏好資訊，從而提供更符合用戶需求結果。\n",
        "\n",
        "---\n",
        "\n",
        "## 🧭 `travel_agent` 整合\n",
        "\n",
        "`travel_agent` 是一個綜合性的代理，負責整體的旅遊規劃。它會根據用戶的輸入和 `UserContext`，決定是否需要將任務交由專門的代理（如 `flight_agent` 或 `hotel_agent`）處理，或者直接提供建議。這種設計使得系統能夠靈活地處理各種旅遊相關的查詢，並提供個性的建議。\n",
        "\n",
        "--\n",
        "\n",
        "在 Python 的 `@dataclass` 裝飾器中，`__post_init__` 方法是一個特殊的初始化鉤子（hook），它會在自動生成的 `__init__` 方法執行完畢後自動被呼叫。這使得我們可以在物件初始化後進行額外的處理，例如設定預設值、驗證輸入或根據其他欄位計算衍生屬性。\n",
        "\n",
        "### 為什麼使用 `__post_init__` 而不是自定義 `__init__`？\n",
        "\n",
        "當我們使用 `@dataclass` 時，Python 會自動為我們生成 `__init__` 方法，這個方法會根據類別中定義的欄位來初始化物件。如果我們手動定義了 `__init__` 方法，這將會覆蓋自動生成的版本，導致我們失去 `@dataclass` 所帶來的便利性。\n",
        "\n",
        "使用 `__post_init__` 可以讓我們在保留自動生成的 `__init__` 方法的同時，添加自定義的初始化邏輯。這種方式不僅簡潔，而且能夠保持代碼的一致性和可讀性。\n",
        "\n",
        "### `__post_init__` 的使用情境\n",
        "\n",
        "1. **設定預設值或處理可變預設值**：避免所有實例共享同一個可變物件。\n",
        "   ```python\n",
        "   from dataclasses import dataclass, field\n",
        "   from typing import List\n",
        "\n",
        "   @dataclass\n",
        "   class MyClass:\n",
        "       items: List[int] = field(default_factory=list)\n",
        "\n",
        "       def __post_init__(self):\n",
        "           # 確保 items 是一個新的列表實例\n",
        "           self.items = list(self.items)\n",
        "   ```\n",
        "\n",
        "2. **根據其他欄位計算衍生屬性**：例如計算兩個欄位的總和。\n",
        "   ```python\n",
        "   @dataclass\n",
        "   class Point:\n",
        "       x: int\n",
        "       y: int\n",
        "       distance: float = 0.0\n",
        "\n",
        "       def __post_init__(self):\n",
        "           self.distance = (self.x ** 2 + self.y ** 2) ** 0.5\n",
        "   ```\n",
        "\n",
        "3. **驗證輸入資料的有效性**：例如檢查某個欄位的值是否在合理範圍內。\n",
        "   ```python\n",
        "   @dataclass\n",
        "   class Product:\n",
        "       name: str\n",
        "       price: float\n",
        "\n",
        "       def __post_init__(self):\n",
        "           if self.price < 0:\n",
        "               raise ValueError(\"Price cannot be negative\")\n",
        "   ```\n",
        "\n",
        "4. **處理初始化專用變數（InitVar）**：這些變數只在初始化期間使用，不會成為實例的屬性。\n",
        "   ```python\n",
        "   from dataclasses import dataclass, InitVar\n",
        "\n",
        "   @dataclass\n",
        "   class Example:\n",
        "       data: int\n",
        "       factor: InitVar[int]\n",
        "\n",
        "       def __post_init__(self, factor):\n",
        "           self.data *= factor\n",
        "   ```\n",
        "\n",
        "### 小結\n",
        "\n",
        "使用 `__post_init__` 方法可以讓我們在保留 `@dataclass` 自動生成功能的同時，添加自定義的初始化邏輯。這種方式特別適合需要在物件初始化後進行額外處理的情境，能夠提升代碼的可維護性和可讀性。\n"
      ],
      "metadata": {
        "id": "CfpzFsavp8Lh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### wrapper: RunContextWrapper\n",
        "\n",
        "`wrapper: RunContextWrapper[UserContext]` 是一個參數，傳遞給像 `search_flights` 這樣的工具函數。這個 `wrapper` 是 `RunContextWrapper` 類型的實例，並且泛型參數為 `UserContext`。\n",
        "\n",
        "### `RunContextWrapper[UserContext]` 的角色\n",
        "\n",
        "`RunContextWrapper` 是一個封裝器，包含了運行時的上下文資訊。在這個例子中，它包含了 `UserContext` 的實例。這使得在執行工具函數時，可以存取使用者的偏好設定，例如：\n",
        "\n",
        "- `preferred_airlines`：使用者偏好的航空公司\n",
        "- `hotel_amenities`：使用者偏好的飯店設施\n",
        "- `budget_level`：使用者的預算等級\n",
        "\n",
        "這些資訊可以用來個性化搜尋結果。例如，在 `search_flights` 函數中，根據 `preferred_airlines` 對航班選項進行排序，將使用者偏好的航空公司排在前面。\n",
        "\n",
        "### 使用 `wrapper.context` 的好處\n",
        "\n",
        "透過 `wrapper.context`，工具函數可以存取使用者的上下文資訊，實現更個性化的功能。這種設計使得工具函數具有更高的靈活性和可重用性，因為它們可以根據不同的使用者上下文進行調整，而不需要硬編碼使用者偏好。\n",
        "\n",
        "### 總結\n",
        "\n",
        "`RunContextWrapper[UserContext]` 提供了一種機制，讓工具函數在執行時能夠存取使用者的上下文資訊，從而實現個性化的功能。這種設計提高了系統的靈活性和可維護性。"
      ],
      "metadata": {
        "id": "Q073f_RxrF7w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Logfire\n",
        "\n",
        "https://www.youtube.com/watch?v=gkHSIOxh60s\n",
        "\n",
        "https://pydantic.dev/pricing\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l8IaOgP1Sftt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### v6_streamlit_agent"
      ],
      "metadata": {
        "id": "caNjpJ-jm81U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit openai langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNc2biuwnHmL",
        "outputId": "82a7bf24-3a25-4b3a-f64c-0ef96e0455f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import asyncio\n",
        "import uuid\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Any\n",
        "import os\n",
        "\n",
        "# Import the travel agent from v5\n",
        "from v5_guardrails_and_context import (\n",
        "    travel_agent,\n",
        "    UserContext,\n",
        "    TravelPlan,\n",
        "    FlightRecommendation,\n",
        "    HotelRecommendation\n",
        ")\n",
        "\n",
        "from agents import Runner\n",
        "\n",
        "# Page configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"Travel Planner Assistant\",\n",
        "    page_icon=\"✈️\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Custom CSS for better styling\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    .chat-message {\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 0.5rem;\n",
        "        margin-bottom: 1rem;\n",
        "        display: flex;\n",
        "        flex-direction: column;\n",
        "    }\n",
        "    .chat-message.user {\n",
        "        background-color: #e6f7ff;\n",
        "        border-left: 5px solid #2196F3;\n",
        "    }\n",
        "    .chat-message.assistant {\n",
        "        background-color: #f0f0f0;\n",
        "        border-left: 5px solid #4CAF50;\n",
        "    }\n",
        "    .chat-message .content {\n",
        "        display: flex;\n",
        "        margin-top: 0.5rem;\n",
        "    }\n",
        "    .avatar {\n",
        "        width: 40px;\n",
        "        height: 40px;\n",
        "        border-radius: 50%;\n",
        "        object-fit: cover;\n",
        "        margin-right: 1rem;\n",
        "    }\n",
        "    .message {\n",
        "        flex: 1;\n",
        "        color: #000000;\n",
        "    }\n",
        "    .timestamp {\n",
        "        font-size: 0.8rem;\n",
        "        color: #888;\n",
        "        margin-top: 0.2rem;\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Initialize session state for chat history and user context\n",
        "if \"chat_history\" not in st.session_state:\n",
        "    st.session_state.chat_history = []\n",
        "\n",
        "if \"thread_id\" not in st.session_state:\n",
        "    st.session_state.thread_id = str(uuid.uuid4())\n",
        "\n",
        "if \"user_context\" not in st.session_state:\n",
        "    st.session_state.user_context = UserContext(\n",
        "        user_id=str(uuid.uuid4())\n",
        "    )\n",
        "\n",
        "if \"processing_message\" not in st.session_state:\n",
        "    st.session_state.processing_message = None\n",
        "\n",
        "# Function to format agent responses based on output type\n",
        "def format_agent_response(output):\n",
        "    # Check if output is a Pydantic model and convert to dict\n",
        "    if hasattr(output, \"model_dump\"):\n",
        "        output = output.model_dump()\n",
        "\n",
        "    if isinstance(output, dict):\n",
        "        # Handle structured outputs\n",
        "        if \"destination\" in output:  # TravelPlan\n",
        "            html = f\"\"\"\n",
        "            <h3>Travel Plan for {output.get('destination', 'Your Trip')}</h3>\n",
        "            <p><strong>Duration:</strong> {output.get('duration_days', 'N/A')} days</p>\n",
        "            <p><strong>Budget:</strong> ${output.get('budget', 'N/A')}</p>\n",
        "\n",
        "            <h4>Recommended Activities:</h4>\n",
        "            <ul>\n",
        "            \"\"\"\n",
        "            for activity in output.get('activities', []):\n",
        "                html += f\"<li>{activity}</li>\"\n",
        "            html += \"</ul>\"\n",
        "\n",
        "            html += f\"<p><strong>Notes:</strong> {output.get('notes', '')}</p>\"\n",
        "            return html\n",
        "\n",
        "        elif \"airline\" in output:  # FlightRecommendation\n",
        "            html = f\"\"\"\n",
        "            <h3>Flight Recommendation</h3>\n",
        "            <p><strong>Airline:</strong> {output.get('airline', 'N/A')}</p>\n",
        "            <p><strong>Departure:</strong> {output.get('departure_time', 'N/A')}</p>\n",
        "            <p><strong>Arrival:</strong> {output.get('arrival_time', 'N/A')}</p>\n",
        "            <p><strong>Price:</strong> ${output.get('price', 'N/A')}</p>\n",
        "            <p><strong>Direct Flight:</strong> {'Yes' if output.get('direct_flight', False) else 'No'}</p>\n",
        "            <p><strong>Why this flight:</strong> {output.get('recommendation_reason', '')}</p>\"\"\"\n",
        "            return html\n",
        "\n",
        "        elif \"name\" in output and \"amenities\" in output:  # HotelRecommendation\n",
        "            html = f\"\"\"\n",
        "            <h3>Hotel Recommendation: {output.get('name', 'N/A')}</h3>\n",
        "            <p><strong>Location:</strong> {output.get('location', 'N/A')}</p>\n",
        "            <p><strong>Price per night:</strong> ${output.get('price_per_night', 'N/A')}</p>\n",
        "\n",
        "            <h4>Amenities:</h4>\n",
        "            <ul>\n",
        "            \"\"\"\n",
        "            for amenity in output.get('amenities', []):\n",
        "                html += f\"<li>{amenity}</li>\"\n",
        "            html += \"</ul>\"\n",
        "\n",
        "            html += f\"<p><strong>Why this hotel:</strong> {output.get('recommendation_reason', '')}</p>\"\n",
        "            return html\n",
        "\n",
        "    # Default: return as string\n",
        "    return str(output)\n",
        "\n",
        "# Function to handle user input\n",
        "def handle_user_message(user_input: str):\n",
        "    # Add user message to chat history immediately\n",
        "    timestamp = datetime.now().strftime(\"%I:%M %p\")\n",
        "    st.session_state.chat_history.append({\n",
        "        \"role\": \"user\",\n",
        "        \"content\": user_input,\n",
        "        \"timestamp\": timestamp\n",
        "    })\n",
        "\n",
        "    # Set the message for processing in the next rerun\n",
        "    st.session_state.processing_message = user_input\n",
        "\n",
        "# Sidebar for user preferences\n",
        "with st.sidebar:\n",
        "    st.title(\"Travel Preferences\")\n",
        "\n",
        "    st.subheader(\"About You\")\n",
        "    traveler_name = st.text_input(\"Your Name\", value=\"Traveler\")\n",
        "\n",
        "    st.subheader(\"Travel Preferences\")\n",
        "    preferred_airlines = st.multiselect(\n",
        "        \"Preferred Airlines\",\n",
        "        [\"SkyWays\", \"OceanAir\", \"MountainJet\", \"Delta\", \"United\", \"American\", \"Southwest\"],\n",
        "        default=st.session_state.user_context.preferred_airlines\n",
        "    )\n",
        "\n",
        "    preferred_amenities = st.multiselect(\n",
        "        \"Must-have Hotel Amenities\",\n",
        "        [\"WiFi\", \"Pool\", \"Gym\", \"Free Breakfast\", \"Restaurant\", \"Spa\", \"Parking\"],\n",
        "        default=st.session_state.user_context.hotel_amenities\n",
        "    )\n",
        "\n",
        "    budget_level = st.select_slider(\n",
        "        \"Budget Level\",\n",
        "        options=[\"budget\", \"mid-range\", \"luxury\"],\n",
        "        value=st.session_state.user_context.budget_level or \"mid-range\"\n",
        "    )\n",
        "\n",
        "    if st.button(\"Save Preferences\"):\n",
        "        st.session_state.user_context.preferred_airlines = preferred_airlines\n",
        "        st.session_state.user_context.hotel_amenities = preferred_amenities\n",
        "        st.session_state.user_context.budget_level = budget_level\n",
        "        st.success(\"Preferences saved!\")\n",
        "\n",
        "    st.divider()\n",
        "\n",
        "    if st.button(\"Start New Conversation\"):\n",
        "        st.session_state.chat_history = []\n",
        "        st.session_state.thread_id = str(uuid.uuid4())\n",
        "        st.success(\"New conversation started!\")\n",
        "\n",
        "# Main chat interface\n",
        "st.title(\"✈️ Travel Planner Assistant\")\n",
        "st.caption(\"Ask me about travel destinations, flight options, hotel recommendations, and more!\")\n",
        "\n",
        "# Display chat messages\n",
        "for message in st.session_state.chat_history:\n",
        "    with st.container():\n",
        "        if message[\"role\"] == \"user\":\n",
        "            st.markdown(f\"\"\"\n",
        "            <div class=\"chat-message user\">\n",
        "                <div class=\"content\">\n",
        "                    <img src=\"https://api.dicebear.com/7.x/avataaars/svg?seed={st.session_state.user_context.user_id}\" class=\"avatar\" />\n",
        "                    <div class=\"message\">\n",
        "                        {message[\"content\"]}\n",
        "                        <div class=\"timestamp\">{message[\"timestamp\"]}</div>\n",
        "                    </div>\n",
        "                </div>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "        else:\n",
        "            st.markdown(f\"\"\"\n",
        "            <div class=\"chat-message assistant\">\n",
        "                <div class=\"content\">\n",
        "                    <img src=\"https://api.dicebear.com/7.x/bottts/svg?seed=travel-agent\" class=\"avatar\" />\n",
        "                    <div class=\"message\">\n",
        "                        {message[\"content\"]}\n",
        "                        <div class=\"timestamp\">{message[\"timestamp\"]}</div>\n",
        "                    </div>\n",
        "                </div>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# User input\n",
        "user_input = st.chat_input(\"Ask about travel plans...\")\n",
        "if user_input:\n",
        "    handle_user_message(user_input)\n",
        "    st.rerun()\n",
        "\n",
        "# Process message if needed\n",
        "if st.session_state.processing_message:\n",
        "    user_input = st.session_state.processing_message\n",
        "    st.session_state.processing_message = None\n",
        "\n",
        "    # Process the message asynchronously\n",
        "    with st.spinner(\"Thinking...\"):\n",
        "        try:\n",
        "            # Prepare input for the agent using chat history\n",
        "            if len(st.session_state.chat_history) > 1:\n",
        "                # Convert chat history to input list format for the agent\n",
        "                input_list = []\n",
        "                for msg in st.session_state.chat_history:\n",
        "                    input_list.append({\"role\": msg[\"role\"], \"content\": msg[\"content\"]})\n",
        "            else:\n",
        "                # First message\n",
        "                input_list = user_input\n",
        "\n",
        "            # Run the agent with the input\n",
        "            result = asyncio.run(Runner.run(\n",
        "                travel_agent,\n",
        "                input_list,\n",
        "                context=st.session_state.user_context\n",
        "            ))\n",
        "\n",
        "            # Format the response based on output type\n",
        "            response_content = format_agent_response(result.final_output)\n",
        "\n",
        "            # Add assistant response to chat history\n",
        "            st.session_state.chat_history.append({\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": response_content,\n",
        "                \"timestamp\": datetime.now().strftime(\"%I:%M %p\")\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            error_message = f\"Sorry, I encountered an error: {str(e)}\"\n",
        "            st.session_state.chat_history.append({\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": error_message,\n",
        "                \"timestamp\": datetime.now().strftime(\"%I:%M %p\")\n",
        "            })\n",
        "\n",
        "        # Force a rerun to display the AI response\n",
        "        st.rerun()\n",
        "\n",
        "# Footer\n",
        "st.divider()\n",
        "st.caption(\"Powered by OpenAI Agents SDK | Built with Streamlit\")"
      ],
      "metadata": {
        "id": "HavoANie8e3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc2321d-30c1-405e-c1c7-a449ba986d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-11 20:50:24.263 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.265 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.332 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-04-11 20:50:24.334 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.336 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.339 Session state does not function when running a script without `streamlit run`\n",
            "2025-04-11 20:50:24.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.342 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.343 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.345 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.346 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.347 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.348 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.350 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.351 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.353 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.355 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.357 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.359 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.360 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.361 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.362 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.363 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.364 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.365 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.365 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.366 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.367 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.367 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.368 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.369 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.370 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.370 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.371 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.372 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.373 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.377 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.378 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.379 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.379 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.380 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.382 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.383 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.383 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.384 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.387 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.388 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.388 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.389 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.390 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.390 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.391 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.392 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.392 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.393 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.394 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.394 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.395 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.396 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.397 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.397 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.398 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.399 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.400 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.400 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.401 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.402 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.403 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.404 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.404 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.405 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.406 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trace\n",
        "\n",
        "Log in OpenAI account, projects, logs, Traces\n",
        "\n",
        "https://platform.openai.com/logs"
      ],
      "metadata": {
        "id": "licHo8Fj92Cf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXJKldzYs9ni"
      },
      "source": [
        "# Courses of next Week\n",
        "\n",
        "Week 46 OpenAI Agent SDK 2/2 advance\n",
        "\n",
        "1. Responses API Walkthrough https://www.youtube.com/watch?v=0pGxoubWI6s\n",
        "  - https://github.com/daveebbelaar/ai-cookbook/tree/main/models/openai/05-responses\n",
        "\n",
        "2. Automate Your Browser with AI! Build a Computer Using Agent (OpenAI API) https://www.youtube.com/watch?v=Tm1_KHdh_kA\n",
        "  - https://github.com/leonvanzyl/openai-responses-api-tutorial-python/blob/master/lesson-9.py\n",
        "\n",
        "\n",
        "3. How To Build An OpenAI Computer-Using Agent (CUA Model) https://www.youtube.com/watch?v=9hkjq6hQTYo\n",
        "\n",
        "\n",
        "---\n",
        "Playwright: https://www.youtube.com/watch?v=RGR5Xj0Qqfs\n",
        "\n",
        "Playwright MCP: https://www.youtube.com/watch?v=2716IUeCIQo\n",
        "\n",
        "Browser Use https://www.youtube.com/watch?v=zGkVKix_CRU\n",
        "\n",
        "\n",
        "\n",
        "https://www.youtube.com/watch?v=gyFu6xubdEk\n",
        "  - https://www.youtube.com/watch?v=gyFu6xubdEk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3YyD0hHjM91"
      },
      "source": [
        "#Colab files of this Study Group\n",
        "\n",
        "\n",
        "1.   [20240531 Hugging Face & LLM Tools - Transformer Introduction Pipeline.ipynb](https://colab.research.google.com/drive/10DuI2Evk_w1ebe4gIgaTQlYMOafUN3z4?usp=sharing)\n",
        "\n",
        "2. [20240607 Hugging Face & LLM Tools - Transformer Encoder Decoder Encoder-Decoder.ipynb](https://colab.research.google.com/drive/1PDj5kbZu2whF8ASXR3IeQZfBYjwvc9ib?usp=sharing)\n",
        "\n",
        "3. [20240614 Hugging Face & LLM Tools - USING TRANSFORMERS.ipynb](https://colab.research.google.com/drive/1H02fg2lDaEuCUFmY8Fzr45uftga0IFJy?usp=sharing)\n",
        "\n",
        "4. [20240621 Hugging Face & LLM Tools - Fine-Tuning A Pretrained Model.ipynb](https://colab.research.google.com/drive/1pQxFFnBFVoOBuGPYp0d6Nih8TFeAk4k7?usp=sharing)\n",
        "\n",
        "5. [20240628 Hugging Face & LLM Tools - Sharing Models and Tokenizer.ipynb](https://colab.research.google.com/drive/1XGY2wRzPelaw-evSPTH8EJ_L-LUutP7y?usp=sharing)\n",
        "\n",
        "6. [20240705 Hugging Face & LLM Tools - Dataset 1/2.ipynb](https://colab.research.google.com/drive/1TjQ9lR-YIbWYT5J9cWJ1L2qghMnid7HX?usp=sharing)\n",
        "\n",
        "7. [20240712 Hugging Face & LLM Tools - Dataset 2/2.ipynb](https://colab.research.google.com/drive/1BgMzO5mTdqK68MCMYX89gpX3wwJsxSRQ?usp=sharing)\n",
        "\n",
        "8. [20240719 Hugging Face & LLM Tools - TOKENIZERS LIBRARY 1/2.ipynb](https://colab.research.google.com/drive/1b1k5AM34gOibFcu9BwddIV_NpApW9ORR?usp=sharing)\n",
        "\n",
        "9. [20240726 Hugging Face & LLM Tools - TOKENIZERS LIBRARY 2/2.ipynb](https://colab.research.google.com/drive/1hCQkn53Gf8vrM33cy2MNNtiotoVBweYA?usp=sharing)\n",
        "\n",
        "10. [20240802 Hugging Face & LLM Tools - MAIN NLP TASKS 1/2.ipynb]( https://colab.research.google.com/drive/1QvyzWlG3K0NOLkOEVzhQL6oGMHsO2Lr3?usp=sharing )\n",
        "\n",
        "11. [20240809 Hugging Face & LLM Tools - MAIN NLP TASKS 2/2.ipynb]( https://colab.research.google.com/drive/13Lfk4tmm9MUCEO5TcZygljAQV_yyp1CM?usp=sharing )\n",
        "\n",
        "12. [20240816 Hugging Face & LLM Tools - How to Ask Help.ipynb]( https://colab.research.google.com/drive/1dCkDVlSBSxQom9M8jEyy_Zk2KocWtMRR?usp=sharing )\n",
        "\n",
        "13. [20240823 Hugging Face & LLM Tools - Building and sharing demos 1/2.ipynb]( https://colab.research.google.com/drive/1VaNWjH_oTqBVxG1K7d8J4_rClyqUcS7W?usp=sharing )\n",
        "\n",
        "14. [20240830 Hugging Face & LLM Tools - Building and sharing demos 2/2.ipynb]( https://colab.research.google.com/drive/15nXSphf9qG02ReTs36CWczPx2g9tU28R?usp=sharing )\n",
        "\n",
        "15. [20240906 Hugging Face & LLM Tools - API.ipynb]( https://colab.research.google.com/drive/1RjtuOignulPp2ewcRXE53CPI-qso-vwA?usp=sharing )\n",
        "\n",
        "16. [20240913 Hugging Face & LLM Tools - Local Server 1/2.ipynb]( https://colab.research.google.com/drive/1gd55wakcBN1LfL7NQGe4ALYmwHvZM0yG?usp=sharing )\n",
        "\n",
        "17. [20240920 Hugging Face & LLM Tools - Local Server 2/2 NIM & LLaMA C++.ipynb]( https://colab.research.google.com/drive/1dMM7NfryclLmqKYMhbEY-z9nZooR492J?usp=sharing )\n",
        "\n",
        "18. [20240927  Hugging Face & LLM Tools - LangChain 1/2 DeepLearning.ipynb]( https://colab.research.google.com/drive/1yQjUlFXRc8JqPzgw7rHOU-_nfqSganNS?usp=sharing )\n",
        "\n",
        "19. [20241004  Hugging Face & LLM Tools - LangChain 2/2 with llama3d2.ipynb]( https://colab.research.google.com/drive/1JPTH4t1USSekFrfxyI7lOWEK0HOOMMcQ?usp=sharing )\n",
        "\n",
        "20. [20241011  Hugging Face & LLM Tools - RAG 1/2 with llamaindex Truera.ipynb]( https://colab.research.google.com/drive/1lSz6H5kgwB08PoFz3K8dYEHZJgkKzDaO?usp=sharing )\n",
        "\n",
        "21. Gap week\n",
        "\n",
        "22. [20241025  Hugging Face & LLM Tools - RAG 2/2 with llamaindex & Agent.ipynb]( https://colab.research.google.com/drive/1PeKC2UVcHS7v0DKtuxq9SfFvyNqbTydO?usp=sharing )\n",
        "\n",
        "23. [20241101  Hugging Face & LLM Tools - Dify 1/3.ipynb]( https://colab.research.google.com/drive/1afJdk5qlw8IqyYkYN0MmT7wVBCBO-1iP?usp=sharing )\n",
        "\n",
        "24. [20241108  Hugging Face & LLM Tools - Dify 2/3.ipynb]( https://colab.research.google.com/drive/1Efz35MYweXE1BveFIxr_0WTMcgHXIixC?usp=sharing )\n",
        "\n",
        "25. [2024115 Hugging Face & LLM Tools - Dify 3/3.ipynb]( https://colab.research.google.com/drive/1CDa6QK7Yl7CADYvAqrh-9xB1R02Lg30D?usp=sharing )\n",
        "\n",
        "26. [20241122 Hugging Face & LLM Tools - Vector DB 1/2 Milvus pgvector .ipynb]( https://colab.research.google.com/drive/1UfFuedpk8aMxqt6OTEdX4_Ap7vmUSLd8?usp=sharing )\n",
        "\n",
        "27. [20241129 Hugging Face & LLM Tools - Vector DB 2/2 Qdrant ChromaDB.ipynb]( https://colab.research.google.com/drive/1piGVevD9FDWJCuYTsdJKkvEsLl2rOkYh?usp=sharing )\n",
        "\n",
        "28. [20241206  Hugging Face & LLM Tools - Graph RAG 1/2 Microsoft GraphRAG.ipynb]( https://colab.research.google.com/drive/1qb2H_EgTccVNUj2M9U-nC-4LmBCyuJjN?usp=sharing )\n",
        "\n",
        "29. [20241213  Hugging Face & LLM Tools - Graph RAG 2/2 code of GraphRAG Sciphi Triplex LightRAG.ipynb]( https://colab.research.google.com/drive/1PTJvst7rkhNiIX0kAWuu7SBDPpRWc2DY?usp=sharing )\n",
        "\n",
        "30. [20241220   Huging Face & LLM Tools - Graph Database 1/2 Neo4j.ipynb]( https://colab.research.google.com/drive/1YG4OwbtQJ7ONULR1lBm9FjXrLG9mqTn4?usp=sharing )\n",
        "\n",
        "31. [20241227   Huging Face & LLM Tools - Graph Database 2/2 Neo4j continue.ipynb]( https://colab.research.google.com/drive/1j-DwNMGEDeh4dJARJ0Zcg1v3BMcAsU4Y?usp=sharing )\n",
        "\n",
        "32. [20250103   Huging Face & LLM Tools - NotebookLM.ipynb]( https://colab.research.google.com/drive/1KAQC8t9Z0AmB3O6qiEQmTc6fzFRtjGGo?usp=sharing )\n",
        "\n",
        "33. Gap week\n",
        "\n",
        "34. [20250117   Huging Face & LLM Tools - Gemini Deep Research.ipynb]( https://colab.research.google.com/drive/139r3EQRK8k0YvZHOyQP4nEcZzyA4nkhY?usp=sharing )\n",
        "\n",
        "35. [20250124    Huging Face & LLM Tools - CrewAI 1/2 Begining.ipynb]( https://colab.research.google.com/drive/1P2CaVTw1RaElFp5LU2eadaIzgGbbAJj2?usp=sharing )\n",
        "\n",
        "36. [20250131 Huging Face & LLM Tools - CrewAI 2/2 Advance.ipynb]( https://colab.research.google.com/drive/1J6JewQwHAO6Av3SnmsVlNofr5RrYeB22?usp=sharing )\n",
        "\n",
        "37. [20250207 Huging Face & LLM Tools LangGraph 1/3 Deeplearning.ipynb]( https://colab.research.google.com/drive/1XR77zFZdUOa_-PoQHZnGWKG8KSRzt2Me?usp=sharing )\n",
        "\n",
        "38. [20250214 Huging Face & LLM Tools LangGraph 2/3 LangChain Academy & LangSmith.ipynb]( https://colab.research.google.com/drive/1Ip7KT3FZZAWfJv3UZRfPxvBjSym7tRaN?usp=sharing )\n",
        "\n",
        "\n",
        "39. [20250221  Huging Face & LLM Tools LangGraph 3/3 LangChain Academy & Open Deep Research.ipynb]( https://colab.research.google.com/drive/1kGbcSs77ZtfSyrZDgywNU2UoG_84srEU?usp=sharing )\n",
        "\n",
        "40. [20250228  Huging Face & LLM Tools Microsoft AutoGen 1/2 DeeplearningAI.ipynb]( https://colab.research.google.com/drive/1dXdbB4ScHcWGAcC3MliL8IjPsvTF9Jsl?usp=sharing )\n",
        "\n",
        "41. [20250307   Huging Face & LLM Tools Microsoft AutoGen 2/2 AutoGen v0.4 MCP AutoGen Studio.ipynb]( https://colab.research.google.com/drive/1vX1AAfvcW9PTHkNN4hW6cExlxKg3Yeyx?usp=sharing )\n",
        "\n",
        "42. [20250314   Huging Face & LLM Tools n8n 1/2 Beginner.ipynb]( https://colab.research.google.com/drive/1Vk0fAginKDWOK_hJosCxXSq1xqejyraQ?usp=sharing )\n",
        "\n",
        "43. [20250321   Huging Face & LLM Tools n8n 2/2 Advance self hosting community nodes MPC.ipynb]( https://colab.research.google.com/drive/1whNl7nu1nJN8hY_IS6zz2BUm9RBqDfzU?usp=sharing )\n",
        "\n",
        "44. [20250328   Huging Face & LLM Tools Dify Plugin.ipynb]( https://colab.research.google.com/drive/1-4qNbhwsi4HyO7BrsmeC2-GHYCsMA2-q?usp=sharing )\n",
        "\n",
        "45. [20250404   Huging Face & LLM Tools Replit Vibe Coding.ipynb]( https://colab.research.google.com/drive/1rxIc4rJxvKvB4jXaj4dIhpugTBhyZFDk?usp=sharing )\n",
        "\n",
        "46. [20250411   Huging Face & LLM Tools OpenAI Agent SDK 1/2 .ipynb]( https://colab.research.google.com/drive/1rDqF8g-02vjLsW5v9fcCEXNQ6aF7_pAG?usp=sharing )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Appendix"
      ],
      "metadata": {
        "id": "Qkkq6_QmPApc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Responses API Walkthrough\n",
        "\n",
        "https://www.youtube.com/watch?v=0pGxoubWI6s\n",
        "https://github.com/daveebbelaar/ai-cookbook/tree/main/models/openai/05-responses\n",
        "\n",
        "https://www.youtube.com/watch?v=gyFu6xubdEk"
      ],
      "metadata": {
        "id": "97HiZ0TiYM9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI Agents SDK Cheatsheet\n",
        "\n",
        "## Installation & Setup\n",
        "\n",
        "```bash\n",
        "# Create a project and virtual environment\n",
        "mkdir my_project\n",
        "cd my_project\n",
        "python -m venv .venv\n",
        "\n",
        "# Activate the virtual environment\n",
        "source .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n",
        "\n",
        "# Install the Agents SDK\n",
        "pip install openai-agents\n",
        "\n",
        "# Set OpenAI API key\n",
        "export OPENAI_API_KEY=sk-...  # On Windows: set OPENAI_API_KEY=sk-...\n",
        "```\n",
        "\n",
        "## Agent Basics\n",
        "\n",
        "### Creating a Simple Agent\n",
        "\n",
        "```python\n",
        "from agents import Agent, Runner\n",
        "import asyncio\n",
        "\n",
        "# Define a basic agent\n",
        "agent = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=\"You are a helpful assistant that provides clear, concise answers.\"\n",
        ")\n",
        "\n",
        "# Run the agent\n",
        "async def main():\n",
        "    result = await Runner.run(agent, \"What is the capital of France?\")\n",
        "    print(result.final_output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n",
        "```\n",
        "\n",
        "### Agent with Tools\n",
        "\n",
        "```python\n",
        "from agents import Agent, function_tool\n",
        "\n",
        "# Define a tool using the decorator\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Get the current weather for a city.\n",
        "    \n",
        "    Args:\n",
        "        city: The name of the city to get weather for.\n",
        "    \"\"\"\n",
        "    # In a real app, call a weather API here\n",
        "    return f\"The weather in {city} is sunny and 75°F\"\n",
        "\n",
        "# Create agent with the tool\n",
        "agent = Agent(\n",
        "    name=\"Weather Assistant\",\n",
        "    instructions=\"Help users with weather-related queries.\",\n",
        "    tools=[get_weather]\n",
        ")\n",
        "```\n",
        "\n",
        "### Agent with Output Type\n",
        "\n",
        "```python\n",
        "from pydantic import BaseModel\n",
        "from agents import Agent\n",
        "\n",
        "class CalendarEvent(BaseModel):\n",
        "    name: str\n",
        "    date: str\n",
        "    participants: list[str]\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Calendar Assistant\",\n",
        "    instructions=\"Extract calendar events from user messages.\",\n",
        "    output_type=CalendarEvent\n",
        ")\n",
        "```\n",
        "\n",
        "## Agent Orchestration\n",
        "\n",
        "### Creating Agents with Handoffs\n",
        "\n",
        "```python\n",
        "from agents import Agent\n",
        "\n",
        "# Create specialist agents\n",
        "history_agent = Agent(\n",
        "    name=\"History Tutor\",\n",
        "    handoff_description=\"Specialist for historical questions\",\n",
        "    instructions=\"You provide assistance with historical queries. Explain important events and context clearly.\"\n",
        ")\n",
        "\n",
        "math_agent = Agent(\n",
        "    name=\"Math Tutor\",\n",
        "    handoff_description=\"Specialist for math questions\",\n",
        "    instructions=\"You provide help with math problems. Explain your reasoning at each step.\"\n",
        ")\n",
        "\n",
        "# Create a triage agent with handoffs\n",
        "triage_agent = Agent(\n",
        "    name=\"Triage Agent\",\n",
        "    instructions=\"Determine which specialist to use based on the user's question\",\n",
        "    handoffs=[history_agent, math_agent]\n",
        ")\n",
        "```\n",
        "\n",
        "### Customizing Handoffs\n",
        "\n",
        "```python\n",
        "from agents import Agent, handoff\n",
        "from agents.extensions import handoff_filters\n",
        "\n",
        "# Create a specialized agent\n",
        "faq_agent = Agent(\n",
        "    name=\"FAQ Agent\",\n",
        "    instructions=\"Answer frequently asked questions about our product.\"\n",
        ")\n",
        "\n",
        "# Create customized handoff\n",
        "handoff_obj = handoff(\n",
        "    agent=faq_agent,\n",
        "    tool_name_override=\"transfer_to_faq_specialist\",\n",
        "    tool_description_override=\"Transfer to the FAQ specialist for product questions\",\n",
        "    input_filter=handoff_filters.remove_all_tools\n",
        ")\n",
        "\n",
        "# Use the handoff in another agent\n",
        "main_agent = Agent(\n",
        "    name=\"Main Agent\",\n",
        "    instructions=\"Help users with their queries. Transfer to specialists as needed.\",\n",
        "    handoffs=[handoff_obj]\n",
        ")\n",
        "```\n",
        "\n",
        "## Tools\n",
        "\n",
        "### Function Tools\n",
        "\n",
        "```python\n",
        "from agents import Agent, function_tool\n",
        "from typing import Dict, List\n",
        "\n",
        "@function_tool\n",
        "def search_database(query: str) -> List[Dict]:\n",
        "    \"\"\"Search the database for information.\n",
        "    \n",
        "    Args:\n",
        "        query: The search query string.\n",
        "    \"\"\"\n",
        "    # Implement database search here\n",
        "    return [{\"title\": \"Sample result\", \"content\": \"Sample content\"}]\n",
        "\n",
        "@function_tool\n",
        "def calculate_total(items: List[Dict[str, float]]) -> float:\n",
        "    \"\"\"Calculate the total price of multiple items.\n",
        "    \n",
        "    Args:\n",
        "        items: List of items with their prices.\n",
        "    \"\"\"\n",
        "    return sum(item[\"price\"] for item in items)\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Database Assistant\",\n",
        "    instructions=\"Help users search the database and calculate totals.\",\n",
        "    tools=[search_database, calculate_total]\n",
        ")\n",
        "```\n",
        "\n",
        "### OpenAI Hosted Tools\n",
        "\n",
        "```python\n",
        "from agents import Agent, WebSearchTool, FileSearchTool\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Research Assistant\",\n",
        "    instructions=\"Help users find information online and from our knowledge base.\",\n",
        "    tools=[\n",
        "        WebSearchTool(),\n",
        "        FileSearchTool(\n",
        "            max_num_results=3,\n",
        "            vector_store_ids=[\"YOUR_VECTOR_STORE_ID\"]\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "```\n",
        "\n",
        "### Agents as Tools\n",
        "\n",
        "```python\n",
        "from agents import Agent\n",
        "\n",
        "translator_spanish = Agent(\n",
        "    name=\"Spanish Translator\",\n",
        "    instructions=\"Translate text to Spanish accurately and naturally.\"\n",
        ")\n",
        "\n",
        "translator_french = Agent(\n",
        "    name=\"French Translator\",\n",
        "    instructions=\"Translate text to French accurately and naturally.\"\n",
        ")\n",
        "\n",
        "orchestrator = Agent(\n",
        "    name=\"Translation Hub\",\n",
        "    instructions=\"Help users translate text to different languages.\",\n",
        "    tools=[\n",
        "        translator_spanish.as_tool(\n",
        "            tool_name=\"translate_to_spanish\",\n",
        "            tool_description=\"Translate the user's text to Spanish\"\n",
        "        ),\n",
        "        translator_french.as_tool(\n",
        "            tool_name=\"translate_to_french\",\n",
        "            tool_description=\"Translate the user's text to French\"\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "```\n",
        "\n",
        "## Guardrails\n",
        "\n",
        "```python\n",
        "from agents import Agent, InputGuardrail, GuardrailFunctionOutput, Runner\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# Define output structure for guardrail\n",
        "class HomeworkCheck(BaseModel):\n",
        "    is_homework: bool\n",
        "    reasoning: str\n",
        "\n",
        "# Create guardrail agent\n",
        "guardrail_agent = Agent(\n",
        "    name=\"Guardrail Check\",\n",
        "    instructions=\"Check if the user is asking about homework.\",\n",
        "    output_type=HomeworkCheck\n",
        ")\n",
        "\n",
        "# Define guardrail function\n",
        "async def homework_guardrail(ctx, agent, input_data):\n",
        "    result = await Runner.run(guardrail_agent, input_data, context=ctx.context)\n",
        "    final_output = result.final_output_as(HomeworkCheck)\n",
        "    \n",
        "    return GuardrailFunctionOutput(\n",
        "        output_info=final_output,\n",
        "        tripwire_triggered=not final_output.is_homework\n",
        "    )\n",
        "\n",
        "# Apply guardrail to agent\n",
        "agent_with_guardrail = Agent(\n",
        "    name=\"Homework Helper\",\n",
        "    instructions=\"Help with legitimate educational questions, not just giving homework answers.\",\n",
        "    input_guardrails=[\n",
        "        InputGuardrail(guardrail_function=homework_guardrail)\n",
        "    ]\n",
        ")\n",
        "```\n",
        "\n",
        "## Context Management\n",
        "\n",
        "```python\n",
        "from dataclasses import dataclass\n",
        "from agents import Agent, RunContextWrapper, function_tool, Runner\n",
        "\n",
        "# Define context structure\n",
        "@dataclass\n",
        "class UserContext:\n",
        "    user_id: str\n",
        "    username: str\n",
        "    is_premium: bool\n",
        "\n",
        "# Create a tool that uses context\n",
        "@function_tool\n",
        "def get_user_info(ctx: RunContextWrapper[UserContext]) -> str:\n",
        "    \"\"\"Get information about the current user.\"\"\"\n",
        "    user = ctx.context\n",
        "    return f\"User: {user.username} (ID: {user.user_id}), Premium: {user.is_premium}\"\n",
        "\n",
        "# Create agent with context type\n",
        "agent = Agent[UserContext](\n",
        "    name=\"User-Aware Assistant\",\n",
        "    instructions=\"Provide personalized assistance based on the user's information.\",\n",
        "    tools=[get_user_info]\n",
        ")\n",
        "\n",
        "# Use the agent with context\n",
        "async def main():\n",
        "    user_context = UserContext(\n",
        "        user_id=\"12345\",\n",
        "        username=\"john_doe\",\n",
        "        is_premium=True\n",
        "    )\n",
        "    \n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"Tell me about my account\",\n",
        "        context=user_context\n",
        "    )\n",
        "    print(result.final_output)\n",
        "```\n",
        "\n",
        "## Running Agents\n",
        "\n",
        "### Basic Running\n",
        "\n",
        "```python\n",
        "from agents import Agent, Runner\n",
        "import asyncio\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Assistant\",\n",
        "        instructions=\"You are a helpful assistant.\"\n",
        "    )\n",
        "    \n",
        "    # Async run\n",
        "    result = await Runner.run(agent, \"Write a haiku about programming.\")\n",
        "    print(result.final_output)\n",
        "    \n",
        "    # For synchronous code, use run_sync instead\n",
        "    # result = Runner.run_sync(agent, \"Write a haiku about programming.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n",
        "```\n",
        "\n",
        "### Streaming\n",
        "\n",
        "```python\n",
        "from agents import Agent, Runner\n",
        "import asyncio\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Storyteller\",\n",
        "        instructions=\"You create engaging short stories.\"\n",
        "    )\n",
        "    \n",
        "    # Get streaming result\n",
        "    result = Runner.run_streamed(\n",
        "        agent,\n",
        "        input=\"Tell me a short story about a robot learning to paint.\"\n",
        "    )\n",
        "    \n",
        "    # Print content as it's generated\n",
        "    print(\"Story is being written...\")\n",
        "    async for event in result.stream_events():\n",
        "        if event.type == \"raw_response_event\":\n",
        "            if hasattr(event.data, \"delta\"):\n",
        "                print(event.data.delta, end=\"\", flush=True)\n",
        "    \n",
        "    print(\"\\n\\nStory complete!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n",
        "```\n",
        "\n",
        "### Multi-turn Conversations\n",
        "\n",
        "```python\n",
        "from agents import Agent, Runner\n",
        "import asyncio\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Conversation Agent\",\n",
        "        instructions=\"You are a helpful assistant that maintains context throughout a conversation.\"\n",
        "    )\n",
        "    \n",
        "    # First turn\n",
        "    result = await Runner.run(agent, \"What's the capital of Japan?\")\n",
        "    print(f\"Agent: {result.final_output}\")\n",
        "    \n",
        "    # Second turn (using previous context)\n",
        "    new_input = result.to_input_list() + [{\"role\": \"user\", \"content\": \"What about South Korea?\"}]\n",
        "    result = await Runner.run(agent, new_input)\n",
        "    print(f\"Agent: {result.final_output}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n",
        "```\n",
        "\n",
        "## Model Configuration\n",
        "\n",
        "```python\n",
        "from agents import Agent, ModelSettings, Runner\n",
        "\n",
        "# Configure model settings\n",
        "agent = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=\"You are a helpful, concise assistant.\",\n",
        "    model=\"o3-mini\",  # Specify model name\n",
        "    model_settings=ModelSettings(\n",
        "        temperature=0.7,\n",
        "        top_p=0.95,\n",
        "        max_tokens=1000\n",
        "    )\n",
        ")\n",
        "\n",
        "# Or override at runtime\n",
        "async def main():\n",
        "    result = await Runner.run(\n",
        "        agent,\n",
        "        \"Explain quantum computing briefly\",\n",
        "        run_config=RunConfig(\n",
        "            model=\"gpt-4o\",\n",
        "            model_settings=ModelSettings(temperature=0)\n",
        "        )\n",
        "    )\n",
        "    print(result.final_output)\n",
        "```\n",
        "\n",
        "## Dynamic Instructions\n",
        "\n",
        "```python\n",
        "from agents import Agent, RunContextWrapper\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class UserProfile:\n",
        "    name: str\n",
        "    language: str\n",
        "    expertise_level: str\n",
        "\n",
        "def dynamic_instructions(\n",
        "    context: RunContextWrapper[UserProfile],\n",
        "    agent: Agent[UserProfile]\n",
        ") -> str:\n",
        "    profile = context.context\n",
        "    return f\"\"\"\n",
        "    You are a helpful assistant for {profile.name}.\n",
        "    Communicate in {profile.language}.\n",
        "    Adjust explanations to a {profile.expertise_level} level of expertise.\n",
        "    Be friendly, clear, and concise in your responses.\n",
        "    \"\"\"\n",
        "\n",
        "agent = Agent[UserProfile](\n",
        "    name=\"Adaptive Assistant\",\n",
        "    instructions=dynamic_instructions\n",
        ")\n",
        "```\n",
        "\n",
        "## Error Handling\n",
        "\n",
        "```python\n",
        "from agents import Agent, function_tool, Runner\n",
        "import asyncio\n",
        "\n",
        "# Custom error handler for tools\n",
        "def handle_tool_error(error, function_name, args):\n",
        "    if isinstance(error, ValueError):\n",
        "        return f\"I couldn't process your request. The value provided was invalid: {str(error)}\"\n",
        "    return f\"An unexpected error occurred: {str(error)}\"\n",
        "\n",
        "@function_tool(failure_error_function=handle_tool_error)\n",
        "def divide_numbers(a: float, b: float) -> float:\n",
        "    \"\"\"Divide two numbers.\n",
        "    \n",
        "    Args:\n",
        "        a: The dividend\n",
        "        b: The divisor (must not be zero)\n",
        "    \"\"\"\n",
        "    if b == 0:\n",
        "        raise ValueError(\"Cannot divide by zero\")\n",
        "    return a / b\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Calculator\",\n",
        "    instructions=\"Help users with mathematical calculations.\",\n",
        "    tools=[divide_numbers]\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    try:\n",
        "        result = await Runner.run(agent, \"What is 10 divided by 0?\")\n",
        "        print(result.final_output)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n",
        "```\n",
        "\n",
        "## Tracing\n",
        "\n",
        "```python\n",
        "from agents import Agent, Runner, trace, set_tracing_disabled\n",
        "\n",
        "# Disable tracing globally\n",
        "# set_tracing_disabled(True)\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Assistant\",\n",
        "        instructions=\"You are a helpful assistant.\"\n",
        "    )\n",
        "    \n",
        "    # Add trace information for this run\n",
        "    with trace(\n",
        "        workflow_name=\"Customer Support\",\n",
        "        group_id=\"user_session_123\",\n",
        "        trace_metadata={\"customer_id\": \"cust_123\", \"channel\": \"chat\"}\n",
        "    ):\n",
        "        result = await Runner.run(agent, \"I need help with my order\")\n",
        "        print(result.final_output)\n",
        "    \n",
        "    # View traces in the OpenAI Dashboard: https://platform.openai.com/traces\n",
        "```\n",
        "\n",
        "## Complete Example: Multi-Agent System\n",
        "\n",
        "```python\n",
        "from agents import Agent, Runner, function_tool, InputGuardrail, GuardrailFunctionOutput\n",
        "from pydantic import BaseModel\n",
        "import asyncio\n",
        "\n",
        "# 1. Define tools\n",
        "@function_tool\n",
        "def get_product_info(product_id: str) -> dict:\n",
        "    \"\"\"Get information about a product.\n",
        "    \n",
        "    Args:\n",
        "        product_id: The unique identifier for the product\n",
        "    \"\"\"\n",
        "    # Mock database lookup\n",
        "    products = {\n",
        "        \"p123\": {\"name\": \"Wireless Headphones\", \"price\": 99.99, \"in_stock\": True},\n",
        "        \"p456\": {\"name\": \"Smart Watch\", \"price\": 249.99, \"in_stock\": False}\n",
        "    }\n",
        "    return products.get(product_id, {\"error\": \"Product not found\"})\n",
        "\n",
        "# 2. Define guardrail check\n",
        "class ProfanityCheck(BaseModel):\n",
        "    contains_profanity: bool\n",
        "    reasoning: str\n",
        "\n",
        "profanity_agent = Agent(\n",
        "    name=\"Profanity Check\",\n",
        "    instructions=\"Check if the user's message contains profanity or inappropriate language.\",\n",
        "    output_type=ProfanityCheck\n",
        ")\n",
        "\n",
        "async def profanity_guardrail(ctx, agent, input_data):\n",
        "    result = await Runner.run(profanity_agent, input_data, context=ctx.context)\n",
        "    final_output = result.final_output_as(ProfanityCheck)\n",
        "    \n",
        "    return GuardrailFunctionOutput(\n",
        "        output_info=final_output,\n",
        "        tripwire_triggered=final_output.contains_profanity\n",
        "    )\n",
        "\n",
        "# 3. Create specialized agents\n",
        "product_agent = Agent(\n",
        "    name=\"Product Specialist\",\n",
        "    handoff_description=\"Specialist for product-related questions\",\n",
        "    instructions=\"You help customers with product information, features, and comparisons.\",\n",
        "    tools=[get_product_info]\n",
        ")\n",
        "\n",
        "support_agent = Agent(\n",
        "    name=\"Support Specialist\",\n",
        "    handoff_description=\"Specialist for customer support issues\",\n",
        "    instructions=\"You help customers with order issues, returns, and technical support.\"\n",
        ")\n",
        "\n",
        "# 4. Create main triage agent\n",
        "triage_agent = Agent(\n",
        "    name=\"Customer Service\",\n",
        "    instructions=\"\"\"\n",
        "    You are the initial point of contact for customer inquiries.\n",
        "    Analyze the customer's question and route to the appropriate specialist:\n",
        "    - Route product questions to the Product Specialist\n",
        "    - Route support issues to the Support Specialist\n",
        "    - For simple questions, answer directly\n",
        "    \"\"\",\n",
        "    handoffs=[product_agent, support_agent],\n",
        "    input_guardrails=[\n",
        "        InputGuardrail(guardrail_function=profanity_guardrail)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 5. Run the system\n",
        "async def main():\n",
        "    # Run with a product question\n",
        "    result = await Runner.run(\n",
        "        triage_agent,\n",
        "        \"Can you tell me more about the wireless headphones with product ID p123?\"\n",
        "    )\n",
        "    print(\"RESULT 1:\\n\", result.final_output)\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "    \n",
        "    # Run with a support question\n",
        "    result = await Runner.run(\n",
        "        triage_agent,\n",
        "        \"I ordered something 3 days ago but haven't received a shipping confirmation.\"\n",
        "    )\n",
        "    print(\"RESULT 2:\\n\", result.final_output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n",
        "```\n"
      ],
      "metadata": {
        "id": "GyobHqGIzi-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI Agents SDK Cheat Sheet\n",
        "\n",
        "## AGENT BASICS\n",
        "Creating and configuring agents\n",
        "```python\n",
        "# Create a simple agent\n",
        "agent = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=\"You are a helpful assistant.\",\n",
        "    model=\"o3-mini\"  # Optional model specification\n",
        ")\n",
        "\n",
        "# Agent with output type\n",
        "agent = Agent(\n",
        "    name=\"Calendar Assistant\",\n",
        "    instructions=\"Extract calendar events.\",\n",
        "    output_type=CalendarEvent  # Pydantic model\n",
        ")\n",
        "\n",
        "# Clone and modify an agent\n",
        "robot_agent = pirate_agent.clone(\n",
        "    name=\"Robot\",\n",
        "    instructions=\"Write like a robot\"\n",
        ")\n",
        "```\n",
        "\n",
        "## TOOLS\n",
        "Enabling agents to take actions\n",
        "```python\n",
        "# Function tool using decorator\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Get weather for a city.\"\"\"\n",
        "    return f\"The weather in {city} is sunny\"\n",
        "\n",
        "# Hosted tools from OpenAI\n",
        "agent = Agent(\n",
        "    tools=[\n",
        "        WebSearchTool(),\n",
        "        FileSearchTool(vector_store_ids=[\"STORE_ID\"])\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Agent as a tool\n",
        "orchestrator = Agent(\n",
        "    tools=[\n",
        "        spanish_agent.as_tool(\n",
        "            tool_name=\"translate_to_spanish\",\n",
        "            tool_description=\"Translate to Spanish\"\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "```\n",
        "\n",
        "## HANDOFFS\n",
        "Delegating tasks between agents\n",
        "```python\n",
        "# Basic handoff\n",
        "triage_agent = Agent(\n",
        "    handoffs=[support_agent, billing_agent]\n",
        ")\n",
        "\n",
        "# Customized handoff\n",
        "handoff_obj = handoff(\n",
        "    agent=faq_agent,\n",
        "    tool_name_override=\"transfer_to_faq\",\n",
        "    input_filter=handoff_filters.remove_all_tools\n",
        ")\n",
        "\n",
        "# Handoff with input data\n",
        "class EscalationData(BaseModel):\n",
        "    reason: str\n",
        "\n",
        "handoff_obj = handoff(\n",
        "    agent=escalation_agent,\n",
        "    input_type=EscalationData\n",
        ")\n",
        "```\n",
        "\n",
        "## CONTEXT MANAGEMENT\n",
        "Working with context and state\n",
        "```python\n",
        "# Define context type\n",
        "@dataclass\n",
        "class UserContext:\n",
        "    user_id: str\n",
        "    username: str\n",
        "    is_premium: bool\n",
        "\n",
        "# Create agent with context\n",
        "agent = Agent[UserContext](\n",
        "    name=\"User-Aware Assistant\",\n",
        "    instructions=\"Provide personalized help.\"\n",
        ")\n",
        "\n",
        "# Access context in tools\n",
        "@function_tool\n",
        "def get_user_info(ctx: RunContextWrapper[UserContext]) -> str:\n",
        "    return f\"User: {ctx.context.username}\"\n",
        "\n",
        "# Run with context\n",
        "result = await Runner.run(\n",
        "    agent, \"Help me\",\n",
        "    context=UserContext(user_id=\"123\", username=\"john\", is_premium=True)\n",
        ")\n",
        "```\n",
        "\n",
        "## GUARDRAILS\n",
        "Protecting and validating inputs/outputs\n",
        "```python\n",
        "# Create guardrail check\n",
        "class ContentCheck(BaseModel):\n",
        "    is_appropriate: bool\n",
        "    reasoning: str\n",
        "\n",
        "guardrail_agent = Agent(\n",
        "    output_type=ContentCheck\n",
        ")\n",
        "\n",
        "# Define guardrail function\n",
        "async def content_guardrail(ctx, agent, input_data):\n",
        "    result = await Runner.run(guardrail_agent, input_data)\n",
        "    output = result.final_output_as(ContentCheck)\n",
        "    \n",
        "    return GuardrailFunctionOutput(\n",
        "        output_info=output,\n",
        "        tripwire_triggered=not output.is_appropriate\n",
        "    )\n",
        "\n",
        "# Apply guardrail to agent\n",
        "agent = Agent(\n",
        "    input_guardrails=[\n",
        "        InputGuardrail(guardrail_function=content_guardrail)\n",
        "    ]\n",
        ")\n",
        "```\n",
        "\n",
        "## RUNNING AGENTS\n",
        "Executing and managing agent runs\n",
        "```python\n",
        "# Basic run (async)\n",
        "result = await Runner.run(agent, \"What is the capital of France?\")\n",
        "print(result.final_output)\n",
        "\n",
        "# Sync run\n",
        "result = Runner.run_sync(agent, \"Tell me a joke\")\n",
        "\n",
        "# Streaming run\n",
        "result = Runner.run_streamed(agent, \"Write a story\")\n",
        "async for event in result.stream_events():\n",
        "    # Process streaming events\n",
        "    pass\n",
        "\n",
        "# Multi-turn conversations\n",
        "new_input = result.to_input_list() + [\n",
        "    {\"role\": \"user\", \"content\": \"Follow-up question\"}\n",
        "]\n",
        "result = await Runner.run(agent, new_input)\n",
        "```\n",
        "\n",
        "## MODELS & CONFIGURATION\n",
        "Configuring models and run settings\n",
        "```python\n",
        "# Set model and settings on agent\n",
        "agent = Agent(\n",
        "    model=\"o3-mini\",\n",
        "    model_settings=ModelSettings(\n",
        "        temperature=0.7,\n",
        "        top_p=0.95\n",
        "    )\n",
        ")\n",
        "\n",
        "# Configure run settings\n",
        "result = await Runner.run(\n",
        "    agent, \"Question\",\n",
        "    run_config=RunConfig(\n",
        "        model=\"gpt-4o\",\n",
        "        workflow_name=\"Customer Support\",\n",
        "        trace_id=\"session_123\",\n",
        "        trace_metadata={\"customer_id\": \"cust_123\"}\n",
        "    )\n",
        ")\n",
        "```\n",
        "\n",
        "## DYNAMIC INSTRUCTIONS\n",
        "Context-aware prompting\n",
        "```python\n",
        "def dynamic_instructions(\n",
        "    context: RunContextWrapper[UserProfile],\n",
        "    agent: Agent[UserProfile]\n",
        ") -> str:\n",
        "    profile = context.context\n",
        "    return f\"\"\"\n",
        "    You are helping {profile.name}.\n",
        "    Communicate in {profile.language}.\n",
        "    \"\"\"\n",
        "\n",
        "agent = Agent[UserProfile](\n",
        "    instructions=dynamic_instructions\n",
        ")\n",
        "```\n",
        "\n",
        "## COMPLETE WORKFLOW EXAMPLE\n",
        "Putting it all together\n",
        "```python\n",
        "# 1. Create specialist agents\n",
        "product_agent = Agent(\n",
        "    name=\"Product Specialist\",\n",
        "    handoff_description=\"For product questions\",\n",
        "    tools=[get_product_info]\n",
        ")\n",
        "\n",
        "support_agent = Agent(\n",
        "    name=\"Support Specialist\",\n",
        "    handoff_description=\"For customer support issues\"\n",
        ")\n",
        "\n",
        "# 2. Create triage agent with handoffs\n",
        "triage_agent = Agent(\n",
        "    name=\"Customer Service\",\n",
        "    instructions=\"Route to appropriate specialist\",\n",
        "    handoffs=[product_agent, support_agent],\n",
        "    input_guardrails=[\n",
        "        InputGuardrail(guardrail_function=profanity_guardrail)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 3. Run the system\n",
        "async def main():\n",
        "    result = await Runner.run(\n",
        "        triage_agent,\n",
        "        \"Can you tell me about product p123?\"\n",
        "    )\n",
        "    print(result.final_output)\n",
        "```\n",
        "\n",
        "OpenAI Agents SDK is a Python toolkit for creating and orchestrating LLM-powered agents. This cheat sheet covers the most important commands and patterns for quick reference.\n"
      ],
      "metadata": {
        "id": "ewDFo2-Cz61I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## level3"
      ],
      "metadata": {
        "id": "KKEIzEFQr5wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import asyncio\n",
        "import os\n",
        "import time\n",
        "from typing import List, Optional, Tuple, Dict, Any\n",
        "from pydantic import BaseModel, Field\n",
        "from datetime import datetime\n",
        "\n",
        "# Try importing the agents SDK components\n",
        "try:\n",
        "    from agents import Agent, Runner, WebSearchTool, trace\n",
        "    from openai import OpenAI, APIError, AuthenticationError\n",
        "    AGENTS_SDK_AVAILABLE = True\n",
        "except ImportError:\n",
        "    AGENTS_SDK_AVAILABLE = False\n",
        "    st.error(\"Agents SDK not found. Some functionality will be simulated.\")\n",
        "\n",
        "# Define ReportData as a global model - simplified for robustness\n",
        "class ReportData(BaseModel):\n",
        "    short_summary: str = Field(..., description=\"A concise summary of the research findings (1-2 paragraphs)\")\n",
        "    markdown_report: str = Field(..., description=\"Brief markdown-formatted report (500-800 words)\")\n",
        "    follow_up_questions: List[str] = Field(default_factory=list, description=\"2-3 suggested follow-up questions\")\n",
        "\n",
        "# Planner Agent\n",
        "class WebSearchItem(BaseModel):\n",
        "    reason: str\n",
        "    query: str\n",
        "\n",
        "class WebSearchPlan(BaseModel):\n",
        "    searches: List[WebSearchItem]\n",
        "\n",
        "# Handoff tracking\n",
        "class HandoffEvent(BaseModel):\n",
        "    from_agent: str\n",
        "    to_agent: str\n",
        "    reason: str\n",
        "    input: str\n",
        "    output: str\n",
        "    timestamp: str\n",
        "\n",
        "    @classmethod\n",
        "    def create(cls, from_agent, to_agent, reason, input_data, output_data):\n",
        "        # Truncate long inputs/outputs for display\n",
        "        input_str = str(input_data)\n",
        "        output_str = str(output_data)\n",
        "\n",
        "        if len(input_str) > 200:\n",
        "            input_str = input_str[:197] + \"...\"\n",
        "        if len(output_str) > 200:\n",
        "            output_str = output_str[:197] + \"...\"\n",
        "\n",
        "        return cls(\n",
        "            from_agent=from_agent,\n",
        "            to_agent=to_agent,\n",
        "            reason=reason,\n",
        "            input=input_str,\n",
        "            output=output_str,\n",
        "            timestamp=datetime.now().strftime(\"%H:%M:%S\")\n",
        "        )\n",
        "\n",
        "# Function to validate API key\n",
        "def validate_openai_key(api_key: str) -> Tuple[bool, Optional[str]]:\n",
        "    \"\"\"\n",
        "    Validate the OpenAI API key\n",
        "\n",
        "    Returns:\n",
        "    - Tuple of (is_valid, error_message)\n",
        "    - is_valid: Boolean indicating if the key is valid\n",
        "    - error_message: Detailed error message if validation fails\n",
        "    \"\"\"\n",
        "    if not api_key or api_key.strip() == \"\":\n",
        "        return False, \"API Key cannot be empty.\"\n",
        "\n",
        "    try:\n",
        "        if AGENTS_SDK_AVAILABLE:\n",
        "            client = OpenAI(api_key=api_key)\n",
        "            # Light validation check - just checking if the key format is valid\n",
        "            # Don't actually call the API to avoid unnecessary costs\n",
        "            if api_key.startswith(\"sk-\") and len(api_key) > 20:\n",
        "                return True, None\n",
        "            else:\n",
        "                return False, \"Invalid API key format. OpenAI API keys typically start with 'sk-'\"\n",
        "        else:\n",
        "            # When SDK not available, just do format validation\n",
        "            if api_key.startswith(\"sk-\") and len(api_key) > 20:\n",
        "                return True, None\n",
        "            else:\n",
        "                return False, \"Invalid API key format. OpenAI API keys typically start with 'sk-'\"\n",
        "    except AuthenticationError:\n",
        "        return False, (\n",
        "            \"Authentication failed. Possible reasons:\\n\"\n",
        "            \"- Incorrect API key\\n\"\n",
        "            \"- Key has been revoked\\n\"\n",
        "            \"- Billing issues with your OpenAI account\"\n",
        "        )\n",
        "    except APIError as e:\n",
        "        return False, (\n",
        "            f\"API Error: {str(e)}\\n\"\n",
        "            \"Possible reasons:\\n\"\n",
        "            \"- Network connectivity issue\\n\"\n",
        "            \"- Temporary OpenAI service disruption\\n\"\n",
        "            \"- Invalid API key format\"\n",
        "        )\n",
        "    except Exception as e:\n",
        "        return False, (\n",
        "            f\"Unexpected error: {str(e)}\\n\"\n",
        "            \"Please check your API key and network connection.\"\n",
        "        )\n",
        "def setup_agents(api_key: str, num_searches: int, writer_model: str):\n",
        "    \"\"\"Set up agents with the provided API key and configuration\"\"\"\n",
        "    if not AGENTS_SDK_AVAILABLE:\n",
        "        # Return mock agents when SDK isn't available (unchanged)\n",
        "        class MockAgent:\n",
        "            def __init__(self, name, instructions=\"\", model=\"\"):\n",
        "                self.name = name\n",
        "                self.instructions = instructions\n",
        "                self.model = model\n",
        "\n",
        "        # Mock agent setup (unchanged)\n",
        "        # ...\n",
        "\n",
        "        return runner_agent\n",
        "\n",
        "    # Real implementation with Agents SDK\n",
        "    # Configure the OpenAI client globally\n",
        "    os.environ['OPENAI_API_KEY'] = api_key\n",
        "\n",
        "    # Writer Agent - Simple prompt with clear instructions\n",
        "    WRITER_PROMPT = (\n",
        "        \"You are a research writer creating a report from search results. \"\n",
        "        \"You will receive a query and search results from the SearchAgent. \"\n",
        "        \"Your task is to compile the findings into a comprehensive report with: \"\n",
        "        \"1. A concise summary (1-2 paragraphs) \"\n",
        "        \"2. A markdown-formatted report (500-800 words) \"\n",
        "        \"3. 2-3 follow-up questions\\n\\n\"\n",
        "        \"Do NOT hand off to any other agent. You are the final step in the research process.\"\n",
        "    )\n",
        "\n",
        "    # Create the writer agent with standard settings - no handoffs needed as it's the final agent\n",
        "    writer_agent = Agent(\n",
        "        name=\"WriterAgent\",\n",
        "        instructions=WRITER_PROMPT,\n",
        "        model=writer_model,\n",
        "        output_type=ReportData,\n",
        "    )\n",
        "\n",
        "    # Search Agent - Simplified and more focused instructions with explicit handoff\n",
        "    SEARCH_INSTRUCTIONS = (\n",
        "        \"You are a research assistant performing web searches. \"\n",
        "        \"You will receive search queries from the PlannerAgent. \"\n",
        "        \"For each search term:\\n\"\n",
        "        \"1. Extract key facts and insights relevant to the query\\n\"\n",
        "        \"2. Focus on objective information from reliable sources\\n\"\n",
        "        \"3. Create a brief summary (150-200 words maximum)\\n\"\n",
        "        \"4. Format information as bullet points whenever possible\\n\"\n",
        "        \"5. Prioritize recent and factual information\\n\\n\"\n",
        "        \"After completing ALL searches, you MUST hand off to the WriterAgent by using the transfer_to_writeragent function. \"\n",
        "        \"Do NOT hand off after each individual search - only after all searches are complete.\"\n",
        "    )\n",
        "\n",
        "    # Create the search agent with handoff to writer\n",
        "    search_agent = Agent(\n",
        "        name=\"SearchAgent\",\n",
        "        instructions=SEARCH_INSTRUCTIONS,\n",
        "        tools=[WebSearchTool(user_location={\"type\": \"approximate\", \"city\": \"New York\"})],\n",
        "        handoffs=[writer_agent],  # Search hands off to Writer\n",
        "    )\n",
        "\n",
        "    # Updated Planner Prompt with explicit handoff instructions\n",
        "    PLANNER_PROMPT = (\n",
        "        \"You are a helpful research assistant. Given a query from the RunnerAgent, \"\n",
        "        f\"come up with a set of web searches to perform to best answer the query. \"\n",
        "        f\"Output between 1-{num_searches} search terms to query for.\\n\\n\"\n",
        "        \"IMPORTANT: You MUST output your search plan in the format required by WebSearchPlan, with a 'searches' array \"\n",
        "        \"containing objects with 'reason' and 'query' fields.\\n\\n\"\n",
        "        \"AFTER creating your search plan, you MUST ALWAYS hand off to the SearchAgent by using the transfer_to_searchagent \"\n",
        "        \"function call. Do NOT try to conduct the searches yourself.\\n\\n\"\n",
        "        \"Workflow steps:\\n\"\n",
        "        \"1. Create your search plan\\n\"\n",
        "        \"2. Output the search plan in the required format\\n\"\n",
        "        \"3. Call the transfer_to_searchagent function to hand off\"\n",
        "    )\n",
        "\n",
        "    # Create the planner agent with handoff to search\n",
        "    planner_agent = Agent(\n",
        "        name=\"PlannerAgent\",\n",
        "        instructions=PLANNER_PROMPT,\n",
        "        model=\"gpt-4o\",\n",
        "        output_type=WebSearchPlan,\n",
        "        handoffs=[search_agent],  # Planner hands off to Search\n",
        "    )\n",
        "\n",
        "    # Runner Agent with explicit sequential instructions\n",
        "    RUNNER_PROMPT = (\n",
        "        \"You are a research workflow coordinator. Your job is to start a sequential research process. \"\n",
        "        \"For any research query, IMMEDIATELY hand off to the PlannerAgent by using the transfer_to_planneragent function. \"\n",
        "        \"The research process will then follow this exact sequence:\\n\"\n",
        "        \"1. PlannerAgent will create search queries and hand off to SearchAgent\\n\"\n",
        "        \"2. SearchAgent will execute searches and hand off to WriterAgent\\n\"\n",
        "        \"3. WriterAgent will compile the findings into a final report\\n\\n\"\n",
        "        \"Your only task is to start this process by handing off to the PlannerAgent.\"\n",
        "    )\n",
        "\n",
        "    # Create the runner agent with initial handoff only to the planner\n",
        "    runner_agent = Agent(\n",
        "        name=\"RunnerAgent\",\n",
        "        instructions=RUNNER_PROMPT,\n",
        "        model=\"gpt-4o\",\n",
        "        handoffs=[planner_agent],  # Runner hands off to Planner\n",
        "    )\n",
        "\n",
        "    return runner_agent\n",
        "async def perform_research(query: str, runner_agent, session_state):\n",
        "    \"\"\"Async function to perform the research workflow using a runner agent\"\"\"\n",
        "    handoff_details = []\n",
        "    search_details = []\n",
        "\n",
        "    # Initialize the progress container\n",
        "    progress_container = st.empty()\n",
        "    progress_bar = progress_container.progress(0)\n",
        "    status_text = st.empty()\n",
        "    error_container = st.empty()\n",
        "\n",
        "    if not AGENTS_SDK_AVAILABLE:\n",
        "        # Simulate the research process\n",
        "        status_text.text(\"Runner agent coordinating research workflow...\")\n",
        "        await asyncio.sleep(1.5)\n",
        "\n",
        "        # First handoff to planner agent\n",
        "        status_text.text(\"Handing off to planning agent...\")\n",
        "        progress_bar.progress(0.2)\n",
        "        await asyncio.sleep(1.5)\n",
        "\n",
        "        # Mock search plan\n",
        "        search_plan = WebSearchPlan(searches=[\n",
        "            WebSearchItem(reason=\"To get latest information\", query=f\"latest developments in {query}\"),\n",
        "            WebSearchItem(reason=\"To get historical context\", query=f\"history of {query}\"),\n",
        "            WebSearchItem(reason=\"To get expert opinions\", query=f\"expert analysis {query}\"),\n",
        "        ])\n",
        "\n",
        "        # Record handoff details\n",
        "        handoff_details.append(HandoffEvent.create(\n",
        "            from_agent=\"RunnerAgent\",\n",
        "            to_agent=\"PlannerAgent\",\n",
        "            reason=\"Planning search strategy\",\n",
        "            input_data=query,\n",
        "            output_data=f\"Created search plan with {len(search_plan.searches)} queries\"\n",
        "        ))\n",
        "\n",
        "        # Second handoff to search agent\n",
        "        status_text.text(\"Handing off to search agent...\")\n",
        "        progress_bar.progress(0.4)\n",
        "        await asyncio.sleep(1.5)\n",
        "\n",
        "        # Mock search results\n",
        "        for i, item in enumerate(search_plan.searches):\n",
        "            status_text.text(f\"Searching: {item.query}\")\n",
        "            await asyncio.sleep(1)\n",
        "\n",
        "            # Mock search result\n",
        "            search_result = f\"Found information about {item.query}. This includes various sources and citations relevant to the query.\"\n",
        "\n",
        "            # Collect detailed run information\n",
        "            search_details.append({\n",
        "                \"query\": item.query,\n",
        "                \"reason\": item.reason,\n",
        "                \"result\": search_result,\n",
        "            })\n",
        "\n",
        "            # Update progress\n",
        "            progress = 0.4 + (0.3 * (i+1) / len(search_plan.searches))\n",
        "            progress_bar.progress(progress)\n",
        "\n",
        "        # Record combined handoff details for search\n",
        "        handoff_details.append(HandoffEvent.create(\n",
        "            from_agent=\"PlannerAgent\",\n",
        "            to_agent=\"SearchAgent\",\n",
        "            reason=\"Execute web searches\",\n",
        "            input_data=\"Search plan with queries\",\n",
        "            output_data=f\"Completed {len(search_plan.searches)} searches\"\n",
        "        ))\n",
        "\n",
        "        # Third handoff to writer agent\n",
        "        status_text.text(\"Handing off to writer agent...\")\n",
        "        progress_bar.progress(0.8)\n",
        "        await asyncio.sleep(2)\n",
        "\n",
        "        # Mock report\n",
        "        report = ReportData(\n",
        "            short_summary=f\"This is a summary of research findings about {query}.\",\n",
        "            markdown_report=f\"\"\"\n",
        "# Comprehensive Research: {query}\n",
        "\n",
        "## Introduction\n",
        "This research explores {query} in depth, analyzing various aspects and perspectives.\n",
        "\n",
        "## Key Findings\n",
        "1. The first major finding about {query}\n",
        "2. The second major finding about {query}\n",
        "3. The third major finding about {query}\n",
        "\n",
        "## Historical Context\n",
        "{query} has a rich history dating back to its origins.\n",
        "\n",
        "## Expert Analysis\n",
        "Experts in the field suggest that {query} will continue to evolve.\n",
        "\n",
        "## Conclusion\n",
        "In conclusion, {query} represents an important area for further study.\n",
        "            \"\"\",\n",
        "            follow_up_questions=[\n",
        "                f\"What are the future trends for {query}?\",\n",
        "                f\"How does {query} compare to similar topics?\",\n",
        "                f\"What are the practical applications of {query}?\"\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Record handoff details\n",
        "        handoff_details.append(HandoffEvent.create(\n",
        "            from_agent=\"SearchAgent\",\n",
        "            to_agent=\"WriterAgent\",\n",
        "            reason=\"Compile research report\",\n",
        "            input_data=\"Collected search results\",\n",
        "            output_data=\"Creating comprehensive report\"\n",
        "        ))\n",
        "\n",
        "        # Update progress\n",
        "        progress_bar.progress(1.0)\n",
        "        status_text.text(\"Research complete!\")\n",
        "\n",
        "    else:\n",
        "        # Use actual Agents SDK with the runner agent\n",
        "        try:\n",
        "            # Start the research process\n",
        "            status_text.text(\"Starting research workflow with runner agent...\")\n",
        "            progress_bar.progress(0.1)\n",
        "\n",
        "            # Add first handoff for UI display (User to Runner)\n",
        "            handoff_details.append(HandoffEvent.create(\n",
        "                from_agent=\"User\",\n",
        "                to_agent=\"RunnerAgent\",\n",
        "                reason=\"Initial query submission\",\n",
        "                input_data=query,\n",
        "                output_data=\"Initiating research workflow\"\n",
        "            ))\n",
        "\n",
        "            # Update UI for first handoff\n",
        "            status_text.text(\"Runner agent analyzing query...\")\n",
        "            progress_bar.progress(0.2)\n",
        "\n",
        "            # Run the entire agent chain\n",
        "            formatted_query = f\"Research Query: {query}\"\n",
        "            with trace(\"Research Workflow\"):\n",
        "                runner_result = await Runner.run(\n",
        "                    runner_agent,\n",
        "                    formatted_query\n",
        "                )\n",
        "\n",
        "            # Process all items to track handoffs and search operations\n",
        "            current_agent = \"RunnerAgent\"\n",
        "            current_search_query = None\n",
        "            search_queries = []\n",
        "            search_plans = []\n",
        "\n",
        "            # First pass: extract search queries from planner output\n",
        "            for item in runner_result.new_items:\n",
        "                # Look for search plans in message output\n",
        "                if item.type == \"message_output_item\":\n",
        "                    output_text = None\n",
        "                    # Try different ways to get output text based on SDK version\n",
        "                    if hasattr(item, 'output_text'):\n",
        "                        output_text = item.output_text\n",
        "                    elif hasattr(item, 'raw_item') and hasattr(item.raw_item, 'content'):\n",
        "                        output_text = item.raw_item.content\n",
        "\n",
        "                    if output_text and isinstance(output_text, str):\n",
        "                        # Look for JSON content with searches\n",
        "                        if '\"searches\"' in output_text or \"'searches'\" in output_text:\n",
        "                            # Clean up JSON content\n",
        "                            content = output_text.strip()\n",
        "                            if \"```json\" in content:\n",
        "                                content = content.split(\"```json\")[1].split(\"```\")[0]\n",
        "                            elif \"```\" in content:\n",
        "                                content = content.split(\"```\")[1].split(\"```\")[0]\n",
        "                            try:\n",
        "                                import json\n",
        "                                data = json.loads(content)\n",
        "                                if \"searches\" in data:\n",
        "                                    search_plans.append(data)\n",
        "                                    for search in data[\"searches\"]:\n",
        "                                        if \"query\" in search and \"reason\" in search:\n",
        "                                            search_queries.append({\n",
        "                                                \"query\": search[\"query\"],\n",
        "                                                \"reason\": search.get(\"reason\", \"Search query\")\n",
        "                                            })\n",
        "                            except json.JSONDecodeError:\n",
        "                                pass\n",
        "\n",
        "            # Second pass: process handoffs and tool calls\n",
        "            for idx, item in enumerate(runner_result.new_items):\n",
        "                # Process handoffs\n",
        "                if item.type == \"handoff_call_item\":\n",
        "                    # Extract target agent name from handoff call\n",
        "                    target_agent = None\n",
        "                    try:\n",
        "                        # Try different ways to get the target agent name based on SDK version\n",
        "                        if hasattr(item.raw_item, 'function'):\n",
        "                            target_agent = item.raw_item.function.name.replace(\"transfer_to_\", \"\")\n",
        "                        elif hasattr(item.raw_item, 'name'):\n",
        "                            target_agent = item.raw_item.name.replace(\"transfer_to_\", \"\")\n",
        "                        else:\n",
        "                            raw_str = str(item.raw_item)\n",
        "                            if \"transfer_to_\" in raw_str:\n",
        "                                target_agent = raw_str.split(\"transfer_to_\")[1].split(\"(\")[0]\n",
        "                    except:\n",
        "                        target_agent = \"Unknown\"\n",
        "\n",
        "                    # Update UI for handoff\n",
        "                    if target_agent:\n",
        "                        if \"planner\" in target_agent.lower():\n",
        "                            status_text.text(\"Planning agent creating search strategy...\")\n",
        "                            progress_bar.progress(0.3)\n",
        "                        elif \"search\" in target_agent.lower():\n",
        "                            status_text.text(\"Search agent executing web searches...\")\n",
        "                            progress_bar.progress(0.5)\n",
        "                        elif \"writer\" in target_agent.lower():\n",
        "                            status_text.text(\"Writer agent creating final report...\")\n",
        "                            progress_bar.progress(0.8)\n",
        "\n",
        "                elif item.type == \"handoff_output_item\":\n",
        "                    # Extract source and target agent names\n",
        "                    source_agent = current_agent\n",
        "                    target_agent = None\n",
        "\n",
        "                    try:\n",
        "                        # Try different ways to get the target agent name\n",
        "                        if hasattr(item, 'target_agent') and item.target_agent:\n",
        "                            target_agent = item.target_agent.name\n",
        "                        elif hasattr(item, 'raw_item'):\n",
        "                            raw_content = str(item.raw_item)\n",
        "                            if \"'assistant':\" in raw_content:\n",
        "                                target_agent = raw_content.split(\"'assistant': '\")[1].split(\"'\")[0]\n",
        "                    except:\n",
        "                        target_agent = \"Unknown\"\n",
        "\n",
        "                    # Add to handoff details\n",
        "                    if target_agent:\n",
        "                        # Determine handoff reason\n",
        "                        reason = \"Agent handoff\"\n",
        "                        if \"planner\" in target_agent.lower():\n",
        "                            reason = \"Planning search strategy\"\n",
        "                        elif \"search\" in target_agent.lower():\n",
        "                            reason = \"Execute web searches\"\n",
        "                        elif \"writer\" in target_agent.lower():\n",
        "                            reason = \"Compile research report\"\n",
        "\n",
        "                        handoff_details.append(HandoffEvent.create(\n",
        "                            from_agent=source_agent,\n",
        "                            to_agent=target_agent,\n",
        "                            reason=reason,\n",
        "                            input_data=\"Processing query\",\n",
        "                            output_data=\"Handling specialized task\"\n",
        "                        ))\n",
        "\n",
        "                        current_agent = target_agent\n",
        "\n",
        "                # Process tool calls to identify web searches\n",
        "                elif item.type == \"tool_call_item\" and \"web_search\" in str(item.raw_item):\n",
        "                    try:\n",
        "                        args = None\n",
        "                        # Try different ways to get the arguments based on SDK version\n",
        "                        if hasattr(item.raw_item, 'function') and hasattr(item.raw_item.function, 'arguments'):\n",
        "                            args = item.raw_item.function.arguments\n",
        "                        elif hasattr(item.raw_item, 'arguments'):\n",
        "                            args = item.raw_item.arguments\n",
        "\n",
        "                        if args:\n",
        "                            import json\n",
        "                            try:\n",
        "                                arg_dict = json.loads(args)\n",
        "                                if \"query\" in arg_dict:\n",
        "                                    current_search_query = arg_dict[\"query\"]\n",
        "                            except:\n",
        "                                current_search_query = str(args)\n",
        "                        else:\n",
        "                            current_search_query = str(item.raw_item)\n",
        "                    except:\n",
        "                        current_search_query = \"Unknown search query\"\n",
        "\n",
        "                # Process tool outputs to capture search results\n",
        "                elif item.type == \"tool_call_output_item\" and current_search_query:\n",
        "                    try:\n",
        "                        # Get result text\n",
        "                        result_text = None\n",
        "                        if hasattr(item, 'output'):\n",
        "                            result_text = str(item.output)\n",
        "                        elif hasattr(item, 'raw_item'):\n",
        "                            result_text = str(item.raw_item)\n",
        "\n",
        "                        if result_text:\n",
        "                            # Try to match with a query from the search plan\n",
        "                            matching_query = None\n",
        "                            for sq in search_queries:\n",
        "                                if sq[\"query\"] in current_search_query or current_search_query in sq[\"query\"]:\n",
        "                                    matching_query = sq\n",
        "                                    break\n",
        "\n",
        "                            # If no match found, create a basic entry\n",
        "                            if not matching_query:\n",
        "                                matching_query = {\"query\": current_search_query, \"reason\": \"Search query\"}\n",
        "\n",
        "                            # Add to search details\n",
        "                            search_details.append({\n",
        "                                \"query\": matching_query[\"query\"],\n",
        "                                \"reason\": matching_query[\"reason\"],\n",
        "                                \"result\": result_text\n",
        "                            })\n",
        "                    except:\n",
        "                        # Fallback for error\n",
        "                        search_details.append({\n",
        "                            \"query\": current_search_query,\n",
        "                            \"reason\": \"Unknown reason\",\n",
        "                            \"result\": \"Error retrieving search result\"\n",
        "                        })\n",
        "\n",
        "            # Final step: process the report\n",
        "            status_text.text(\"Finalizing research report...\")\n",
        "            progress_bar.progress(0.9)\n",
        "\n",
        "            # Process the final output\n",
        "            try:\n",
        "                raw_output = runner_result.final_output\n",
        "\n",
        "                # Handle different output types\n",
        "                if isinstance(raw_output, ReportData):\n",
        "                    report = raw_output\n",
        "                elif isinstance(raw_output, dict):\n",
        "                    # Convert dictionary to ReportData\n",
        "                    report = ReportData(\n",
        "                        short_summary=raw_output.get('short_summary', f\"Summary of research on {query}\"),\n",
        "                        markdown_report=raw_output.get('markdown_report', f\"# Research on {query}\"),\n",
        "                        follow_up_questions=raw_output.get('follow_up_questions', [f\"What more can we learn about {query}?\"])\n",
        "                    )\n",
        "                else:\n",
        "                    # Create a fallback report\n",
        "                    report = ReportData(\n",
        "                        short_summary=f\"Research on '{query}' completed successfully.\",\n",
        "                        markdown_report=(\n",
        "                            f\"# Research on: {query}\\n\\n\"\n",
        "                            f\"The research workflow has completed. Here's what was found:\\n\\n\"\n",
        "                            + str(raw_output)\n",
        "                        ),\n",
        "                        follow_up_questions=[\n",
        "                            f\"What are the most important aspects of {query}?\",\n",
        "                            f\"What future developments are expected in {query}?\"\n",
        "                        ]\n",
        "                    )\n",
        "\n",
        "                # If we have no search details but have search queries, generate basic search details\n",
        "                if not search_details and search_queries:\n",
        "                    for query_item in search_queries:\n",
        "                        search_details.append({\n",
        "                            \"query\": query_item[\"query\"],\n",
        "                            \"reason\": query_item[\"reason\"],\n",
        "                            \"result\": \"Search results were used to generate the report, but detailed results weren't captured.\"\n",
        "                        })\n",
        "\n",
        "            except Exception as report_err:\n",
        "                error_container.error(f\"Error processing final output: {str(report_err)}\")\n",
        "                # Create a fallback report\n",
        "                report = ReportData(\n",
        "                    short_summary=f\"Research on '{query}' was conducted, but there was an issue formatting the final report.\",\n",
        "                    markdown_report=(\n",
        "                        f\"# Research on: {query}\\n\\n\"\n",
        "                        f\"## Research Process\\n\\n\"\n",
        "                        f\"The research process was completed, but there was an error formatting the final report: {str(report_err)}\\n\\n\"\n",
        "                    ),\n",
        "                    follow_up_questions=[\n",
        "                        f\"What are the key aspects of {query}?\",\n",
        "                        f\"What are expert opinions on {query}?\"\n",
        "                    ]\n",
        "                )\n",
        "\n",
        "        except Exception as e:\n",
        "            error_container.error(f\"Error in research workflow: {str(e)}. Creating a simplified report instead.\")\n",
        "            # Create a fallback report\n",
        "            report = ReportData(\n",
        "                short_summary=f\"Research on '{query}' encountered an issue but found some information.\",\n",
        "                markdown_report=(\n",
        "                    f\"# Research on: {query}\\n\\n\"\n",
        "                    f\"## Research Process\\n\\n\"\n",
        "                    f\"The research workflow encountered an issue: {str(e)}\\n\\n\"\n",
        "                ),\n",
        "                follow_up_questions=[\n",
        "                    f\"What are the key aspects of {query}?\",\n",
        "                    f\"What are expert opinions on {query}?\"\n",
        "                ]\n",
        "            )\n",
        "\n",
        "        # Update progress\n",
        "        progress_bar.progress(1.0)\n",
        "        status_text.text(\"Research complete!\")\n",
        "\n",
        "    # Clean up progress display\n",
        "    await asyncio.sleep(1)\n",
        "    progress_container.empty()\n",
        "    status_text.empty()\n",
        "\n",
        "    # Store handoff details and search details in session state\n",
        "    session_state.handoff_details = handoff_details\n",
        "    session_state.search_details = search_details\n",
        "\n",
        "    return report, handoff_details\n",
        "\n",
        "def render_handoff_chain(handoff_details):\n",
        "    \"\"\"Render the handoff chain as a visual flow\"\"\"\n",
        "    if not handoff_details:\n",
        "        return\n",
        "\n",
        "    st.subheader(\"Agent Handoff Chain\", divider=\"blue\")\n",
        "\n",
        "    for i, handoff in enumerate(handoff_details):\n",
        "        col1, col2, col3 = st.columns([2, 1, 2])\n",
        "\n",
        "        with col1:\n",
        "            st.markdown(f\"\"\"\n",
        "            <div style='background-color:var(--bg-card); padding:15px; border-radius:5px; border-left:5px solid var(--primary-color);'>\n",
        "                <strong>{handoff.from_agent}</strong><br>\n",
        "                <small>Input: {handoff.input}</small>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        with col2:\n",
        "            st.markdown(f\"\"\"\n",
        "            <div style='text-align:center; padding:10px;'>\n",
        "                <span style='font-size:20px; color:var(--primary-color);'>↓</span><br>\n",
        "                <small style='color:var(--text-color);'>{handoff.reason}</small><br>\n",
        "                <small style='color:var(--text-color); opacity:0.7;'>{handoff.timestamp}</small>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        with col3:\n",
        "            st.markdown(f\"\"\"\n",
        "            <div style='background-color:var(--bg-card); padding:15px; border-radius:5px; border-left:5px solid var(--secondary-color);'>\n",
        "                <strong>{handoff.to_agent}</strong><br>\n",
        "                <small>Output: {handoff.output}</small>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        if i < len(handoff_details) - 1:\n",
        "            st.markdown(\"<div style='height:20px;'></div>\", unsafe_allow_html=True)\n",
        "\n",
        "def main():\n",
        "    # Set page configuration\n",
        "    st.set_page_config(\n",
        "        page_title=\"AI Research Assistant\",\n",
        "        page_icon=\"🔍\",\n",
        "        layout=\"wide\",\n",
        "        initial_sidebar_state=\"expanded\"\n",
        "    )\n",
        "\n",
        "    # CSS styling (unchanged)\n",
        "    st.markdown(\"\"\"\n",
        "    <style>\n",
        "    /* Only style the custom components in the main content area */\n",
        "    .main-header {\n",
        "        font-size: 2.5rem;\n",
        "        color: #1E88E5;\n",
        "        margin-bottom: 1rem;\n",
        "    }\n",
        "\n",
        "    .sub-header {\n",
        "        font-size: 1.5rem;\n",
        "        color: #1E88E5;\n",
        "        margin: 1rem 0;\n",
        "    }\n",
        "\n",
        "    .info-box {\n",
        "        background-color: #F0F7FF;\n",
        "        padding: 1rem;\n",
        "        border-radius: 0.5rem;\n",
        "        border-left: 5px solid #1E88E5;\n",
        "        margin-bottom: 1rem;\n",
        "    }\n",
        "\n",
        "    .success-box {\n",
        "        background-color: #F0FFF0;\n",
        "        padding: 1rem;\n",
        "        border-radius: 0.5rem;\n",
        "        border-left: 5px solid #43A047;\n",
        "        margin-bottom: 1rem;\n",
        "    }\n",
        "\n",
        "    .warning-box {\n",
        "        background-color: #FFFAF0;\n",
        "        padding: 1rem;\n",
        "        border-radius: 0.5rem;\n",
        "        border-left: 5px solid #FFA000;\n",
        "        margin-bottom: 1rem;\n",
        "    }\n",
        "\n",
        "    .error-box {\n",
        "        background-color: #FFF0F0;\n",
        "        padding: 1rem;\n",
        "        border-radius: 0.5rem;\n",
        "        border-left: 5px solid #E53935;\n",
        "        margin-bottom: 1rem;\n",
        "    }\n",
        "\n",
        "    .stButton button {\n",
        "        background-color: #1E88E5;\n",
        "        color: white;\n",
        "        font-weight: bold;\n",
        "        padding: 0.5rem 2rem;\n",
        "        border-radius: 0.3rem;\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    # Initialize session state for storing persistent data\n",
        "    if 'api_key_valid' not in st.session_state:\n",
        "        st.session_state.api_key_valid = False\n",
        "    if 'handoff_details' not in st.session_state:\n",
        "        st.session_state.handoff_details = []\n",
        "    if 'search_details' not in st.session_state:\n",
        "        st.session_state.search_details = []\n",
        "    if 'report' not in st.session_state:\n",
        "        st.session_state.report = None\n",
        "\n",
        "    # App Header\n",
        "    col1, col2 = st.columns([3, 1])\n",
        "    with col1:\n",
        "        st.markdown(\"<h1 class='main-header'>🔍 AI Research Assistant</h1>\", unsafe_allow_html=True)\n",
        "        st.markdown(\"<p style='color:var(--text-color);'>Powered by OpenAI Agents SDK</p>\", unsafe_allow_html=True)\n",
        "    with col2:\n",
        "        if AGENTS_SDK_AVAILABLE:\n",
        "            st.markdown(\"<div class='success-box'>Agents SDK Loaded ✓</div>\", unsafe_allow_html=True)\n",
        "        else:\n",
        "            st.markdown(\"<div class='warning-box'>Agents SDK Not Found - Using Simulation</div>\", unsafe_allow_html=True)\n",
        "\n",
        "    # Sidebar for configuration\n",
        "    with st.sidebar:\n",
        "        st.markdown(\"<h2 class='sub-header'>Research Configuration</h2>\", unsafe_allow_html=True)\n",
        "\n",
        "        # Display agent workflow\n",
        "        st.markdown(\"<h3 style='color:var(--text-color);'>Agent Workflow</h3>\", unsafe_allow_html=True)\n",
        "\n",
        "        with st.container():\n",
        "            # Show runner agent at the top\n",
        "            st.markdown(\"\"\"\n",
        "            <div class='agent-card'>\n",
        "                <h4 style='color:var(--text-color);'>🧠 Runner Agent</h4>\n",
        "                <p style='color:var(--text-color);'>Orchestrates the entire research process by delegating to specialized agents in sequence.</p>\n",
        "                <small style='color:var(--text-color); opacity:0.8;'>Model: GPT-4o</small>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "            st.markdown(\"<div style='text-align:center; padding:5px;'><span style='color:var(--primary-color);'>↓ First</span></div>\", unsafe_allow_html=True)\n",
        "\n",
        "            st.markdown(\"\"\"\n",
        "            <div class='agent-card'>\n",
        "                <h4 style='color:var(--text-color);'>📋 Planner Agent</h4>\n",
        "                <p style='color:var(--text-color);'>Analyzes your query and designs a research strategy with targeted search queries.</p>\n",
        "                <small style='color:var(--text-color); opacity:0.8;'>Model: GPT-4o</small>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "            st.markdown(\"<div style='text-align:center; padding:5px;'><span style='color:var(--primary-color);'>↓ Second</span></div>\", unsafe_allow_html=True)\n",
        "\n",
        "            st.markdown(\"\"\"\n",
        "            <div class='agent-card'>\n",
        "                <h4 style='color:var(--text-color);'>🔎 Search Agent</h4>\n",
        "                <p style='color:var(--text-color);'>Performs web searches based on the planned queries and summarizes the findings.</p>\n",
        "                <small style='color:var(--text-color); opacity:0.8;'>Tools: Web Search</small>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "            st.markdown(\"<div style='text-align:center; padding:5px;'><span style='color:var(--primary-color);'>↓ Third</span></div>\", unsafe_allow_html=True)\n",
        "\n",
        "            st.markdown(\"\"\"\n",
        "            <div class='agent-card'>\n",
        "                <h4 style='color:var(--text-color);'>✍️ Writer Agent</h4>\n",
        "                <p style='color:var(--text-color);'>Synthesizes search results into a cohesive, detailed research report.</p>\n",
        "                <small style='color:var(--text-color); opacity:0.8;'>Output: Formatted Report</small>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        # API Key Input\n",
        "        st.markdown(\"<h3>OpenAI API Key</h3>\", unsafe_allow_html=True)\n",
        "\n",
        "        # Check if API key is already set in environment\n",
        "        existing_key = os.environ.get('OPENAI_API_KEY', '')\n",
        "\n",
        "        api_key = st.text_input(\n",
        "            \"Enter your OpenAI API Key\",\n",
        "            value=existing_key,\n",
        "            type=\"password\",\n",
        "            help=\"Your API key will be used to authenticate with OpenAI services.\"\n",
        "        )\n",
        "\n",
        "        # Number of Searches Slider\n",
        "        num_searches = st.slider(\n",
        "            \"Number of Web Searches\",\n",
        "            min_value=1,\n",
        "            max_value=10,\n",
        "            value=5,\n",
        "            step=1,\n",
        "            help=\"Maximum number of web searches to perform for your query.\"\n",
        "        )\n",
        "\n",
        "        # Writer Model Selection\n",
        "        writer_model = st.radio(\n",
        "            \"Report Writer Model\",\n",
        "           [\"gpt-4o\", \"gpt-3.5-turbo\"],\n",
        "           index=0,\n",
        "           help=\"Select the model to use for writing the final research report.\"\n",
        "       )\n",
        "\n",
        "       # Validate and save API key\n",
        "    if api_key:\n",
        "        if st.button(\"Validate API Key\"):\n",
        "            is_valid, error_message = validate_openai_key(api_key)\n",
        "\n",
        "            if is_valid:\n",
        "                st.session_state.api_key_valid = True\n",
        "                st.markdown(\"<div class='success-box'>API Key validated successfully! ✓</div>\", unsafe_allow_html=True)\n",
        "            else:\n",
        "                st.session_state.api_key_valid = False\n",
        "                st.markdown(f\"<div class='error-box'>Invalid API Key: {error_message}</div>\", unsafe_allow_html=True)\n",
        "\n",
        "    # Troubleshooting Information (unchanged)\n",
        "    with st.expander(\"Troubleshooting\"):\n",
        "        st.markdown(\"\"\"\n",
        "        ### 🔑 API Key Issues\n",
        "\n",
        "        1. **Invalid format** - OpenAI API keys start with `sk-`\n",
        "        2. **Authentication failed** - Check your OpenAI account status\n",
        "        3. **Billing issues** - Ensure your OpenAI account has valid billing\n",
        "        4. **Usage limits** - You may have hit your usage cap\n",
        "\n",
        "        ### 📡 Connection Issues\n",
        "\n",
        "        1. **Network problems** - Check your internet connection\n",
        "        2. **Timeouts** - The request might be taking too long\n",
        "        3. **Service disruption** - OpenAI services might be experiencing issues\n",
        "\n",
        "        For more help, visit [OpenAI Support](https://help.openai.com/)\n",
        "        \"\"\")\n",
        "\n",
        "   # Main content area\n",
        "    if api_key and st.session_state.api_key_valid:\n",
        "        # Setup only the runner agent with the validated key\n",
        "        try:\n",
        "            runner_agent = setup_agents(\n",
        "                api_key,\n",
        "                num_searches,\n",
        "                writer_model\n",
        "            )\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error setting up agents: {e}\")\n",
        "\n",
        "        # Query input\n",
        "        st.markdown(\"<h2 class='sub-header'>Research Query</h2>\", unsafe_allow_html=True)\n",
        "        query = st.text_input(\n",
        "            \"What would you like to research?\",\n",
        "            placeholder=\"E.g., 'The impact of artificial intelligence on healthcare'\"\n",
        "        )\n",
        "\n",
        "        # Research button\n",
        "        if st.button(\"Start Research\"):\n",
        "            if query:\n",
        "                try:\n",
        "                    # Reset previous results\n",
        "                    st.session_state.report = None\n",
        "                    st.session_state.handoff_details = []\n",
        "                    st.session_state.search_details = []\n",
        "\n",
        "                    # Use asyncio to run the async function with just the runner agent\n",
        "                    report, handoff_details = asyncio.run(perform_research(\n",
        "                        query,\n",
        "                        runner_agent,\n",
        "                        st.session_state\n",
        "                    ))\n",
        "\n",
        "                    # Store the report in session state\n",
        "                    st.session_state.report = report\n",
        "\n",
        "                    # Force a rerun to show the new content\n",
        "                    st.rerun()\n",
        "\n",
        "                except Exception as e:\n",
        "                    st.error(f\"An error occurred during research: {e}\")\n",
        "            else:\n",
        "                st.warning(\"Please enter a research query.\")\n",
        "\n",
        "        # Display results if available (same as original)\n",
        "        if st.session_state.report:\n",
        "            report = st.session_state.report\n",
        "\n",
        "            # Research Results\n",
        "            st.markdown(\"<h2 class='sub-header'>Research Results</h2>\", unsafe_allow_html=True)\n",
        "\n",
        "            # Display summary in a nice box\n",
        "            st.markdown(f\"\"\"\n",
        "            <div class='info-box'>\n",
        "                <h3>Summary</h3>\n",
        "                <p>{report.short_summary}</p>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "            # Render the handoff chain\n",
        "            render_handoff_chain(st.session_state.handoff_details)\n",
        "\n",
        "            # Tabs for detailed content\n",
        "            tab1, tab2, tab3 = st.tabs([\"📝 Full Report\", \"🔍 Search Details\", \"❓ Follow-up Questions\"])\n",
        "\n",
        "            with tab1:\n",
        "                st.markdown(report.markdown_report)\n",
        "\n",
        "            with tab2:\n",
        "                if st.session_state.search_details:\n",
        "                    for i, detail in enumerate(st.session_state.search_details):\n",
        "                        with st.expander(f\"Search {i+1}: {detail['query']}\"):\n",
        "                            st.markdown(f\"**Reason:** {detail['reason']}\")\n",
        "                            st.markdown(f\"**Result:** {detail['result']}\")\n",
        "                else:\n",
        "                    st.info(\"No search details available.\")\n",
        "\n",
        "            with tab3:\n",
        "                if report.follow_up_questions:\n",
        "                    for question in report.follow_up_questions:\n",
        "                        st.markdown(f\"- {question}\")\n",
        "                else:\n",
        "                    st.info(\"No follow-up questions generated.\")\n",
        "    else:\n",
        "        # When no API key is present or valid (same as original)\n",
        "        st.markdown(\"\"\"\n",
        "        <div class='info-box'>\n",
        "            <h3>Getting Started</h3>\n",
        "            <p>To use the AI Research Assistant, please follow these steps:</p>\n",
        "            <ol>\n",
        "                <li>Enter your OpenAI API Key in the sidebar</li>\n",
        "                <li>Click \"Validate API Key\" to verify your credentials</li>\n",
        "                <li>Enter your research query and start researching!</li>\n",
        "            </ol>\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        # Sample queries to help users get started\n",
        "        st.markdown(\"<h3>Sample Research Topics</h3>\", unsafe_allow_html=True)\n",
        "        sample_queries = [\n",
        "            \"The environmental impact of electric vehicles\",\n",
        "            \"Advancements in quantum computing in the last 5 years\",\n",
        "            \"The role of gut microbiome in human health\",\n",
        "            \"The economic effects of remote work\"\n",
        "        ]\n",
        "\n",
        "        for query in sample_queries:\n",
        "            st.markdown(f\"- {query}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "oPYexgfFr_Hf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}