{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daisysong76/AI--Machine--learning/blob/main/20250411_Huging_Face_%26_LLM_Tools_OpenAI_Agent_SDK_1_2_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRP7lL0AdRxb"
      },
      "source": [
        "# Hugging Face & LLM Tools Study Group\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo-with-title.png\" width=\"600\">    \n",
        "\n",
        "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2023/07/langchain3.png\" width=\"200\">\n",
        "\n",
        "<img src=\"https://devio2023-media.developers.io/wp-content/uploads/2023/03/eyecatch-llamdaindex-960x504.png\" width=\"200\">\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://www.marktechpost.com/wp-content/uploads/2024/01/Screenshot-2024-01-16-at-12.30.59-PM.png\" width=\"200\">\n",
        "\n",
        "<img src=\"https://media.theresanaiforthat.com/icons/ollama.svg\" width=\"200\">\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Gx7VhGYaBgxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CIE-SF Annual Conference**\n",
        "\n",
        "---\n",
        "**AI for Everyone: Shaping Tomorrow's World**  \n",
        "Time: 2025 6/7 Sat. 12:45 pm  \n",
        "Address: 800 North Mary Avenue, Sunnyvale, CA  \n",
        "Synopsys Sunnyvale Campus  \n",
        "Building 1 Auditorium  \n",
        "\n",
        "**Eventbrite:**\n",
        "https://www.eventbrite.com/e/1288716378379?aff=oddtdtcreator\n",
        "\n",
        "---\n",
        "\n",
        "Speakers:\n",
        "- VP of Synopsys, AI using in Chip design\n",
        "- Sr. Director of Meta, llama models\n",
        "- Start-up Advisor of Stanford, AI impact PM jobs and star-ups\n",
        "- Lead Architect AI/ML of Trend Micro, AI for Security & Security for AI\n"
      ],
      "metadata": {
        "id": "yLMoJR3BBHNx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMiDJCDUOroX"
      },
      "source": [
        "# Study Group Line Group Link\n",
        "\n",
        "https://line.me/ti/g2/ewvZJBa7bOJzCtwhZpHv4yUqJhGDOPRWwA1UWA\n",
        "\n",
        "ç”±æ–¼æœ€è¿‘è‡ªå­¸å°çµ„çš„ LINE ç¾¤çµ„å…§å‡ºç¾éå¤šåƒåœ¾è²¼æ–‡ï¼Œæˆ‘å·²ç¶“å»ºç«‹äº†ä¸€å€‹æ–°çš„ LINE ç¤¾ç¾¤ï¼Œåç‚ºã€ŒAI è‡ªå­¸å°çµ„ LLM Toolsã€ã€‚LINE ç¤¾ç¾¤ç›¸è¼ƒæ–¼ç¾¤çµ„å…·æœ‰æ›´å®Œå–„çš„ç®¡ç†åŠŸèƒ½ï¼Œä¸åƒ…å¯ä»¥è«‹èµ°å¼µè²¼ä¸ç•¶å…§å®¹çš„æˆå“¡ï¼Œé‚„èƒ½ç›´æ¥ç§»é™¤åƒåœ¾è²¼æ–‡ã€‚æ­¤å¤–ï¼Œæœªä¾†ä¹Ÿå¯ä»¥é‡å°æ–°åƒåŠ è€…é€²è¡Œå¯©æŸ¥é€šéã€‚\n",
        "\n",
        "æˆ‘å·²ç¶“å°‡éå»ä¸€å¹´å¤šçš„è²¼æ–‡æ¬ç§»åˆ°æ–°çš„ LINE ç¤¾ç¾¤ã€‚ç¤¾ç¾¤çš„ä¸€å€‹å„ªå‹¢æ˜¯ï¼Œæ–°åŠ å…¥çš„æˆå“¡å¯ä»¥ç€è¦½ä¹‹å‰çš„æ­·å²è²¼æ–‡ï¼Œä¾¿æ–¼å¿«é€ŸæŒæ¡å°çµ„çš„è¨è«–å’Œå­¸ç¿’é€²å±•ã€‚æœŸå¾…å¤§å®¶ä¸€èµ·åœ¨æ–°ç¤¾ç¾¤ä¸­ç¹¼çºŒäº¤æµå’Œæˆé•·ï¼\n",
        "\n",
        "ä½†æˆ‘å€‘ç™¼ç¾ä¸€äº›ç¾åœ‹çš„æœ‹å‹ç„¡æ³•åŠ å…¥é€™å€‹ç¤¾ç¾¤ï¼Œæˆ‘å‘LINEè©¢å•çš„çµæœå¾—åˆ°ä¸‹é¢çš„ç­”è¦†ï¼š  \n",
        "  - ã€Œç›®å‰ç¤¾ç¾¤æœå‹™æä¾›åœ‹å®¶ç‚ºï¼šæ—¥æœ¬ã€å°ç£ã€æ³°åœ‹ï¼Œå…¶å®ƒåœ°å€ä¸¦æœªæä¾›è©²é …æœå‹™ã€‚ã€\n",
        "\n",
        "åœ¨ LINE æ”¹è®Šä½œæ³•ä»¥å‰ï¼Œæˆ‘å€‘é‚„èƒ½ç”¨ LINE group èˆ‡ WeChat Group ä¾†æºé€šã€‚æˆ‘å€‘ç›®å‰æŠŠ  LINE group è¨­å®šæˆåªèƒ½ç”±æˆå“¡é‚€è«‹åŠ å…¥ï¼Œä¸é–‹æ”¾ QR code åŠ å…¥ï¼Œ WeChat Group æ¯æ¬¡ç”¢ç”Ÿçš„ QR code æœ‰ä¸€å€‹æ™‚é™ã€‚ä½ å¯ä»¥åœ¨æˆ‘å€‘çš„ Zoom meeting çš„æ™‚æ®µè«‹äººæ‹‰ä½ é€²å…¥ã€‚å¦‚æœä½ çš„LINEå¸³è™Ÿæ˜¯ æ—¥æœ¬ã€å°ç£ã€æ³°åœ‹ å€åŸŸï¼Œé‚£å»ºè­°ä½ ç›´æ¥åŠ å…¥ç¤¾ç¾¤ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSa0AdtRpC5F"
      },
      "source": [
        "# Courses of this Week\n",
        "\n",
        "Week 46 OpenAI Agent SDK 1/2 begining\n",
        "\n",
        "1. OpenAI å…¨æ–° AI Agentsï¼šResponses API å®Œæ•´æŒ‡å— https://tenten.co/learning/openai-agent-responses-api/\n",
        "\n",
        "2. How to Build an Agent with the OpenAI Agents SDK https://www.youtube.com/watch?v=0Z7u6DTDZ8o\n",
        "  - https://colab.research.google.com/drive/17XLmT81pBxHHf6zONgcCatTjpgzHKvae?usp=sharing\n",
        "  - https://github.com/samwit/llm-tutorials\n",
        "\n",
        "3. OpenAIâ€™s BRAND NEW Agents SDK (Crash Course) https://www.youtube.com/watch?v=e7qvd2bOITc\n",
        "  - https://github.com/coleam00/ottomator-agents/tree/main/openai-sdk-agent\n",
        "  - https://github.com/openai/openai-agents-python/tree/main\n",
        "  - https://openai.github.io/openai-agents-python/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI Agent SDK\n",
        "\n",
        "![OpenAI Agent]( https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQI9Ppy_J3po8PoxDtbPZ--ES6g0GtwT1EUcA&s )\n",
        "\n",
        "\n",
        "https://github.com/openai/openai-agents-python/tree/main"
      ],
      "metadata": {
        "id": "jSl1RaPs4UBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- New tools for building agents https://openai.com/index/new-tools-for-building-agents/\n",
        "\n",
        "  - The new [Responses API](https://platform.openai.com/docs/quickstart?api-mode=responses) , combining the simplicity of the Chat Completions API with the tool use capabilities of the Assistants API for building agents\n",
        "  - Built-in tools including [web search](https://platform.openai.com/docs/guides/tools-web-search?api-mode=responses), [file search](https://platform.openai.com/docs/guides/tools-file-search), and [computer use](https://platform.openai.com/docs/guides/tools-computer-use)\n",
        "  - The new Agents SDKâ (opens in a new window) to orchestrate single-agent and multi-agent workflows\n",
        "  - Integrated observability toolsâ (opens in a new window) to trace and inspect agent workflow execution\n",
        "- OpenAI å…¨æ–° AI Agentsï¼šResponses API å®Œæ•´æŒ‡å— https://tenten.co/learning/openai-agent-responses-api/"
      ],
      "metadata": {
        "id": "mpXied7a5S_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Price\n",
        "\n",
        "Responses API  \n",
        "Our newest API combining the simplicity of Chat Completions with the built-in tool use of Assistants.\n",
        "\n",
        "Price  \n",
        "Responses API is not priced separately. Tokens are billed at the chosen language modelâ€™s input and output rates."
      ],
      "metadata": {
        "id": "vUevFufL8Sf6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare three OpenAI API\n",
        "\n",
        "## 1. Chat Completions APIï¼ˆèŠå¤©è£œå…¨ APIï¼‰\n",
        "\n",
        "### ğŸ§  æ¦‚è¿°\n",
        "Chat Completions API æ˜¯è¨­è¨ˆä¾†æ”¯æ´å®Œæ•´å°è©±æµç¨‹çš„ APIã€‚å®ƒé€éä¸€çµ„æœ‰ã€Œè§’è‰²ã€ï¼ˆå¦‚ systemã€userã€assistantï¼‰çš„è¨Šæ¯çµ„æˆçš„é™£åˆ—ï¼Œä¾†é€²è¡Œä¸Šä¸‹æ–‡å°è©±è£œå…¨ã€‚ç‰¹åˆ¥é©åˆéœ€è¦å¤šè¼ªäº’å‹•ä¸”ä¿æŒä¸Šä¸‹æ–‡ä¸€è‡´çš„æ‡‰ç”¨æƒ…å¢ƒã€‚\n",
        "\n",
        "### ğŸ§ª Python ç¯„ä¾‹\n",
        "```python\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"ä½ çš„ API é‡‘é‘°\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä½æ¨‚æ–¼åŠ©äººçš„åŠ©æ‰‹ã€‚\"},\n",
        "        {\"role\": \"user\", \"content\": \"è¬›å€‹ç¬‘è©±çµ¦æˆ‘è½ã€‚\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message[\"content\"])\n",
        "```\n",
        "\n",
        "### ğŸ”‘ é—œéµç‰¹é»\n",
        "- **è¨Šæ¯çµæ§‹æ˜ç¢º**ï¼šä½¿ç”¨è§’è‰²æ¨™è¨»ï¼ˆsystem/user/assistantï¼‰å€åˆ†å°è©±éšæ®µã€‚\n",
        "- **æ”¯æ´ä¸Šä¸‹æ–‡è¨˜æ†¶**ï¼šèƒ½è¿½è¹¤å¤šè¼ªå°è©±çš„ä¸Šä¸‹æ–‡ã€‚\n",
        "- **äº’å‹•å½ˆæ€§é«˜**ï¼šé©åˆç”¨åœ¨éœ€è¦é€£çºŒäº’å‹•çš„æ‡‰ç”¨ï¼ˆå¦‚å®¢æœã€èŠå¤©æ©Ÿå™¨äººç­‰ï¼‰ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Assistants APIï¼ˆåŠ©æ‰‹ APIï¼‰\n",
        "\n",
        "### ğŸ§  æ¦‚è¿°\n",
        "Assistants API æ˜¯ç‚ºäº†å»ºç«‹å…·æœ‰æŒä¹…å€‹æ€§èˆ‡è¨˜æ†¶çš„è™›æ“¬åŠ©æ‰‹æ‰€è¨­è¨ˆï¼Œé©åˆéœ€è¦é•·æœŸäº¤è«‡èˆ‡è¨˜éŒ„çš„æ‡‰ç”¨ï¼Œä¾‹å¦‚æ™ºèƒ½åŠ©ç†ã€‚å¯ä»¥è¨­å®šæŒ‡ä»¤ã€æª”æ¡ˆã€æŒä¹…è¨˜æ†¶ç­‰åŠŸèƒ½ã€‚\n",
        "\n",
        "### ğŸ§ª Python ç¯„ä¾‹ï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰\n",
        "```python\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"ä½ çš„ API é‡‘é‘°\"\n",
        "\n",
        "# å‡è¨­ä½ å·²ç¶“å»ºç«‹ assistant ä¸¦å–å¾— assistant_id\n",
        "response = openai.beta.threads.create_and_run(\n",
        "    assistant_id=\"ä½ çš„_assistant_id\",\n",
        "    thread={\"messages\": [{\"role\": \"user\", \"content\": \"ä»Šå¤©å¤©æ°£æ€éº¼æ¨£ï¼Ÿ\"}]}\n",
        ")\n",
        "\n",
        "print(response)\n",
        "```\n",
        "\n",
        "### ğŸ”‘ é—œéµç‰¹é»\n",
        "- **å€‹äººåŒ–æ”¯æ´**ï¼šå¯ä»¥ç‚ºåŠ©æ‰‹è¨­ç½®æŒä¹…å€‹æ€§èˆ‡æŒ‡ä»¤ã€‚\n",
        "- **æ”¯æ´è¨˜æ†¶èˆ‡å°è©±ç·šç¨‹ï¼ˆthreadï¼‰**ï¼šé©åˆéœ€è¦é•·æœŸäº’å‹•çš„æ‡‰ç”¨ï¼ˆå¦‚å€‹äººåŠ©ç† Appï¼‰ã€‚\n",
        "- **é€²éšæ§åˆ¶åŠŸèƒ½**ï¼šå¯ç®¡ç†å·¥å…·ï¼ˆtoolsï¼‰ã€æª”æ¡ˆã€è¨˜æ†¶é«”ç­‰åŠŸèƒ½ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Responses APIï¼ˆå›æ‡‰ APIï¼‰\n",
        "\n",
        "### ğŸ§  æ¦‚è¿°\n",
        "Responses API æ˜¯æœ€æ–°ä¸”ç²¾ç°¡çš„ APIï¼Œé©åˆéœ€è¦å–®æ¬¡å¿«é€Ÿã€æ ¼å¼æ¸…æ™°å›ç­”çš„æ‡‰ç”¨å ´æ™¯ã€‚èˆ‡ Chat Completions API ä¸åŒï¼Œå®ƒä¸éœ€è¦ç¶­è­·è¨Šæ¯é™£åˆ—ä¸Šä¸‹æ–‡ï¼Œä¸»è¦ç”¨æ–¼ä¸€æ¬¡æ€§æŸ¥è©¢ã€‚\n",
        "\n",
        "### ğŸ§ª Python ç¯„ä¾‹\n",
        "```python\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"ä½ çš„ API é‡‘é‘°\"\n",
        "\n",
        "response = openai.Response.create(\n",
        "    model=\"gpt-4\",\n",
        "    prompt=\"è«‹è§£é‡‹ AI æ¨¡å‹ä¹‹é–“çš„å·®ç•°ã€‚\"\n",
        ")\n",
        "\n",
        "print(response['data'][0]['content'])\n",
        "```\n",
        "\n",
        "> âš ï¸ è«‹æ³¨æ„ `Response API` å°šå±¬è¼ƒæ–°åŠŸèƒ½ï¼Œå¯¦éš›çš„ Python å‡½å¼åç¨±å¯èƒ½æœƒéš¨ OpenAI SDK æ›´æ–°è€Œèª¿æ•´ã€‚å»ºè­°åƒè€ƒ [å®˜æ–¹æ–‡ä»¶](https://platform.openai.com/docs) ç¢ºèªèªæ³•ã€‚\n",
        "\n",
        "### ğŸ”‘ é—œéµç‰¹é»\n",
        "- **æ“ä½œç°¡å–®**ï¼šåƒ…éœ€å‚³å…¥ `prompt`ï¼Œç„¡éœ€å¤šè¼ªè¨Šæ¯çµæ§‹ã€‚\n",
        "- **æ ¼å¼åŒ–è¼¸å‡ºæ”¯æ´ä½³**ï¼šå¯æ›´å®¹æ˜“æ•´åˆç‚º JSONã€è¡¨æ ¼ã€API å›å‚³è³‡æ–™ç­‰æ ¼å¼ã€‚\n",
        "- **é€Ÿåº¦å¿«ã€æ•ˆèƒ½ç©©å®š**ï¼šéå¸¸é©åˆ FAQ æŸ¥è©¢ã€å–®å¥ç”Ÿæˆã€æœå°‹ç­‰ä»»å‹™ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## 4. API æ¯”è¼ƒç¸½è¦½\n",
        "\n",
        "| ç‰¹æ€§ / API       | Chat Completions | Assistants             | Responses              |\n",
        "|------------------|------------------|-------------------------|------------------------|\n",
        "| å°è©±ä¸Šä¸‹æ–‡       | âœ… æ”¯æ´å¤šè¼ª         | âœ… æ”¯æ´å¤šè¼ªèˆ‡è¨˜æ†¶         | âŒ éœ€æ‰‹å‹•ç¶­æŒä¸Šä¸‹æ–‡        |\n",
        "| ç‹€æ…‹è¨˜æ†¶         | âŒ ç„¡è¨˜æ†¶           | âœ… å…·è¨˜æ†¶åŠŸèƒ½              | âŒ ç„¡è¨˜æ†¶               |\n",
        "| æ•´åˆé›£æ˜“åº¦       | ä¸­ç­‰               | è¼ƒè¤‡é›œï¼ˆéœ€å»ºç«‹åŠ©æ‰‹ï¼‰         | æœ€ç°¡å–®ï¼ˆç›´æ¥ promptï¼‰      |\n",
        "| å»ºè­°æ‡‰ç”¨å ´æ™¯     | å®¢æœã€æ™ºæ…§èŠå¤©æ©Ÿå™¨äºº  | è¡Œå‹•åŠ©æ‰‹ã€æ•™è‚² App         | FAQ æ©Ÿå™¨äººã€æœå°‹æ‘˜è¦        |\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… å»ºè­°ä½¿ç”¨æƒ…å¢ƒ\n",
        "\n",
        "- **Chat Completions API**ï¼šç•¶ä½ éœ€è¦å»ºæ§‹è‡ªç„¶èªè¨€ã€å¤šè¼ªäº’å‹•çš„å°è©±æ‡‰ç”¨ã€‚\n",
        "- **Assistants API**ï¼šç•¶ä½ è¦æ‰“é€ å…·å‚™å€‹æ€§ã€å·¥å…·æ•´åˆã€è¨˜æ†¶åŠ›çš„é•·æœŸ AI åŠ©ç†ã€‚\n",
        "- **Responses API**ï¼šç•¶ä½ åªéœ€è¦å¿«é€Ÿã€æ˜ç¢ºçš„ä¸€æ¬¡æ€§å›ç­”ï¼Œä¾‹å¦‚æœå°‹çµæœã€æ‘˜è¦ã€ç¨‹å¼ç¢¼ç”Ÿæˆã€‚\n",
        "\n"
      ],
      "metadata": {
        "id": "f_2FZvw6CU26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI Agents SDK\n",
        "\n",
        "https://openai.github.io/openai-agents-python/\n",
        "\n",
        "- **Agents**, which are LLMs equipped with instructions and tools\n",
        "- **Handoffs**, which allow agents to delegate to other agents for specific tasks\n",
        "- **Guardrails**, which enable the inputs to agents to be validated\n",
        "\n",
        "https://openai.github.io/openai-agents-python/agents/\n",
        "https://openai.github.io/openai-agents-python/running_agents/"
      ],
      "metadata": {
        "id": "SQ_9Dz2aJjgv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Web search\n",
        "\n",
        "\n",
        "\n",
        "Using the Responses API, you can enable web search by configuring it in the tools array in an API request to generate content. Like any other tool, the model can choose to search the web or not based on the content of the input prompt.\n",
        "\n",
        "```python\n",
        "# Web search tool example\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o\",\n",
        "    tools=[{\"type\": \"web_search_preview\"}],\n",
        "    input=\"What was a positive news story from today?\"\n",
        ")\n",
        "\n",
        "print(response.output_text)\n",
        "```\n"
      ],
      "metadata": {
        "id": "cw1BJUYX7bix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### File Search\n",
        "\n",
        "https://platform.openai.com/docs/guides/tools-file-search\n",
        "\n",
        "Prior to using file search with the Responses API, you need to have set up a knowledge base in a vector store and uploaded files to it.\n",
        "\n",
        "```python\n",
        "#from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"What is deep research by OpenAI?\",\n",
        "    tools=[{\n",
        "        \"type\": \"file_search\",\n",
        "        \"vector_store_ids\": [\"<vector_store_id>\"]\n",
        "    }]\n",
        ")\n",
        "print(response)\n",
        "```"
      ],
      "metadata": {
        "id": "LwMB0zyh-pr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computer use\n",
        "\n",
        "https://platform.openai.com/docs/guides/tools-computer-use\n",
        "\n",
        "å— Operator ç”¢å“å•Ÿç™¼ï¼Œå…è¨± AI ä»£ç†åœ¨è¨ˆç®—æ©Ÿæˆ–ç€è¦½å™¨ä¸ŠåŸ·è¡Œä»»å‹™ï¼Œå¦‚é»æ“Šã€æ»¾å‹•å’Œè¼¸å…¥ã€‚é€™å€‹å·¥å…·ä»è™•æ–¼æ—©æœŸéšæ®µï¼Œè¼¸å‡ºé€šå¸¸æ˜¯å·¥å…·èª¿ç”¨ã€‚\n",
        "å®ƒé©åˆè‡ªå‹•åŒ–éœ€è¦å¤šæ­¥æ“ä½œçš„ä»»å‹™ï¼Œä¾‹å¦‚ç‚ºç”¢å“æˆ–å®¢æˆ¶è‡ªå‹•åŒ–è¨ˆç®—æ©Ÿä»»å‹™ã€‚é›–ç„¶ç›®å‰åŠŸèƒ½æœ‰é™ï¼Œä½†é¡¯ç¤ºå‡ºè‡ªå‹•åŒ–è¤‡é›œä»»å‹™çš„å·¨å¤§æ½›åŠ›ï¼Œä¾‹å¦‚æ¨¡æ“¬ç”¨æˆ¶åœ¨ç€è¦½å™¨ä¸Šçš„äº¤äº’ã€‚\n",
        "\n",
        "https://github.com/openai/openai-cua-sample-app\n",
        "\n",
        "> [!CAUTION]  \n",
        "> Computer use is in preview. Because the model is still in preview and may be susceptible to exploits and inadvertent mistakes, we discourage trusting it in authenticated environments or for high-stakes tasks."
      ],
      "metadata": {
        "id": "DAdJCoc9Lw1H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Master OpenAI's Agents SDK\n",
        "\n",
        "æˆ‘æ‰¾åˆ°ä¸€éƒ¨å¾ˆé©åˆæœ¬é€±å…§å®¹çš„å½±ç‰‡ï¼Œä»Šå¤©çš„æœƒè­°ä¸Šä¹Ÿæœƒè«‡ä¸€äº›è£¡é¢çš„é‡é»ã€‚\n",
        "Master OpenAI's Agents SDK  \n",
        "https://www.youtube.com/watch?v=XP7nOVWI_HU\n",
        "\n",
        "GitHub Repository: https://github.com/theailifestyle/oai-agents-sdk\n",
        "\n",
        "\n",
        "# 4 Facets of OpenAIâ€™s Agents SDK\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Agents  \n",
        "Agents are the core building block of the SDK. An agent is a large language model (LLM), configured with tools like web search, file access, and function calling.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Handoffs and Orchestration  \n",
        "Handoffs allow an agent to delegate tasks to another agent. This is particularly useful in scenarios where different agents specialize in different areas.  \n",
        "For example, one agent might handle customer support questions while another handles technical issues, such as software bugs, feature requests, refunds, FAQs, etc.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Guardrails  \n",
        "Guardrails operate alongside agents to validate user interactions.  \n",
        "They come in two types:  \n",
        "- input guardrails that screen inputs  \n",
        "- output guardrails that check final agent responses  \n",
        "\n",
        "Using either, those responsible for guardrails prevent misuse risks in LLM-powered systems.  \n",
        "Guardrails help improve security and ensure the system behaves as expected by restricting harmful, irrelevant, or unsafe responses.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Traceability  \n",
        "The Agents SDK includes built-in tracing, collecting a comprehensive record of events during an agent run:  \n",
        "- LLM generations  \n",
        "- tool calls  \n",
        "- handoffs  \n",
        "- guardrails  \n",
        "- even custom events that users track  \n",
        "\n",
        "Using the Traces dashboard, you can debug, visualize, and monitor your workflows during development and in production.\n",
        "\n",
        "\n",
        "\n",
        "### Overview\n",
        "\n",
        "Building agents involves assembling components across several domainsâ€”such as **models**, **tools**, **knowledge & memory**, **guardrails**, and **orchestration**â€”and OpenAI provides composable primitives for each.\n",
        "\n",
        "\n",
        "| **Domain**             | **Description**                                                                 | **OpenAI Primitives**                                                                                  |\n",
        "|------------------------|---------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------|\n",
        "| **Models**             | Core intelligence capable of reasoning, making decisions, and processing different modalities. | `o1`, `o3-mini`, `GPT-4.5`, `GPT-4o`, `GPT-4o-mini`                                                    |\n",
        "| **Tools**              | Interface to the world, interact with environment, function calling, built-in tools, etc. | [Function calling](#), [Web search](#), [File search](#), [Computer use](#)                             |\n",
        "| **Knowledge & memory** | Augment agents with external and persistent knowledge.                          | [Vector stores](#), [File search](#), [Embeddings](#)                                                  |\n",
        "| **Guardrails**         | Prevent irrelevant, harmful, or undesirable behavior.                           | [Moderation](#), [Instruction hierarchy](#)                                                             |\n",
        "| **Orchestration**      | Develop, deploy, monitor, and improve agents.                                   | [Agents SDK](#), [Tracing](#), [Evaluations](#), [Fine-tuning](#)                                      |\n"
      ],
      "metadata": {
        "id": "MkCblFZkJX8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AgentOps.ai\n",
        "\n",
        "https://docs.agentops.ai/v1/introduction\n",
        "\n",
        "https://www.agentops.ai/#pricing"
      ],
      "metadata": {
        "id": "wcWXE_19Bc-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent Example In-N-Out Burger\n",
        "\n",
        ". How to Build an Agent with the OpenAI Agents SDK\n",
        "https://www.youtube.com/watch?v=0Z7u6DTDZ8o\n",
        "\n",
        "\n",
        "- https://colab.research.google.com/drive/17XLmT81pBxHHf6zONgcCatTjpgzHKvae?usp=sharing#scrollTo=Q2HFn4FzWXZt"
      ],
      "metadata": {
        "id": "kx6mne_LlcbZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example code"
      ],
      "metadata": {
        "id": "VssP89MwIwBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install openai-agents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmjCwtH7HCP_",
        "outputId": "4cffb1db-486b-4e1a-94b2-3f664fe2ca82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/107.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/129.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.2/129.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "\n",
        "# Verify that the key is set\n",
        "print(f\"OpenAI API key set: {bool(openai_api_key)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gt9ZGjFJHcq1",
        "outputId": "05e58160-820d-4d46-e6ac-77cce5bede04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API key set: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import markdown\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Example usage\n",
        "markdown_text = \"\"\"\n",
        "# Inâ€‘Nâ€‘Out Burger Chatbot\n",
        "\"\"\"\n",
        "\n",
        "display(Markdown(markdown_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "GwuTomVOHGMa",
        "outputId": "057df725-6959-404a-ba82-0a6790d68efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n# Inâ€‘Nâ€‘Out Burger Chatbot\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "0TpoaMT5HhQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MENU_PRICES = \"\"\"\n",
        "\n",
        "# Inâ€‘Nâ€‘Out Burger Menu (2025)\n",
        "\n",
        "**Prices are approximate and subject to change.**\n",
        "\n",
        "## Burgers & Combos\n",
        "\n",
        "| Item                                    | Price  |\n",
        "|-----------------------------------------|--------|\n",
        "| Additional Burger Patty (per extra)     | $1.30  |\n",
        "| Additional Cheese Slice (per extra)     | $0.50  |\n",
        "| **Hamburger**                           | $3.60  |\n",
        "| **Hamburger Combo**                     | $8.15  |\n",
        "| **Cheeseburger**                        | $4.10  |\n",
        "| **Cheeseburger Combo**                  | $8.65  |\n",
        "| **Double DoubleÂ®**                      | $5.90  |\n",
        "| **Double DoubleÂ® Combo**                | $10.45 |\n",
        "| **French Fries**                        | $2.30  |\n",
        "\n",
        "## Beverages\n",
        "\n",
        "| Item                                        | Price  |\n",
        "|---------------------------------------------|--------|\n",
        "| **Coffee**                                  | $1.35  |\n",
        "| **Hot Cocoa**                               | $2.25  |\n",
        "| **Milk**                                    | $0.99  |\n",
        "| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\n",
        "| **Soda (Small)**                            | $2.10  |\n",
        "| **Soda (Medium)**                           | $2.25  |\n",
        "| **Soda (Large)**                            | $2.45  |\n",
        "| **Soda (Xâ€‘Large)**                          | $2.65  |\n",
        "\n",
        "## Notâ€‘Soâ€‘Secret Menu Options\n",
        "\n",
        "- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\n",
        "- **Animal Style:** Burger or fries served with a mustardâ€‘cooked beef patty, extra spread, pickles, and grilled onions.\n",
        "\n",
        "tax not included\n",
        "\n",
        "tax is 7.25%\n",
        "\n",
        "---\"\"\""
      ],
      "metadata": {
        "id": "hyCg6c1P4PqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner\n",
        "\n",
        "agent = Agent(name=\"In-N-Out Cashier Assistant\",\n",
        "              instructions=f\"You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n{MENU_PRICES}\",\n",
        "              model=\"gpt-4o-mini\"\n",
        "              )"
      ],
      "metadata": {
        "id": "BqYnuVEnH3RU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = Runner.run_sync(agent, \"How much is a Double Double?.\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZDfieblI22f",
        "outputId": "55c703f5-0874-4b97-83bc-aacb3060bdf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Double DoubleÂ® is priced at $5.90.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(agent, \"How much is a Double Double combo?.\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrscnTW3KNpw",
        "outputId": "3fb96a3e-e95e-40bf-8053-52e6e9b18bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Double DoubleÂ® Combo is $10.45.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(agent, \"How much is a Double Double and french fries?.\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4Ty9TXekD0F",
        "outputId": "2b5e781a-5978-483d-f9f6-a8686d769a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Double DoubleÂ® is $5.90, and French Fries are $2.30. \n",
            "\n",
            "So, the total before tax would be $8.20. With tax (7.25%), it would be approximately $8.80.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(agent, \"How much is a Double Double and french fries?.\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWQr2GN9kgze",
        "outputId": "a79daeac-b903-4c99-b680-fcb6eff2800c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Double DoubleÂ® costs $5.90, and French Fries cost $2.30. \n",
            "\n",
            "So, the total before tax would be $8.20. With a tax of 7.25%, the final amount would be approximately $8.80.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(agent, \"How much is 32 Double Doubles each with french fries with tax?.\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikED24bGkhrZ",
        "outputId": "82ba1016-8a83-4b2d-d71e-2e9581f507a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To calculate the total cost for 32 Double Doubles and French Fries, we first determine the cost before tax:\n",
            "\n",
            "- **Double DoubleÂ®:** $5.90 each \n",
            "- **French Fries:** $2.30 each \n",
            "\n",
            "Now, let's calculate the total:\n",
            "\n",
            "1. Cost of 32 Double Doubles:\n",
            "   \\[\n",
            "   32 \\times 5.90 = 188.80\n",
            "   \\]\n",
            "\n",
            "2. Cost of 32 French Fries:\n",
            "   \\[\n",
            "   32 \\times 2.30 = 73.60\n",
            "   \\]\n",
            "\n",
            "3. Total cost before tax:\n",
            "   \\[\n",
            "   188.80 + 73.60 = 262.40\n",
            "   \\]\n",
            "\n",
            "Now, let's calculate the tax (7.25%):\n",
            "\n",
            "4. Tax amount:\n",
            "   \\[\n",
            "   262.40 \\times 0.0725 \\approx 19.03\n",
            "   \\]\n",
            "\n",
            "5. Total cost including tax:\n",
            "   \\[\n",
            "   262.40 + 19.03 \\approx 281.43\n",
            "   \\]\n",
            "\n",
            "So, the total cost for 32 Double Doubles each with French fries, including tax, would be approximately **$281.43**.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Streaming"
      ],
      "metadata": {
        "id": "rjJTeTJzklNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from openai.types.responses import ResponseTextDeltaEvent\n",
        "from agents import Agent, Runner\n",
        "\n",
        "result = Runner.run_streamed(agent, input=\"How much is everything on the menu?.\")\n",
        "async for event in result.stream_events():\n",
        "    if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
        "        print(event.data.delta, end=\"\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH83Y1d1kpOt",
        "outputId": "4401ce2f-e457-4815-e985-6aa69f21ced3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hereâ€™s a breakdown of the prices on the In-N-Out Burger menu:\n",
            "\n",
            "### Burgers & Combos\n",
            "- Additional Burger Patty (per extra): $1.30\n",
            "- Additional Cheese Slice (per extra): $0.50\n",
            "- Hamburger: $3.60\n",
            "- Hamburger Combo: $8.15\n",
            "- Cheeseburger: $4.10\n",
            "- Cheeseburger Combo: $8.65\n",
            "- Double DoubleÂ®: $5.90\n",
            "- Double DoubleÂ® Combo: $10.45\n",
            "- French Fries: $2.30\n",
            "\n",
            "### Beverages\n",
            "- Coffee: $1.35\n",
            "- Hot Cocoa: $2.25\n",
            "- Milk: $0.99\n",
            "- Shakes (Chocolate, Strawberry, Vanilla): $3.00\n",
            "- Soda (Small): $2.10\n",
            "- Soda (Medium): $2.25\n",
            "- Soda (Large): $2.45\n",
            "- Soda (X-Large): $2.65\n",
            "\n",
            "If you'd like me to calculate the total price for all items combined (excluding tax), just let me know!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Code Explain\n",
        "\n",
        "```python\n",
        "result = Runner.run_streamed(agent, input=\"How much is everything on the menu?.\")\n",
        "async for event in result.stream_events():\n",
        "    if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
        "        print(event.data.delta, end=\"\", flush=True)\n",
        "```\n",
        "îˆ†\n",
        "\n",
        "### 1. `result = Runner.run_streamed(...)`\n",
        "\n",
        "- **`Runner.run_streamed(agent, input=...)`**ï¼šé€™è¡Œç¨‹å¼ç¢¼å‘¼å« `Runner` é¡åˆ¥çš„ `run_streamed` æ–¹æ³•ï¼Œå•Ÿå‹•æŒ‡å®š `agent` çš„ä¸²æµåŸ·è¡Œï¼Œä¸¦å‚³å…¥åˆå§‹è¼¸å…¥ï¼ˆåœ¨æ­¤ä¾‹ä¸­ç‚º \"How much is everything on the menu?.\"ï¼‰ã€‚è©²æ–¹æ³•è¿”å›ä¸€å€‹ `RunResultStreaming` ç‰©ä»¶ï¼Œå…è¨±æ‚¨ä»¥ç•°æ­¥æ–¹å¼ç›£è½å’Œè™•ç†åŸ·è¡Œéç¨‹ä¸­çš„äº‹ä»¶ã€‚îˆ†\n",
        "\n",
        "### 2. `async for event in result.stream_events():`\n",
        "\n",
        "- **`async for` è¿´åœˆ**ï¼šé€™æ˜¯ä¸€å€‹ç•°æ­¥è¿´åœˆï¼Œç”¨æ–¼éæ­· `result.stream_events()` æ–¹æ³•è¿”å›çš„äº‹ä»¶æµã€‚ç”±æ–¼äº‹ä»¶æ˜¯ä»¥ç•°æ­¥æ–¹å¼ç”¢ç”Ÿçš„ï¼Œä½¿ç”¨ `async for` å¯ä»¥åœ¨ä¸é˜»å¡ä¸»ç¨‹åºçš„æƒ…æ³ä¸‹é€ä¸€è™•ç†æ¯å€‹äº‹ä»¶ã€‚îˆ†\n",
        "\n",
        "- **`result.stream_events()`**ï¼šé€™å€‹æ–¹æ³•è¿”å›ä¸€å€‹ç•°æ­¥ç”Ÿæˆå™¨ï¼Œç”¢ç”ŸåŸ·è¡Œéç¨‹ä¸­çš„å„ç¨®äº‹ä»¶ï¼Œå…è¨±æ‚¨å³æ™‚ç›£è½å’Œè™•ç†é€™äº›äº‹ä»¶ã€‚îˆ†\n",
        "\n",
        "### 3. `if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):`\n",
        "\n",
        "- **äº‹ä»¶éæ¿¾**ï¼šåœ¨è¿´åœˆå…§ï¼Œé€™è¡Œç¨‹å¼ç¢¼æª¢æŸ¥ç•¶å‰äº‹ä»¶æ˜¯å¦ç‚ºé¡å‹ç‚º `\"raw_response_event\"` çš„äº‹ä»¶ï¼Œä¸”å…¶æ•¸æ“šéƒ¨åˆ†æ˜¯å¦ç‚º `ResponseTextDeltaEvent` é¡å‹ã€‚é€™æ¨£çš„æª¢æŸ¥ç¢ºä¿äº†åƒ…è™•ç†ç‰¹å®šé¡å‹çš„äº‹ä»¶ï¼Œé¿å…å°å…¶ä»–ç„¡é—œäº‹ä»¶é€²è¡Œè™•ç†ã€‚îˆ†\n",
        "\n",
        "### 4. `print(event.data.delta, end=\"\", flush=True)`\n",
        "\n",
        "- **è¼¸å‡ºè™•ç†**ï¼šå¦‚æœäº‹ä»¶ç¬¦åˆä¸Šè¿°æ¢ä»¶ï¼Œå‰‡æå–ä¸¦è¼¸å‡º `event.data.delta` çš„å…§å®¹ã€‚`delta` åŒ…å«äº†æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬å¢é‡ï¼Œé€æ­¥æ§‹æˆå®Œæ•´çš„å›æ‡‰ã€‚ä½¿ç”¨ `end=\"\"` ç¢ºä¿è¼¸å‡ºä¸æ›è¡Œï¼Œ`flush=True` å‰‡ç¢ºä¿ç·©è¡å€çš„å…§å®¹ç«‹å³è¼¸å‡ºï¼Œæä¾›å³æ™‚çš„åé¥‹çµ¦ä½¿ç”¨è€…ã€‚îˆ†\n",
        "\n",
        "é€™æ®µç¨‹å¼ç¢¼çš„ä½œç”¨æ˜¯ä»¥ç•°æ­¥æ–¹å¼ç›£è½ä¸¦è™•ç†ä»£ç†åŸ·è¡Œéç¨‹ä¸­çš„æ–‡æœ¬ç”Ÿæˆäº‹ä»¶ï¼Œä¸¦å³æ™‚å°‡ç”Ÿæˆçš„æ–‡æœ¬è¼¸å‡ºåˆ°æ§åˆ¶å°ã€‚é€™ç¨®æ–¹å¼ç‰¹åˆ¥é©åˆéœ€è¦å³æ™‚åé¥‹çš„æ‡‰ç”¨å ´æ™¯ï¼Œä¾‹å¦‚èŠå¤©æ©Ÿå™¨äººæˆ–å³æ™‚è³‡è¨Šå±•ç¤ºã€‚îˆ†"
      ],
      "metadata": {
        "id": "h8V3bnJ8md3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrotdBJcmyX7",
        "outputId": "804f5581-3feb-495c-d36a-be22f0bca67d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RunResultStreaming(input='How much is everything on the menu?.', new_items=[MessageOutputItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# Inâ€‘Nâ€‘Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double DoubleÂ®**                      | $5.90  |\\n| **Double DoubleÂ® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (Xâ€‘Large)**                          | $2.65  |\\n\\n## Notâ€‘Soâ€‘Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustardâ€‘cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='msg_67f8371ac80081918ab5f39a208d2bdf0df95ae63143c515', content=[ResponseOutputText(annotations=[], text=\"Hereâ€™s a breakdown of the prices on the In-N-Out Burger menu:\\n\\n### Burgers & Combos\\n- Additional Burger Patty (per extra): $1.30\\n- Additional Cheese Slice (per extra): $0.50\\n- Hamburger: $3.60\\n- Hamburger Combo: $8.15\\n- Cheeseburger: $4.10\\n- Cheeseburger Combo: $8.65\\n- Double DoubleÂ®: $5.90\\n- Double DoubleÂ® Combo: $10.45\\n- French Fries: $2.30\\n\\n### Beverages\\n- Coffee: $1.35\\n- Hot Cocoa: $2.25\\n- Milk: $0.99\\n- Shakes (Chocolate, Strawberry, Vanilla): $3.00\\n- Soda (Small): $2.10\\n- Soda (Medium): $2.25\\n- Soda (Large): $2.45\\n- Soda (X-Large): $2.65\\n\\nIf you'd like me to calculate the total price for all items combined (excluding tax), just let me know!\", type='output_text')], role='assistant', status='completed', type='message'), type='message_output_item')], raw_responses=[ModelResponse(output=[ResponseOutputMessage(id='msg_67f8371ac80081918ab5f39a208d2bdf0df95ae63143c515', content=[ResponseOutputText(annotations=[], text=\"Hereâ€™s a breakdown of the prices on the In-N-Out Burger menu:\\n\\n### Burgers & Combos\\n- Additional Burger Patty (per extra): $1.30\\n- Additional Cheese Slice (per extra): $0.50\\n- Hamburger: $3.60\\n- Hamburger Combo: $8.15\\n- Cheeseburger: $4.10\\n- Cheeseburger Combo: $8.65\\n- Double DoubleÂ®: $5.90\\n- Double DoubleÂ® Combo: $10.45\\n- French Fries: $2.30\\n\\n### Beverages\\n- Coffee: $1.35\\n- Hot Cocoa: $2.25\\n- Milk: $0.99\\n- Shakes (Chocolate, Strawberry, Vanilla): $3.00\\n- Soda (Small): $2.10\\n- Soda (Medium): $2.25\\n- Soda (Large): $2.45\\n- Soda (X-Large): $2.65\\n\\nIf you'd like me to calculate the total price for all items combined (excluding tax), just let me know!\", type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=413, output_tokens=225, total_tokens=638), referenceable_id='resp_67f8371a792881918aad8b0d6899b4c00df95ae63143c515')], final_output=\"Hereâ€™s a breakdown of the prices on the In-N-Out Burger menu:\\n\\n### Burgers & Combos\\n- Additional Burger Patty (per extra): $1.30\\n- Additional Cheese Slice (per extra): $0.50\\n- Hamburger: $3.60\\n- Hamburger Combo: $8.15\\n- Cheeseburger: $4.10\\n- Cheeseburger Combo: $8.65\\n- Double DoubleÂ®: $5.90\\n- Double DoubleÂ® Combo: $10.45\\n- French Fries: $2.30\\n\\n### Beverages\\n- Coffee: $1.35\\n- Hot Cocoa: $2.25\\n- Milk: $0.99\\n- Shakes (Chocolate, Strawberry, Vanilla): $3.00\\n- Soda (Small): $2.10\\n- Soda (Medium): $2.25\\n- Soda (Large): $2.45\\n- Soda (X-Large): $2.65\\n\\nIf you'd like me to calculate the total price for all items combined (excluding tax), just let me know!\", input_guardrail_results=[], output_guardrail_results=[], current_agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# Inâ€‘Nâ€‘Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double DoubleÂ®**                      | $5.90  |\\n| **Double DoubleÂ® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (Xâ€‘Large)**                          | $2.65  |\\n\\n## Notâ€‘Soâ€‘Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustardâ€‘cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), current_turn=1, max_turns=10, is_complete=True)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import random\n",
        "from agents import Agent, ItemHelpers, Runner, function_tool\n",
        "\n",
        "result = Runner.run_streamed(\n",
        "    agent,\n",
        "    input=\"How much is 32 Double Doubles each with french fries?.\",\n",
        ")\n",
        "print(\"=== Run starting ===\")\n",
        "\n",
        "async for event in result.stream_events():\n",
        "    # We'll ignore the raw responses event deltas\n",
        "    if event.type == \"raw_response_event\":\n",
        "        continue\n",
        "    # When the agent updates, print that\n",
        "    elif event.type == \"agent_updated_stream_event\":\n",
        "        print(f\"Agent updated: {event.new_agent.name}\")\n",
        "        continue\n",
        "    # When items are generated, print them\n",
        "    elif event.type == \"run_item_stream_event\":\n",
        "        if event.item.type == \"tool_call_item\":\n",
        "            print(\"-- Tool was called\")\n",
        "        elif event.item.type == \"tool_call_output_item\":\n",
        "            print(f\"-- Tool output: {event.item.output}\")\n",
        "        elif event.item.type == \"message_output_item\":\n",
        "            print(f\"-- Message output:\\n {ItemHelpers.text_message_output(event.item)}\")\n",
        "        else:\n",
        "            pass  # Ignore other event types\n",
        "\n",
        "print(\"=== Run complete ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXxFTFa8nTgk",
        "outputId": "459e2cb0-f6c8-4f36-f4ce-85fd4c0c005d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Run starting ===\n",
            "Agent updated: In-N-Out Cashier Assistant\n",
            "-- Message output:\n",
            " To calculate the cost for 32 Double Doubles each with a French fry order:\n",
            "\n",
            "- **Double DoubleÂ® price:** $5.90\n",
            "- **French Fries price:** $2.30\n",
            "\n",
            "**Total for one combo (Double DoubleÂ® + French Fries):**\n",
            "- Double DoubleÂ® + French Fries = $5.90 + $2.30 = $8.20\n",
            "\n",
            "**Total for 32 combos:**\n",
            "- 32 combos x $8.20 = $262.40\n",
            "\n",
            "Now, adding tax (7.25%):\n",
            "- Tax = $262.40 x 0.0725 = $19.02 (approx.)\n",
            "\n",
            "**Total cost including tax:**\n",
            "- $262.40 + $19.02 = $281.42 (approx.)\n",
            "\n",
            "So, the total cost for 32 Double Doubles with French fries, including tax, is approximately **$281.42**.\n",
            "=== Run complete ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### streaming\n",
        "\n",
        "### 1. å•Ÿå‹•ä»£ç†çš„ä¸²æµåŸ·è¡Œ\n",
        "\n",
        "```python\n",
        "result = Runner.run_streamed(\n",
        "    agent,\n",
        "    input=\"How much is 32 Double Doubles each with french fries?.\",\n",
        ")\n",
        "```\n",
        "îˆ†\n",
        "\n",
        "- **`Runner.run_streamed()`**ï¼šé€™å€‹æ–¹æ³•å•Ÿå‹•æŒ‡å®šä»£ç†çš„ä¸²æµåŸ·è¡Œï¼Œä¸¦è¿”å›ä¸€å€‹ `RunResultStreaming` ç‰©ä»¶ã€‚îˆ†\n",
        "- **`agent`**ï¼šä»£è¡¨è¦åŸ·è¡Œçš„ä»£ç†å¯¦ä¾‹ã€‚îˆ†\n",
        "- **`input`**ï¼šæä¾›çµ¦ä»£ç†çš„è¼¸å…¥è¨Šæ¯ã€‚îˆ†\n",
        "\n",
        "### 2. éåŒæ­¥è™•ç†äº‹ä»¶æµ\n",
        "\n",
        "```python\n",
        "async for event in result.stream_events():\n",
        "```\n",
        "îˆ†\n",
        "\n",
        "- **`async for`**ï¼šä½¿ç”¨éåŒæ­¥è¿´åœˆä¾†éæ­·äº‹ä»¶æµï¼Œå…è¨±åœ¨äº‹ä»¶ç”¢ç”Ÿæ™‚å³æ™‚è™•ç†ã€‚îˆ†\n",
        "- **`result.stream_events()`**ï¼šè¿”å›ä¸€å€‹éåŒæ­¥ç”Ÿæˆå™¨ï¼Œç”¢ç”Ÿä»£ç†åŸ·è¡Œéç¨‹ä¸­çš„å„ç¨®äº‹ä»¶ã€‚îˆ†\n",
        "\n",
        "### 3. è™•ç†ä¸åŒé¡å‹çš„äº‹ä»¶\n",
        "\n",
        "#### a. å¿½ç•¥åŸå§‹å›æ‡‰äº‹ä»¶\n",
        "\n",
        "```python\n",
        "if event.type == \"raw_response_event\":\n",
        "    continue\n",
        "```\n",
        "îˆ†\n",
        "\n",
        "- **`raw_response_event`**ï¼šè¡¨ç¤ºä¾†è‡ªèªè¨€æ¨¡å‹çš„åŸå§‹å›æ‡‰äº‹ä»¶ï¼Œé€šå¸¸åŒ…å«é€å­—ç”Ÿæˆçš„æ–‡æœ¬ã€‚îˆ†\n",
        "- **`continue`**ï¼šè·³éé€™äº›äº‹ä»¶ï¼Œä¸é€²è¡Œè™•ç†ã€‚îˆ†\n",
        "\n",
        "#### b. è™•ç†ä»£ç†æ›´æ–°äº‹ä»¶\n",
        "\n",
        "```python\n",
        "elif event.type == \"agent_updated_stream_event\":\n",
        "    print(f\"Agent updated: {event.new_agent.name}\")\n",
        "    continue\n",
        "```\n",
        "îˆ†\n",
        "\n",
        "- **`agent_updated_stream_event`**ï¼šè¡¨ç¤ºä»£ç†å·²æ›´æ–°ï¼Œå¯èƒ½æ˜¯ç”±æ–¼ä»»å‹™è½‰äº¤çµ¦å…¶ä»–ä»£ç†ã€‚îˆ†\n",
        "- **`event.new_agent.name`**ï¼šå–å¾—æ–°çš„ä»£ç†åç¨±ä¸¦è¼¸å‡ºã€‚îˆ†\n",
        "\n",
        "#### c. è™•ç†åŸ·è¡Œé …ç›®äº‹ä»¶\n",
        "\n",
        "```python\n",
        "elif event.type == \"run_item_stream_event\":\n",
        "    if event.item.type == \"tool_call_item\":\n",
        "        print(\"-- Tool was called\")\n",
        "    elif event.item.type == \"tool_call_output_item\":\n",
        "        print(f\"-- Tool output: {event.item.output}\")\n",
        "    elif event.item.type == \"message_output_item\":\n",
        "        print(f\"-- Message output:\\n {ItemHelpers.text_message_output(event.item)}\")\n",
        "    else:\n",
        "        pass  # Ignore other event types\n",
        "```\n",
        "îˆ†\n",
        "\n",
        "- **`run_item_stream_event`**ï¼šè¡¨ç¤ºä»£ç†åŸ·è¡Œéç¨‹ä¸­çš„å…·é«”é …ç›®äº‹ä»¶ã€‚îˆ†\n",
        "- **`tool_call_item`**ï¼šä»£ç†å‘¼å«å·¥å…·çš„äº‹ä»¶ï¼Œè¼¸å‡ºæç¤ºã€‚îˆ†\n",
        "- **`tool_call_output_item`**ï¼šå·¥å…·åŸ·è¡Œå®Œæˆä¸¦è¿”å›çµæœçš„äº‹ä»¶ï¼Œè¼¸å‡ºçµæœã€‚îˆ†\n",
        "- **`message_output_item`**ï¼šä»£ç†ç”Ÿæˆè¨Šæ¯çš„äº‹ä»¶ï¼Œä½¿ç”¨ `ItemHelpers.text_message_output()` æ–¹æ³•æ ¼å¼åŒ–ä¸¦è¼¸å‡ºè¨Šæ¯å…§å®¹ã€‚îˆ†\n",
        "\n",
        "### 4. çµæŸåŸ·è¡Œ\n",
        "\n",
        "```python\n",
        "print(\"=== Run complete ===\")\n",
        "```\n",
        "îˆ†\n",
        "\n",
        "- åœ¨æ‰€æœ‰äº‹ä»¶è™•ç†å®Œç•¢å¾Œï¼Œè¼¸å‡ºåŸ·è¡Œå®Œæˆçš„æç¤ºã€‚îˆ†\n",
        "\n",
        "é€™æ®µç¨‹å¼ç¢¼çš„ç›®çš„æ˜¯å³æ™‚ç›£æ§ä»£ç†çš„åŸ·è¡Œéç¨‹ï¼Œä¸¦æ ¹æ“šä¸åŒçš„äº‹ä»¶é¡å‹è¼¸å‡ºç›¸æ‡‰çš„è³‡è¨Šï¼Œé€™å°æ–¼é–‹ç™¼äº¤äº’å¼æ‡‰ç”¨æˆ–é€²è¡Œé™¤éŒ¯éå¸¸æœ‰å¹«åŠ©ã€‚îˆ†"
      ],
      "metadata": {
        "id": "EIQAFglhnijF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding Tools"
      ],
      "metadata": {
        "id": "iAkcyaqKpFxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, function_tool\n",
        "\n",
        "@function_tool\n",
        "async def calculate_tax(order_total: float, tax_rate: float) -> str:\n",
        "    print(f\"[debug] calculating tax function called order:{order_total} tax:{tax_rate}\")\n",
        "    \"\"\"Calculates the tax for a given order total based on the input amount (float) and tax rate (float).\n",
        "    Args:\n",
        "        order_total: The total amount of the order before tax.\n",
        "        location: The location of the order. Defaults to Los Angeles, CA.\n",
        "    \"\"\"\n",
        "    tax_rate = 0.0725  # Default tax rate for Los Angeles, CA\n",
        "    tax_amount = order_total * tax_rate\n",
        "    total_with_tax = order_total + tax_amount\n",
        "    return f\"The tax on your order is ${tax_amount:.2f}. Your total with tax is ${total_with_tax:.2f}.\""
      ],
      "metadata": {
        "id": "JKTVxtSppErf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = Agent(name=\"In-N-Out Cashier Assistant\",\n",
        "              instructions=f\"You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n{MENU_PRICES}\",\n",
        "              model=\"gpt-4o\",\n",
        "              tools=[calculate_tax]\n",
        "              )"
      ],
      "metadata": {
        "id": "xx7CpYpapQqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(agent, \"How much is 5 Double Doubles each with french fries?.\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9jb0gp7pZrd",
        "outputId": "ee0a2a0b-7f2c-4ce6-9ad1-d1cf0a81914d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[debug] calculating tax function called order:40.1 tax:7.25\n",
            "[debug] calculating tax function called order:11.5 tax:7.25\n",
            "The cost for 5 Double Doubles with French Fries each is $40.10 before tax. \n",
            "\n",
            "With a 7.25% tax, the total comes to $43.01.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "æˆ‘åœ¨æ¸¬è©¦ä¸­ GPT-4o æ›¾ç¶“æœ‰è¨ˆç®—éŒ¯ 5 Double Doubles each with french fries çš„åƒ¹æ ¼"
      ],
      "metadata": {
        "id": "nwlqGWTsqQOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "41.0 *1.0725"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce1SDgQfprMg",
        "outputId": "47b58acc-962d-4907-b8cc-d8d544fa2438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43.972500000000004"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c082hu8zrgfK",
        "outputId": "e4c731b5-0fd9-46dc-a203-155b64b34205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RunResult(input='How much is 5 Double Doubles each with french fries?.', new_items=[ToolCallItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# Inâ€‘Nâ€‘Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double DoubleÂ®**                      | $5.90  |\\n| **Double DoubleÂ® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (Xâ€‘Large)**                          | $2.65  |\\n\\n## Notâ€‘Soâ€‘Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustardâ€‘cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"order_total\":40.1,\"tax_rate\":7.25}', call_id='call_Pwki0CEgV5ZbXCgHKyYBLyvN', name='calculate_tax', type='function_call', id='fc_67f83c4892e481918d3fb2a2e418458206f1996463c69815', status='completed'), type='tool_call_item'), ToolCallItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# Inâ€‘Nâ€‘Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double DoubleÂ®**                      | $5.90  |\\n| **Double DoubleÂ® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (Xâ€‘Large)**                          | $2.65  |\\n\\n## Notâ€‘Soâ€‘Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustardâ€‘cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"order_total\":11.5,\"tax_rate\":7.25}', call_id='call_z1wBBTZjhiuzrswaq5DhMGjV', name='calculate_tax', type='function_call', id='fc_67f83c48bf0481919ef1007bc288589206f1996463c69815', status='completed'), type='tool_call_item'), ToolCallOutputItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# Inâ€‘Nâ€‘Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double DoubleÂ®**                      | $5.90  |\\n| **Double DoubleÂ® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (Xâ€‘Large)**                          | $2.65  |\\n\\n## Notâ€‘Soâ€‘Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustardâ€‘cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_Pwki0CEgV5ZbXCgHKyYBLyvN', 'output': 'The tax on your order is $2.91. Your total with tax is $43.01.', 'type': 'function_call_output'}, output='The tax on your order is $2.91. Your total with tax is $43.01.', type='tool_call_output_item'), ToolCallOutputItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# Inâ€‘Nâ€‘Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double DoubleÂ®**                      | $5.90  |\\n| **Double DoubleÂ® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (Xâ€‘Large)**                          | $2.65  |\\n\\n## Notâ€‘Soâ€‘Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustardâ€‘cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_z1wBBTZjhiuzrswaq5DhMGjV', 'output': 'The tax on your order is $0.83. Your total with tax is $12.33.', 'type': 'function_call_output'}, output='The tax on your order is $0.83. Your total with tax is $12.33.', type='tool_call_output_item'), MessageOutputItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# Inâ€‘Nâ€‘Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double DoubleÂ®**                      | $5.90  |\\n| **Double DoubleÂ® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (Xâ€‘Large)**                          | $2.65  |\\n\\n## Notâ€‘Soâ€‘Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustardâ€‘cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='msg_67f83c49677881918da25e377f8811aa06f1996463c69815', content=[ResponseOutputText(annotations=[], text='The cost for 5 Double Doubles with French Fries each is $40.10 before tax. \\n\\nWith a 7.25% tax, the total comes to $43.01.', type='output_text')], role='assistant', status='completed', type='message'), type='message_output_item')], raw_responses=[ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"order_total\":40.1,\"tax_rate\":7.25}', call_id='call_Pwki0CEgV5ZbXCgHKyYBLyvN', name='calculate_tax', type='function_call', id='fc_67f83c4892e481918d3fb2a2e418458206f1996463c69815', status='completed'), ResponseFunctionToolCall(arguments='{\"order_total\":11.5,\"tax_rate\":7.25}', call_id='call_z1wBBTZjhiuzrswaq5DhMGjV', name='calculate_tax', type='function_call', id='fc_67f83c48bf0481919ef1007bc288589206f1996463c69815', status='completed')], usage=Usage(requests=1, input_tokens=0, output_tokens=0, total_tokens=0), referenceable_id='resp_67f83c481c4c8191b82131980c819f9f06f1996463c69815'), ModelResponse(output=[ResponseOutputMessage(id='msg_67f83c49677881918da25e377f8811aa06f1996463c69815', content=[ResponseOutputText(annotations=[], text='The cost for 5 Double Doubles with French Fries each is $40.10 before tax. \\n\\nWith a 7.25% tax, the total comes to $43.01.', type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=562, output_tokens=41, total_tokens=603), referenceable_id='resp_67f83c4910948191b8075040da16271506f1996463c69815')], final_output='The cost for 5 Double Doubles with French Fries each is $40.10 before tax. \\n\\nWith a 7.25% tax, the total comes to $43.01.', input_guardrail_results=[], output_guardrail_results=[], _last_agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# Inâ€‘Nâ€‘Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double DoubleÂ®**                      | $5.90  |\\n| **Double DoubleÂ® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (Xâ€‘Large)**                          | $2.65  |\\n\\n## Notâ€‘Soâ€‘Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustardâ€‘cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in result.__dict__.items():\n",
        "  print(f\"{k}: {v}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HK09nabUrobq",
        "outputId": "f4247a2b-9076-4dcd-ba98-07dc05b8c947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: How much is 5 Double Doubles each with french fries?.\n",
            "new_items: [ToolCallItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# Inâ€‘Nâ€‘Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double DoubleÂ®**                      | $5.90  |\\n| **Double DoubleÂ® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (Xâ€‘Large)**                          | $2.65  |\\n\\n## Notâ€‘Soâ€‘Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustardâ€‘cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"order_total\":40.1,\"tax_rate\":7.25}', call_id='call_Pwki0CEgV5ZbXCgHKyYBLyvN', name='calculate_tax', type='function_call', id='fc_67f83c4892e481918d3fb2a2e418458206f1996463c69815', status='completed'), type='tool_call_item'), ToolCallItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# Inâ€‘Nâ€‘Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double DoubleÂ®**                      | $5.90  |\\n| **Double DoubleÂ® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (Xâ€‘Large)**                          | $2.65  |\\n\\n## Notâ€‘Soâ€‘Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustardâ€‘cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"order_total\":11.5,\"tax_rate\":7.25}', call_id='call_z1wBBTZjhiuzrswaq5DhMGjV', name='calculate_tax', type='function_call', id='fc_67f83c48bf0481919ef1007bc288589206f1996463c69815', status='completed'), type='tool_call_item'), ToolCallOutputItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# Inâ€‘Nâ€‘Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double DoubleÂ®**                      | $5.90  |\\n| **Double DoubleÂ® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (Xâ€‘Large)**                          | $2.65  |\\n\\n## Notâ€‘Soâ€‘Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustardâ€‘cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_Pwki0CEgV5ZbXCgHKyYBLyvN', 'output': 'The tax on your order is $2.91. Your total with tax is $43.01.', 'type': 'function_call_output'}, output='The tax on your order is $2.91. Your total with tax is $43.01.', type='tool_call_output_item'), ToolCallOutputItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# Inâ€‘Nâ€‘Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double DoubleÂ®**                      | $5.90  |\\n| **Double DoubleÂ® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (Xâ€‘Large)**                          | $2.65  |\\n\\n## Notâ€‘Soâ€‘Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustardâ€‘cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_z1wBBTZjhiuzrswaq5DhMGjV', 'output': 'The tax on your order is $0.83. Your total with tax is $12.33.', 'type': 'function_call_output'}, output='The tax on your order is $0.83. Your total with tax is $12.33.', type='tool_call_output_item'), MessageOutputItem(agent=Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# Inâ€‘Nâ€‘Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double DoubleÂ®**                      | $5.90  |\\n| **Double DoubleÂ® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (Xâ€‘Large)**                          | $2.65  |\\n\\n## Notâ€‘Soâ€‘Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustardâ€‘cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='msg_67f83c49677881918da25e377f8811aa06f1996463c69815', content=[ResponseOutputText(annotations=[], text='The cost for 5 Double Doubles with French Fries each is $40.10 before tax. \\n\\nWith a 7.25% tax, the total comes to $43.01.', type='output_text')], role='assistant', status='completed', type='message'), type='message_output_item')]\n",
            "raw_responses: [ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"order_total\":40.1,\"tax_rate\":7.25}', call_id='call_Pwki0CEgV5ZbXCgHKyYBLyvN', name='calculate_tax', type='function_call', id='fc_67f83c4892e481918d3fb2a2e418458206f1996463c69815', status='completed'), ResponseFunctionToolCall(arguments='{\"order_total\":11.5,\"tax_rate\":7.25}', call_id='call_z1wBBTZjhiuzrswaq5DhMGjV', name='calculate_tax', type='function_call', id='fc_67f83c48bf0481919ef1007bc288589206f1996463c69815', status='completed')], usage=Usage(requests=1, input_tokens=0, output_tokens=0, total_tokens=0), referenceable_id='resp_67f83c481c4c8191b82131980c819f9f06f1996463c69815'), ModelResponse(output=[ResponseOutputMessage(id='msg_67f83c49677881918da25e377f8811aa06f1996463c69815', content=[ResponseOutputText(annotations=[], text='The cost for 5 Double Doubles with French Fries each is $40.10 before tax. \\n\\nWith a 7.25% tax, the total comes to $43.01.', type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=562, output_tokens=41, total_tokens=603), referenceable_id='resp_67f83c4910948191b8075040da16271506f1996463c69815')]\n",
            "final_output: The cost for 5 Double Doubles with French Fries each is $40.10 before tax. \n",
            "\n",
            "With a 7.25% tax, the total comes to $43.01.\n",
            "input_guardrail_results: []\n",
            "output_guardrail_results: []\n",
            "_last_agent: Agent(name='In-N-Out Cashier Assistant', instructions='You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n\\n\\n# Inâ€‘Nâ€‘Out Burger Menu (2025)\\n\\n**Prices are approximate and subject to change.**\\n\\n## Burgers & Combos\\n\\n| Item                                    | Price  |\\n|-----------------------------------------|--------|\\n| Additional Burger Patty (per extra)     | $1.30  |\\n| Additional Cheese Slice (per extra)     | $0.50  |\\n| **Hamburger**                           | $3.60  |\\n| **Hamburger Combo**                     | $8.15  |\\n| **Cheeseburger**                        | $4.10  |\\n| **Cheeseburger Combo**                  | $8.65  |\\n| **Double DoubleÂ®**                      | $5.90  |\\n| **Double DoubleÂ® Combo**                | $10.45 |\\n| **French Fries**                        | $2.30  |\\n\\n## Beverages\\n\\n| Item                                        | Price  |\\n|---------------------------------------------|--------|\\n| **Coffee**                                  | $1.35  |\\n| **Hot Cocoa**                               | $2.25  |\\n| **Milk**                                    | $0.99  |\\n| **Shakes** (Chocolate, Strawberry, Vanilla) | $3.00  |\\n| **Soda (Small)**                            | $2.10  |\\n| **Soda (Medium)**                           | $2.25  |\\n| **Soda (Large)**                            | $2.45  |\\n| **Soda (Xâ€‘Large)**                          | $2.65  |\\n\\n## Notâ€‘Soâ€‘Secret Menu Options\\n\\n- **Protein Style Burger:** Any burger wrapped in lettuce instead of a bun.\\n- **Animal Style:** Burger or fries served with a mustardâ€‘cooked beef patty, extra spread, pickles, and grilled onions.\\n\\ntax not included\\n\\ntax is 7.25%\\n\\n---', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='calculate_tax', description='', params_json_schema={'properties': {'order_total': {'title': 'Order Total', 'type': 'number'}, 'tax_rate': {'title': 'Tax Rate', 'type': 'number'}}, 'required': ['order_total', 'tax_rate'], 'title': 'calculate_tax_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c15568e0>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def extract_function_calls(run_result):\n",
        "    \"\"\"\n",
        "    Extracts function call items (both the call details and outputs)\n",
        "    from the run_result object.\n",
        "    \"\"\"\n",
        "    function_calls = {}\n",
        "    # Use attribute access instead of dict.get()\n",
        "    new_items = run_result.new_items if hasattr(run_result, 'new_items') else []\n",
        "\n",
        "    for item in new_items:\n",
        "        # Assuming each item has an attribute 'raw_item'\n",
        "        raw_item = item.raw_item if hasattr(item, 'raw_item') else {}\n",
        "\n",
        "        # Try to get the type from raw_item. It might be a dict or an object.\n",
        "        if isinstance(raw_item, dict):\n",
        "            item_type = raw_item.get(\"type\")\n",
        "            call_id = raw_item.get(\"call_id\")\n",
        "        else:\n",
        "            item_type = getattr(raw_item, \"type\", None)\n",
        "            call_id = getattr(raw_item, \"call_id\", None)\n",
        "\n",
        "        # Check if the item is a function call or its output\n",
        "        if item_type in [\"function_call\", \"function_call_output\"]:\n",
        "            if call_id not in function_calls:\n",
        "                function_calls[call_id] = {}\n",
        "            if item_type == \"function_call\":\n",
        "                # Get arguments as a JSON string and parse it\n",
        "                if isinstance(raw_item, dict):\n",
        "                    args = raw_item.get(\"arguments\")\n",
        "                    function_calls[call_id][\"name\"] = raw_item.get(\"name\")\n",
        "                else:\n",
        "                    args = getattr(raw_item, \"arguments\", None)\n",
        "                    function_calls[call_id][\"name\"] = getattr(raw_item, \"name\", None)\n",
        "                try:\n",
        "                    function_calls[call_id][\"arguments\"] = json.loads(args)\n",
        "                except Exception:\n",
        "                    function_calls[call_id][\"arguments\"] = args\n",
        "            elif item_type == \"function_call_output\":\n",
        "                if isinstance(raw_item, dict):\n",
        "                    function_calls[call_id][\"output\"] = raw_item.get(\"output\")\n",
        "                else:\n",
        "                    function_calls[call_id][\"output\"] = getattr(raw_item, \"output\", None)\n",
        "    return function_calls\n",
        "\n",
        "# Assuming `result` is your RunResult object:\n",
        "calls = extract_function_calls(result)\n",
        "\n",
        "# Print the extracted details\n",
        "for call_id, details in calls.items():\n",
        "    print(f\"Call ID: {call_id}\")\n",
        "    print(f\"Function Name: {details.get('name', 'N/A')}\")\n",
        "    print(\"Arguments:\")\n",
        "    for arg, value in details.get(\"arguments\", {}).items():\n",
        "        print(f\"  {arg}: {value}\")\n",
        "    print(\"Output:\")\n",
        "    print(f\"  {details.get('output', 'No output')}\")\n",
        "    print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4eGiXupryDq",
        "outputId": "58a8b656-b32f-4da6-f0f6-3034b2374a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Call ID: call_Pwki0CEgV5ZbXCgHKyYBLyvN\n",
            "Function Name: calculate_tax\n",
            "Arguments:\n",
            "  order_total: 40.1\n",
            "  tax_rate: 7.25\n",
            "Output:\n",
            "  The tax on your order is $2.91. Your total with tax is $43.01.\n",
            "----------------------------------------\n",
            "Call ID: call_z1wBBTZjhiuzrswaq5DhMGjV\n",
            "Function Name: calculate_tax\n",
            "Arguments:\n",
            "  order_total: 11.5\n",
            "  tax_rate: 7.25\n",
            "Output:\n",
            "  The tax on your order is $0.83. Your total with tax is $12.33.\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Websearch Tool"
      ],
      "metadata": {
        "id": "NVEE1MX-r7IL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, FileSearchTool, Runner, WebSearchTool"
      ],
      "metadata": {
        "id": "LgerrUHar5ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcdonalds_agent = Agent(name=\"McDonalds Assistant\",\n",
        "              instructions=f\"You are a helpful server at McDonalds, respond to questions by using the search tool\",\n",
        "              model=\"gpt-4o\",\n",
        "              tools=[WebSearchTool()]\n",
        "              )"
      ],
      "metadata": {
        "id": "AhOc8T7VsFRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(mcdonalds_agent, \"How much is BigMac?.\")\n",
        "\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJicFk0TsKfb",
        "outputId": "758556ba-1ef1-4850-b8a7-96960e2c95dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As of 2024, the average price of a McDonald's Big Mac in the United States is approximately $5.29, reflecting a 20.5% increase from $4.39 in 2019. ([wsaz.com](https://www.wsaz.com/2024/05/30/mcdonalds-says-18-big-mac-meal-was-an-exception-news-reports-overstated-its-price-increases/?utm_source=openai)) However, prices can vary by location due to factors like regional costs and franchisee pricing decisions. For instance, in Massachusetts, a Big Mac can cost as much as $7.09, while in North Carolina and Wyoming, it's priced at $4.19. ([zippia.com](https://www.zippia.com/advice/how-much-big-mac-costs-states/?utm_source=openai)) Additionally, McDonald's has introduced value deals, such as a $5 meal promotion, to offer more affordable options to customers. ([wsaz.com](https://www.wsaz.com/2024/05/30/mcdonalds-says-18-big-mac-meal-was-an-exception-news-reports-overstated-its-price-increases/?utm_source=openai)) \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.new_items[1].raw_item.content[0].annotations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq6bUIQBsUT8",
        "outputId": "8ff9b1a8-3e94-4a6a-a45e-2be4bef116c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AnnotationURLCitation(end_index=303, start_index=147, title=\"McDonald's says $18 Big Mac meal was an 'exception' and news reports overstated its price increases\", type='url_citation', url='https://www.wsaz.com/2024/05/30/mcdonalds-says-18-big-mac-meal-was-an-exception-news-reports-overstated-its-price-increases/?utm_source=openai'),\n",
              " AnnotationURLCitation(end_index=632, start_index=538, title='How Much A Big Mac Costs In Every State - Zippia', type='url_citation', url='https://www.zippia.com/advice/how-much-big-mac-costs-states/?utm_source=openai'),\n",
              " AnnotationURLCitation(end_index=918, start_index=762, title=\"McDonald's says $18 Big Mac meal was an 'exception' and news reports overstated its price increases\", type='url_citation', url='https://www.wsaz.com/2024/05/30/mcdonalds-says-18-big-mac-meal-was-an-exception-news-reports-overstated-its-price-increases/?utm_source=openai')]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agents as tools"
      ],
      "metadata": {
        "id": "oHHvBj0jsWKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner\n",
        "import asyncio\n",
        "\n",
        "\n",
        "\n",
        "orchestrator_agent = Agent(\n",
        "    name=\"orchestrator_agent\",\n",
        "    instructions=(\n",
        "        \"You are a DoorDash Agent who decides which tools or assistants to call \"\n",
        "        \"If asked for prices or menu items, you call the relevant tools.\"\n",
        "        \"if asked for info from. more than one source run multiple tools\"\n",
        "    ),\n",
        "    tools=[\n",
        "        agent.as_tool(\n",
        "            tool_name=\"in_n_out_burger_assistant\",\n",
        "            tool_description=\"Get prices with tax for In-N-Out Burger\",\n",
        "        ),\n",
        "        mcdonalds_agent.as_tool(\n",
        "            tool_name=\"mcdonalds_assistant\",\n",
        "            tool_description=\"Get prices for McDonalds\",\n",
        "        ),\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "janSLi3TsY70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(orchestrator_agent, input=\"How much is a Double Double at in-N-out?\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1hcPdsZsgRj",
        "outputId": "af545d87-37d3-41e0-85bf-72491b185d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Double DoubleÂ® by itself is $5.90, and as a Combo with fries and a drink, it's $10.45.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(orchestrator_agent, input=\"what does McDonalds have for breakfast?\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfB5cG_tssT2",
        "outputId": "5f4b0989-0ab9-4110-8836-ef68006bcc56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "McDonald's breakfast menu includes a variety of delicious options:\n",
            "\n",
            "1. **Egg McMuffinÂ®**: Freshly cracked egg, Canadian bacon, and American cheese on an English muffin (310 calories).\n",
            "\n",
            "2. **Sausage McMuffinÂ® with Egg**: Sausage, American cheese, and a freshly cracked egg on an English muffin (480 calories).\n",
            "\n",
            "3. **Bacon, Egg & Cheese Biscuit**: Buttermilk biscuit with bacon, egg, and American cheese (450 calories).\n",
            "\n",
            "4. **Sausage, Egg & Cheese McGriddlesÂ®**: Sausage, egg, and cheese between maple-flavored griddle cakes (550 calories).\n",
            "\n",
            "5. **Hotcakes**: Three hotcakes with butter and syrup (590 calories).\n",
            "\n",
            "For more details, including prices and local availability, check with your local McDonald's or visit their [official breakfast menu](https://www.mcdonalds.com/us/en-us/full-menu/breakfast.html).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(orchestrator_agent, input=\"Is a BigMac or a DoubleDouble AnimalStyle cheaper?\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuUHUFh4sz-9",
        "outputId": "e12a4ae9-b1ce-426d-8b15-4445e190ba33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[debug] calculating tax function called order:5.9 tax:7.25\n",
            "The Double Double Animal Style at In-N-Out costs $6.33 with tax, while the average price of a Big Mac at McDonald's is around $5.29. Therefore, the Big Mac is generally cheaper.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYpVgsH-s3ac",
        "outputId": "42ccb547-08b5-49dd-c76c-6024b9dea6a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RunResult(input='Is a BigMac or a DoubleDouble AnimalStyle cheaper?', new_items=[ToolCallItem(agent=Agent(name='orchestrator_agent', instructions='You are a DoorDash Agent who decides which tools or assistants to call If asked for prices or menu items, you call the relevant tools.if asked for info from. more than one source run multiple tools', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='in_n_out_burger_assistant', description='Get prices with tax for In-N-Out Burger', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'in_n_out_burger_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1590ea0>, strict_json_schema=True), FunctionTool(name='mcdonalds_assistant', description='Get prices for McDonalds', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'mcdonalds_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1525080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"input\":\"Big Mac\"}', call_id='call_hKLyrzpSmH8lVzJ6df5ZeJWQ', name='mcdonalds_assistant', type='function_call', id='fc_67f83e4753948191a3ba0d5042244cdf05f5889c5a98b6a8', status='completed'), type='tool_call_item'), ToolCallItem(agent=Agent(name='orchestrator_agent', instructions='You are a DoorDash Agent who decides which tools or assistants to call If asked for prices or menu items, you call the relevant tools.if asked for info from. more than one source run multiple tools', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='in_n_out_burger_assistant', description='Get prices with tax for In-N-Out Burger', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'in_n_out_burger_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1590ea0>, strict_json_schema=True), FunctionTool(name='mcdonalds_assistant', description='Get prices for McDonalds', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'mcdonalds_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1525080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"input\":\"Double Double Animal Style\"}', call_id='call_sieCxHHI10ME6IWdCrGddscS', name='in_n_out_burger_assistant', type='function_call', id='fc_67f83e477f048191a424f82124b8637605f5889c5a98b6a8', status='completed'), type='tool_call_item'), ToolCallOutputItem(agent=Agent(name='orchestrator_agent', instructions='You are a DoorDash Agent who decides which tools or assistants to call If asked for prices or menu items, you call the relevant tools.if asked for info from. more than one source run multiple tools', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='in_n_out_burger_assistant', description='Get prices with tax for In-N-Out Burger', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'in_n_out_burger_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1590ea0>, strict_json_schema=True), FunctionTool(name='mcdonalds_assistant', description='Get prices for McDonalds', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'mcdonalds_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1525080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_hKLyrzpSmH8lVzJ6df5ZeJWQ', 'output': \"The Big Mac is one of McDonald's most iconic burgers. It features:\\n\\n- Two all-beef patties\\n- Special sauce (similar to Thousand Island dressing)\\n- Lettuce\\n- Cheese\\n- Pickles\\n- Onions\\n- Served on a sesame seed bun with an additional middle bun\\n\\nWould you like to know anything else about it?\", 'type': 'function_call_output'}, output=\"The Big Mac is one of McDonald's most iconic burgers. It features:\\n\\n- Two all-beef patties\\n- Special sauce (similar to Thousand Island dressing)\\n- Lettuce\\n- Cheese\\n- Pickles\\n- Onions\\n- Served on a sesame seed bun with an additional middle bun\\n\\nWould you like to know anything else about it?\", type='tool_call_output_item'), ToolCallOutputItem(agent=Agent(name='orchestrator_agent', instructions='You are a DoorDash Agent who decides which tools or assistants to call If asked for prices or menu items, you call the relevant tools.if asked for info from. more than one source run multiple tools', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='in_n_out_burger_assistant', description='Get prices with tax for In-N-Out Burger', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'in_n_out_burger_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1590ea0>, strict_json_schema=True), FunctionTool(name='mcdonalds_assistant', description='Get prices for McDonalds', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'mcdonalds_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1525080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_sieCxHHI10ME6IWdCrGddscS', 'output': 'The Double DoubleÂ® Animal Style includes a mustard-cooked beef patty, extra spread, pickles, and grilled onions. The base price for a Double DoubleÂ® is $5.90. Would you like me to calculate the total with tax for you?', 'type': 'function_call_output'}, output='The Double DoubleÂ® Animal Style includes a mustard-cooked beef patty, extra spread, pickles, and grilled onions. The base price for a Double DoubleÂ® is $5.90. Would you like me to calculate the total with tax for you?', type='tool_call_output_item'), ToolCallItem(agent=Agent(name='orchestrator_agent', instructions='You are a DoorDash Agent who decides which tools or assistants to call If asked for prices or menu items, you call the relevant tools.if asked for info from. more than one source run multiple tools', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='in_n_out_burger_assistant', description='Get prices with tax for In-N-Out Burger', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'in_n_out_burger_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1590ea0>, strict_json_schema=True), FunctionTool(name='mcdonalds_assistant', description='Get prices for McDonalds', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'mcdonalds_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1525080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"input\":\"Big Mac price\"}', call_id='call_0pgpU9lxW3NHLIPsJ2VdaTC8', name='mcdonalds_assistant', type='function_call', id='fc_67f83e4a429481919ae677f6d655eaa105f5889c5a98b6a8', status='completed'), type='tool_call_item'), ToolCallItem(agent=Agent(name='orchestrator_agent', instructions='You are a DoorDash Agent who decides which tools or assistants to call If asked for prices or menu items, you call the relevant tools.if asked for info from. more than one source run multiple tools', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='in_n_out_burger_assistant', description='Get prices with tax for In-N-Out Burger', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'in_n_out_burger_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1590ea0>, strict_json_schema=True), FunctionTool(name='mcdonalds_assistant', description='Get prices for McDonalds', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'mcdonalds_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1525080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"input\":\"Double Double Animal Style price with tax\"}', call_id='call_TihHAnux5U14safi5SvJeaSN', name='in_n_out_burger_assistant', type='function_call', id='fc_67f83e4a66288191bc25a1e01ada353905f5889c5a98b6a8', status='completed'), type='tool_call_item'), ToolCallOutputItem(agent=Agent(name='orchestrator_agent', instructions='You are a DoorDash Agent who decides which tools or assistants to call If asked for prices or menu items, you call the relevant tools.if asked for info from. more than one source run multiple tools', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='in_n_out_burger_assistant', description='Get prices with tax for In-N-Out Burger', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'in_n_out_burger_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1590ea0>, strict_json_schema=True), FunctionTool(name='mcdonalds_assistant', description='Get prices for McDonalds', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'mcdonalds_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1525080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_0pgpU9lxW3NHLIPsJ2VdaTC8', 'output': \"As of April 2025, the average price of a Big Mac in the United States is approximately $5.29, reflecting a 21% increase from $4.39 in 2019. ([cbsnews.com](https://www.cbsnews.com/news/mcdonalds-menu-price-hikes-fast-food/?utm_source=openai)) Prices can vary by location due to factors such as local operating costs and franchisee pricing decisions. For instance, in 2024, Hawaii had the highest average price at $6.75, while Mississippi offered the lowest at $4.75. ([mymcdonaldsmenuprices.com](https://mymcdonaldsmenuprices.com/how-much-does-a-big-mac-cost/?utm_source=openai)) It's important to note that these figures are averages, and actual prices may differ based on specific locations and current economic conditions. \", 'type': 'function_call_output'}, output=\"As of April 2025, the average price of a Big Mac in the United States is approximately $5.29, reflecting a 21% increase from $4.39 in 2019. ([cbsnews.com](https://www.cbsnews.com/news/mcdonalds-menu-price-hikes-fast-food/?utm_source=openai)) Prices can vary by location due to factors such as local operating costs and franchisee pricing decisions. For instance, in 2024, Hawaii had the highest average price at $6.75, while Mississippi offered the lowest at $4.75. ([mymcdonaldsmenuprices.com](https://mymcdonaldsmenuprices.com/how-much-does-a-big-mac-cost/?utm_source=openai)) It's important to note that these figures are averages, and actual prices may differ based on specific locations and current economic conditions. \", type='tool_call_output_item'), ToolCallOutputItem(agent=Agent(name='orchestrator_agent', instructions='You are a DoorDash Agent who decides which tools or assistants to call If asked for prices or menu items, you call the relevant tools.if asked for info from. more than one source run multiple tools', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='in_n_out_burger_assistant', description='Get prices with tax for In-N-Out Burger', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'in_n_out_burger_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1590ea0>, strict_json_schema=True), FunctionTool(name='mcdonalds_assistant', description='Get prices for McDonalds', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'mcdonalds_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1525080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_TihHAnux5U14safi5SvJeaSN', 'output': 'The price of a Double Double Animal Style with tax is $6.33.', 'type': 'function_call_output'}, output='The price of a Double Double Animal Style with tax is $6.33.', type='tool_call_output_item'), MessageOutputItem(agent=Agent(name='orchestrator_agent', instructions='You are a DoorDash Agent who decides which tools or assistants to call If asked for prices or menu items, you call the relevant tools.if asked for info from. more than one source run multiple tools', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='in_n_out_burger_assistant', description='Get prices with tax for In-N-Out Burger', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'in_n_out_burger_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1590ea0>, strict_json_schema=True), FunctionTool(name='mcdonalds_assistant', description='Get prices for McDonalds', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'mcdonalds_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1525080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='msg_67f83e4f5ed48191979e523989b5e5c505f5889c5a98b6a8', content=[ResponseOutputText(annotations=[], text=\"The Double Double Animal Style at In-N-Out costs $6.33 with tax, while the average price of a Big Mac at McDonald's is around $5.29. Therefore, the Big Mac is generally cheaper.\", type='output_text')], role='assistant', status='completed', type='message'), type='message_output_item')], raw_responses=[ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"input\":\"Big Mac\"}', call_id='call_hKLyrzpSmH8lVzJ6df5ZeJWQ', name='mcdonalds_assistant', type='function_call', id='fc_67f83e4753948191a3ba0d5042244cdf05f5889c5a98b6a8', status='completed'), ResponseFunctionToolCall(arguments='{\"input\":\"Double Double Animal Style\"}', call_id='call_sieCxHHI10ME6IWdCrGddscS', name='in_n_out_burger_assistant', type='function_call', id='fc_67f83e477f048191a424f82124b8637605f5889c5a98b6a8', status='completed')], usage=Usage(requests=1, input_tokens=0, output_tokens=0, total_tokens=0), referenceable_id='resp_67f83e4663e881918c79741a95851d0a05f5889c5a98b6a8'), ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"input\":\"Big Mac price\"}', call_id='call_0pgpU9lxW3NHLIPsJ2VdaTC8', name='mcdonalds_assistant', type='function_call', id='fc_67f83e4a429481919ae677f6d655eaa105f5889c5a98b6a8', status='completed'), ResponseFunctionToolCall(arguments='{\"input\":\"Double Double Animal Style price with tax\"}', call_id='call_TihHAnux5U14safi5SvJeaSN', name='in_n_out_burger_assistant', type='function_call', id='fc_67f83e4a66288191bc25a1e01ada353905f5889c5a98b6a8', status='completed')], usage=Usage(requests=1, input_tokens=0, output_tokens=0, total_tokens=0), referenceable_id='resp_67f83e49740c81919d19dd33a4faf83c05f5889c5a98b6a8'), ModelResponse(output=[ResponseOutputMessage(id='msg_67f83e4f5ed48191979e523989b5e5c505f5889c5a98b6a8', content=[ResponseOutputText(annotations=[], text=\"The Double Double Animal Style at In-N-Out costs $6.33 with tax, while the average price of a Big Mac at McDonald's is around $5.29. Therefore, the Big Mac is generally cheaper.\", type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=609, output_tokens=46, total_tokens=655), referenceable_id='resp_67f83e4effc48191aa82193b3fb7fe2005f5889c5a98b6a8')], final_output=\"The Double Double Animal Style at In-N-Out costs $6.33 with tax, while the average price of a Big Mac at McDonald's is around $5.29. Therefore, the Big Mac is generally cheaper.\", input_guardrail_results=[], output_guardrail_results=[], _last_agent=Agent(name='orchestrator_agent', instructions='You are a DoorDash Agent who decides which tools or assistants to call If asked for prices or menu items, you call the relevant tools.if asked for info from. more than one source run multiple tools', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None), tools=[FunctionTool(name='in_n_out_burger_assistant', description='Get prices with tax for In-N-Out Burger', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'in_n_out_burger_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1590ea0>, strict_json_schema=True), FunctionTool(name='mcdonalds_assistant', description='Get prices for McDonalds', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'mcdonalds_assistant_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ae9c1525080>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `agent.as_tool()` v.s. `handoffs`\n",
        "\n",
        "åœ¨ OpenAI Agents SDK ä¸­ï¼Œ`agent.as_tool()` å’Œ `handoffs` æ˜¯å…©ç¨®ä¸åŒçš„ä»£ç†ï¼ˆAgentï¼‰å”ä½œæ–¹å¼ï¼Œå„è‡ªé©ç”¨æ–¼ä¸åŒçš„å ´æ™¯ã€‚ä»¥ä¸‹æ˜¯å®ƒå€‘çš„ä¸»è¦å·®ç•°ï¼š\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”§ `agent.as_tool()`ï¼šå°‡ä»£ç†ä½œç‚ºå·¥å…·ä½¿ç”¨\n",
        "\n",
        "- **ç”¨é€”**îˆƒå°‡ä¸€å€‹ä»£ç†å°è£ç‚ºå·¥å…·ï¼Œä½¿å…¶ä»–ä»£ç†å¯ä»¥åœ¨å…¶å…§éƒ¨æµç¨‹ä¸­èª¿ç”¨å®ƒîˆ„îˆ†\n",
        "- **ç‰¹é»**ï¼š\n",
        "  -îˆƒè¢«èª¿ç”¨çš„ä»£ç†ä¸æœƒæ¥ç®¡å°è©±æµç¨‹ï¼Œè€Œæ˜¯åŸ·è¡Œç‰¹å®šä»»å‹™å¾Œå°‡çµæœè¿”å›çµ¦èª¿ç”¨è€…îˆ„îˆ†\n",
        "  -îˆƒé©ç”¨æ–¼éœ€è¦åœ¨ä¸»ä»£ç†æµç¨‹ä¸­åµŒå…¥ç‰¹å®šåŠŸèƒ½çš„æƒ…å¢ƒï¼Œä¾‹å¦‚è¨ˆç®—ã€æŸ¥è©¢ç­‰îˆ„îˆ†\n",
        "- **ä½¿ç”¨æ–¹å¼**ï¼š\n",
        "  -îˆƒé€é `agent.as_tool()` æ–¹æ³•å°‡ä»£ç†è½‰æ›ç‚ºå·¥å…·îˆ„îˆ†\n",
        "  -îˆƒåœ¨ä¸»ä»£ç†çš„ `tools` åƒæ•¸ä¸­åŠ å…¥è©²å·¥å…·îˆ„îˆ†\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ¤ `handoffs`ï¼šä»£ç†é–“çš„ä»»å‹™ç§»äº¤\n",
        "\n",
        "- **ç”¨é€”*ï¼šîˆƒåœ¨ä»£ç†ä¹‹é–“ç§»äº¤å°è©±æ§åˆ¶æ¬Šï¼Œè®“å°ˆé–€çš„ä»£ç†è™•ç†ç‰¹å®šä»»ã€‚îˆ„îˆ†\n",
        "- **ç‰¹é»**ï¼š\n",
        "   îˆƒè¢«ç§»äº¤çš„ä»£ç†æ¥ç®¡å°è©±æµç¨‹ï¼Œä¸¦æ ¹æ“šå…¶è¨­è¨ˆè™•ç†å¾ŒçºŒçš„å°ã€‚îˆ„îˆ†\n",
        "   îˆƒé©ç”¨æ–¼éœ€è¦æ ¹æ“šç”¨æˆ¶è¼¸å…¥å‹•æ…‹æ±ºå®šç”±å“ªå€‹ä»£ç†è™•ç†çš„æƒ…å¢ƒï¼Œä¾‹å¦‚èªè¨€è­˜åˆ¥å¾Œé¸æ“‡ç›¸æ‡‰èªè¨€çš„ä»£ã€‚îˆ„îˆ†\n",
        "- **ä½¿ç”¨æ–¹å¼**ï¼š\n",
        "   îˆƒåœ¨ä¸»ä»£ç†çš„ `handoffs` åƒæ•¸ä¸­æŒ‡å®šå¯ç§»äº¤çš„ä»£ç†åˆ—ã€‚îˆ„îˆ†\n",
        "   îˆƒä¸»ä»£ç†æ ¹æ“šå°è©±å…§å®¹æ±ºå®šæ˜¯å¦é€²è¡Œç§»ã€‚îˆ„îˆ†\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ†š æ¯”è¼ƒç¸½çµ\n",
        "\n",
        "| ç‰¹æ€§             | `agent.as_tool()`                           | `handoffs`                                 |\n",
        "|------------------|---------------------------------------------|--------------------------------------------|\n",
        "| æ§åˆ¶æ¬Š          | îˆƒä¸»ä»£ç†ä¿ç•™åˆ¶æ¬Šîˆ„                        | îˆƒæ§åˆ¶æ¬Šç§»äº¤çµ¦è¢«æŒ‡å®šä»£ç†îˆ„               |\n",
        "| é©ç”¨å ´æ™¯        | îˆƒåµŒå…¥ç‰¹å®šåŠŸèƒ½æˆ–å·¥èª¿ç”¨îˆ„                  | îˆƒæ ¹æ“šå°è©±å…§å®¹å‹•æ…‹é¸æ“‡è™•ä»£ç†îˆ„           |\n",
        "| å°è©±æ­·å²        | îˆƒè¢«èª¿ç”¨ä»£ç†ä¸æ¥æ”¶å®Œæ•´å°æ­·å²îˆ„            | îˆƒè¢«ç§»äº¤ä»£ç†æ¥æ”¶å®Œæ•´å°æ­·å²îˆ„             |\n",
        "| ä½¿ç”¨æ–¹å¼        | îˆƒå°‡ä»£ç†è½‰æ›ç‚ºå·¥å…·ä¸¦åŠ å…¥ä¸»ä»£ç†çš„å·¥åˆ—è¡¨îˆ„  | îˆƒåœ¨ä¸»ä»£ç†ä¸­æŒ‡å®šå¯ç§»äº¤çš„ä»£åˆ—è¡¨îˆ„         |\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“ å¯¦éš›æ‡‰ç”¨å»ºè­°\n",
        "- îˆƒç•¶éœ€è¦åœ¨ä¸»ä»£ç†æµç¨‹ä¸­èª¿ç”¨ç‰¹å®šåŠŸèƒ½æ™‚ï¼Œä½¿ç”¨ `agent.as_tool()` æ˜¯è¼ƒç‚ºåˆé©é¸æ“‡ã€‚îˆ„\n",
        "- îˆƒç•¶éœ€è¦æ ¹æ“šç”¨æˆ¶è¼¸å…¥å‹•æ…‹é¸æ“‡è™•ç†ä»£ç†ï¼Œä¸¦è®“å…¶æ¥ç®¡å°è©±æµç¨‹æ™‚ï¼Œä½¿ç”¨ `handoffs` æ›´é©å®œã€‚îˆ†\n",
        "\n",
        "îˆƒé€™å…©ç¨®æ–¹å¼å¯ä»¥æ ¹æ“šå¯¦éš›éœ€æ±‚éˆæ´»é¸æ“‡ï¼Œç”šè‡³åœ¨åŒä¸€æ‡‰ç”¨ä¸­çµåˆä½¿ç”¨ï¼Œä»¥å¯¦ç¾æ›´è¤‡é›œçš„ä»£ç†å”æµç¨‹ã€‚îˆ„îˆ†"
      ],
      "metadata": {
        "id": "5ADqsDCqe8nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Giving it a Chat Memory"
      ],
      "metadata": {
        "id": "7Rskid9Ts688"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = Agent(name=\"In-N-Out Cashier Assistant\",\n",
        "              instructions=f\"You are a helpful server at In-N-Out Burger respond to questions based on the menu below: \\n\\n{MENU_PRICES}\",\n",
        "              model=\"gpt-4o\",\n",
        "              tools=[calculate_tax]\n",
        "              )"
      ],
      "metadata": {
        "id": "iFPyTUC-s5pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(agent, \"ok first let me order a Double Doubles with french fries.\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGkMS5UQtCu1",
        "outputId": "e37b6858-0c56-4370-94fa-017e7aac1954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Would you like to make it a Combo for $10.45, or get the Double DoubleÂ® and French Fries separately for a total of $8.20?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.to_input_list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5vwDde7tGb3",
        "outputId": "c87d7455-eb7b-4c9f-eb72-fcc49c1db10c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'content': 'ok first let me order a Double Doubles with french fries.',\n",
              "  'role': 'user'},\n",
              " {'id': 'msg_67f83e8a77ec819182c4e9dc0f9b41300db1a0ca547b7298',\n",
              "  'content': [{'annotations': [],\n",
              "    'text': 'Would you like to make it a Combo for $10.45, or get the Double DoubleÂ® and French Fries separately for a total of $8.20?',\n",
              "    'type': 'output_text'}],\n",
              "  'role': 'assistant',\n",
              "  'status': 'completed',\n",
              "  'type': 'message'}]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### to_input_list()\n",
        "\n",
        "åœ¨ OpenAI Agents SDK ä¸­ï¼Œ`result.to_input_list()` æ–¹æ³•çš„å‘½åå’ŒåŠŸèƒ½è¨­è¨ˆï¼Œæ—¨åœ¨ç°¡åŒ–å¤šè¼ªå°è©±çš„ä¸Šä¸‹æ–‡ç®¡ç†ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”„ `to_input_list()` çš„å‘½åå«ç¾©\n",
        "îˆƒ`to_input_list()` çš„å‘½åç›´è§€åœ°è¡¨æ˜å…¶åŠŸèƒ½ï¼šå°‡ä»£ç†é‹è¡Œçš„çµæœè½‰æ›ç‚ºä¸€å€‹è¼¸å…¥åˆ—è¡¨îˆ„é€™å€‹åˆ—è¡¨åŒ…æ‹¬ï¼šîˆ†\n",
        "\n",
        "1.îˆƒåŸå§‹çš„ç”¨æˆ¶è¼¸å…¥îˆ„îˆ†\n",
        "2.îˆƒä»£ç†åœ¨é‹è¡Œéç¨‹ä¸­ç”Ÿæˆçš„æ‰€æœ‰æ–°é …ç›®ï¼ˆå¦‚æ¨¡å‹å›æ‡‰ã€å·¥å…·èª¿ç”¨ã€äº¤æ¥ç­‰ï¼‰îˆ„îˆ†\n",
        "îˆƒé€™æ¨£çš„è¨­è¨ˆä½¿å¾—é–‹ç™¼è€…èƒ½å¤ è¼•é¬†åœ°å°‡ä¸€æ¬¡ä»£ç†é‹è¡Œçš„ä¸Šä¸‹æ–‡ä½œç‚ºä¸‹ä¸€æ¬¡é‹è¡Œçš„è¼¸å…¥ï¼Œå¯¦ç¾å°è©±çš„é€£è²«æ€§îˆ„îˆ†\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ§  ç‚ºä½•éœ€è¦ `to_input_list()`\n",
        "îˆƒåœ¨å¤šè¼ªå°è©±ä¸­ï¼Œä¿æŒä¸Šä¸‹æ–‡çš„ä¸€è‡´æ€§è‡³é—œé‡îˆ„îˆƒ`to_input_list()` æ–¹æ³•æä¾›äº†ä¸€ç¨®ç°¡ä¾¿çš„æ–¹å¼ï¼Œå°‡ä¹‹å‰çš„å°è©±æ­·å²å’Œä»£ç†ç”Ÿæˆçš„å…§å®¹çµ„åˆæˆæ–°çš„è¼¸å…¥ï¼Œä¾›ä¸‹ä¸€è¼ªä½¿ã€‚îˆ„é€™é¿å…äº†æ‰‹å‹•ç®¡ç†å°è©±æ­·å²çš„ç¹ç‘£ï¼Œæé«˜äº†é–‹ç™¼æ•ˆç‡ã€‚îˆ†\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ§© èˆ‡å…¶ä»–æ–¹æ³•çš„é—œç³»\n",
        "\n",
        "îˆƒ`to_input_list()` æ˜¯ `RunResultBase` é¡ä¸­çš„ä¸€å€‹æ–¹æ³•ï¼Œè©²é¡æ˜¯ä»£ç†é‹è¡Œçµæœçš„ã€‚îˆ„îˆƒé€™æ„å‘³è‘—ç„¡è«–æ˜¯åŒæ­¥é‹è¡Œé‚„æ˜¯ç•°æ­¥é‹è¡Œçš„çµæœï¼Œéƒ½å¯ä»¥ä½¿ç”¨æ­¤æ–¹æ³•ä¾†ç²å–æ–°çš„è¼¸å…¥è¡¨ã€‚îˆ„îˆ†\n",
        "\n"
      ],
      "metadata": {
        "id": "xBVJkC19djV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assemble_conversation(result, new_input):\n",
        "    if result !=None:\n",
        "        new_input = result.to_input_list() + [{'content': new_input,\n",
        "                                                'role': 'user'}]\n",
        "    else:\n",
        "        new_input = new_input\n",
        "    return new_input"
      ],
      "metadata": {
        "id": "fn55qAtztLyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_prompt = \"Yes make it a combo please\""
      ],
      "metadata": {
        "id": "eScfQfXmtOqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_input = assemble_conversation(result, new_prompt)\n",
        "\n",
        "result = await Runner.run(agent, new_input)\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElrDcT5XtSLl",
        "outputId": "0115da20-0e84-4d18-f119-4c77752eaaa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[debug] calculating tax function called order:10.45 tax:7.25\n",
            "Your Double DoubleÂ® Combo comes to $10.45, and with tax, the total is $11.21. Would you like to add anything else to your order?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_prompt = \"Yes can I get a coffee as well. thats all\" #coffee $1.35"
      ],
      "metadata": {
        "id": "0bAsBBmdtVsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_input = assemble_conversation(result, new_prompt)\n",
        "\n",
        "result = await Runner.run(agent, new_input)\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW9rCEU_tZid",
        "outputId": "d75e699f-1275-47d7-b2fb-7f8c79a10323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[debug] calculating tax function called order:1.35 tax:7.25\n",
            "The coffee is $1.35, and with tax, the total is $1.45.\n",
            "\n",
            "Your new order total, including the combo and coffee, is $12.66. Would you like to proceed with this order?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAIâ€™s BRAND NEW Agents SDK (Crash Course)\n",
        "\n",
        "OpenAIâ€™s BRAND NEW Agents SDK (Crash Course) https://www.youtube.com/watch?v=e7qvd2bOITc\n",
        "  - https://github.com/coleam00/ottomator-agents/tree/main/openai-sdk-agent\n",
        "  - https://github.com/openai/openai-agents-python/tree/main\n",
        "  - https://openai.github.io/openai-agents-python/"
      ],
      "metadata": {
        "id": "MiIuxRxn0N55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Core concepts:\n",
        "\n",
        "1. [**Agents**](https://openai.github.io/openai-agents-python/agents): LLMs configured with instructions, tools, guardrails, and handoffs\n",
        "2. [**Handoffs**](https://openai.github.io/openai-agents-python/handoffs/): A specialized tool call used by the Agents SDK for transferring control between agents\n",
        "3. [**Guardrails**](https://openai.github.io/openai-agents-python/guardrails/): Configurable safety checks for input and output validation\n",
        "4. [**Tracing**](https://openai.github.io/openai-agents-python/tracing/): Built-in tracking of agent runs, allowing you to view, debug and optimize your workflows\n",
        "\n",
        "Explore the [examples](examples) directory to see the SDK in action, and read our [documentation](https://openai.github.io/openai-agents-python/) for more details.\n",
        "\n",
        "Notably, our SDK [is compatible](https://openai.github.io/openai-agents-python/models/) with any model providers that support the OpenAI Chat Completions API format."
      ],
      "metadata": {
        "id": "Ot9P4ekV050G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project Structure\n",
        "\n",
        "- `v1_basic_agent.py` - A simple agent example that generates a haiku about recursion\n",
        "- `v2_structured_output.py` - Travel agent with structured output using Pydantic models\n",
        "- `v3_tool_calls.py` - Travel agent with tool calls for weather forecasting\n",
        "- `v4_handoffs.py` - Travel agent with specialized sub-agents for flights and hotels\n",
        "- `v5_guardrails_and_context.py` - Travel agent with budget guardrails and user context\n",
        "- `v6_streamlit_agent.py` - A Streamlit web interface for the travel agent with chat memory"
      ],
      "metadata": {
        "id": "yC97bBKd1ysm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install openai-agents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a7ecd6-e3f5-4401-dbaf-8365174bacab",
        "id": "xn9iODB75JXl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/107.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/129.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”\u001b[0m \u001b[32m122.9/129.2 kB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.2/129.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "\n",
        "# Verify that the key is set\n",
        "print(f\"OpenAI API key set: {bool(openai_api_key)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5182c47-3ff3-4039-dbd9-08a60b63c558",
        "id": "LG3ibufL5JXl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API key set: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### v1_basic_agent"
      ],
      "metadata": {
        "id": "UUJMnuTh5XGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=\"You are a helpful assistant\",\n",
        "    model=\"gpt-4o-mini\"\n",
        ")\n",
        "\n",
        "result = Runner.run_sync(agent, \"Write a haiku about recursion in programming.\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M9PrPs_tcSt",
        "outputId": "031d7c49-c01c-4ba9-dfbf-86084fd8d67b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code calls back to itself,  \n",
            "Layers deep, a loop unfolds,  \n",
            "Endless paths converge.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### v2_structured_output"
      ],
      "metadata": {
        "id": "Dh2yVGeY5bof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "2H1-tvj56pZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from typing import List\n",
        "from pydantic import BaseModel, Field\n",
        "from agents import Agent, Runner\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "model = os.getenv('MODEL_CHOICE', 'gpt-4o-mini')\n",
        "\n",
        "# --- Models for structured outputs ---\n",
        "\n",
        "class TravelPlan(BaseModel):\n",
        "    destination: str\n",
        "    duration_days: int\n",
        "    budget: float\n",
        "    activities: List[str] = Field(description=\"List of recommended activities\")\n",
        "    notes: str = Field(description=\"Additional notes or recommendations\")\n",
        "\n",
        "# --- Main Travel Agent ---\n",
        "\n",
        "travel_agent = Agent(\n",
        "    name=\"Travel Planner\",\n",
        "    instructions=\"\"\"\n",
        "    You are a comprehensive travel planning assistant that helps users plan their perfect trip.\n",
        "\n",
        "    You can create personalized travel itineraries based on the user's interests and preferences.\n",
        "\n",
        "    Always be helpful, informative, and enthusiastic about travel. Provide specific recommendations\n",
        "    based on the user's interests and preferences.\n",
        "\n",
        "    When creating travel plans, consider:\n",
        "    - Local attractions and activities\n",
        "    - Budget constraints\n",
        "    - Travel duration\n",
        "    \"\"\",\n",
        "    model=model,\n",
        "    output_type=TravelPlan\n",
        ")\n",
        "\n",
        "# --- Main Function ---\n",
        "\n",
        "async def main():\n",
        "    # Example queries to test the system\n",
        "    queries = [\n",
        "        \"I'm planning a trip to Miami for 5 days with a budget of $2000. What should I do there?\",\n",
        "        \"I want to visit Tokyo for a week with a budget of $3000. What activities do you recommend?\"\n",
        "    ]\n",
        "\n",
        "    for query in queries:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"QUERY: {query}\")\n",
        "\n",
        "        result = await Runner.run(travel_agent, query)\n",
        "\n",
        "        print(\"\\nFINAL RESPONSE:\")\n",
        "        travel_plan = result.final_output\n",
        "\n",
        "        # Format the output in a nicer way\n",
        "        print(f\"\\nğŸŒ TRAVEL PLAN FOR {travel_plan.destination.upper()} ğŸŒ\")\n",
        "        print(f\"Duration: {travel_plan.duration_days} days\")\n",
        "        print(f\"Budget: ${travel_plan.budget}\")\n",
        "\n",
        "        print(\"\\nğŸ¯ RECOMMENDED ACTIVITIES:\")\n",
        "        for i, activity in enumerate(travel_plan.activities, 1):\n",
        "            print(f\"  {i}. {activity}\")\n",
        "\n",
        "        print(f\"\\nğŸ“ NOTES: {travel_plan.notes}\")\\\n",
        "\n",
        "'''\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n",
        "'''\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE0GAuLs50E0",
        "outputId": "579a3c90-291d-438d-e2cd-abad02db07bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "QUERY: I'm planning a trip to Miami for 5 days with a budget of $2000. What should I do there?\n",
            "\n",
            "FINAL RESPONSE:\n",
            "\n",
            "ğŸŒ TRAVEL PLAN FOR MIAMI, FLORIDA ğŸŒ\n",
            "Duration: 5 days\n",
            "Budget: $2000.0\n",
            "\n",
            "ğŸ¯ RECOMMENDED ACTIVITIES:\n",
            "  1. Visit South Beach and relax on the iconic sandy shores\n",
            "  2. Explore the vibrant Art Deco Historic District\n",
            "  3. Take a stroll through the colorful Wynwood Walls\n",
            "  4. Enjoy a day at the Miami Seaquarium\n",
            "  5. Visit Little Havana for a taste of Cuban culture and cuisine\n",
            "  6. Take a boat tour of Biscayne Bay to see the luxurious islands\n",
            "  7. Explore the shops and cafes at Lincoln Road Mall\n",
            "  8. Visit the PÃ©rez Art Museum Miami (PAMM) for contemporary art\n",
            "\n",
            "ğŸ“ NOTES: Consider dining at local food trucks or casual eateries to save on meals while enjoying authentic flavors. Check out happy hour specials for drinks and snacks. Make sure to pack sunscreen!\n",
            "\n",
            "==================================================\n",
            "QUERY: I want to visit Tokyo for a week with a budget of $3000. What activities do you recommend?\n",
            "\n",
            "FINAL RESPONSE:\n",
            "\n",
            "ğŸŒ TRAVEL PLAN FOR TOKYO, JAPAN ğŸŒ\n",
            "Duration: 7 days\n",
            "Budget: $3000.0\n",
            "\n",
            "ğŸ¯ RECOMMENDED ACTIVITIES:\n",
            "  1. Visit the historic Senso-ji Temple in Asakusa\n",
            "  2. Explore the bustling streets of Shibuya and take a photo at the famous Shibuya Crossing\n",
            "  3. Experience the vibrant Harajuku district and shop on Takeshita Street\n",
            "  4. Visit the Tokyo Skytree for panoramic views of the city\n",
            "  5. Spend a day in Akihabara, the center of otaku culture and electronics\n",
            "  6. Take a walk in Ueno Park and visit its museums, including the Tokyo National Museum\n",
            "  7. Explore the tranquil Meiji Shrine\n",
            "  8. Enjoy a sushi-making class or a local izakaya dining experience\n",
            "  9. Take a day trip to Nikko or Mount Fuji\n",
            "  10. Visit the teamLab Borderless digital art museum in Odaiba\n",
            "\n",
            "ğŸ“ NOTES: Consider purchasing a Japan Rail Pass for convenient travel. Don't forget to try local delicacies like ramen, sushi, and street food. Check for any cultural festivals or events during your visit!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### pydantic\n",
        "\n",
        "`TravelPlan` é¡åˆ¥ç¹¼æ‰¿è‡ª `pydantic.BaseModel`ï¼Œé€™ä½¿å¾—å®ƒæˆç‚ºä¸€å€‹çµæ§‹åŒ–è³‡æ–™æ¨¡å‹ï¼Œèƒ½å¤ è‡ªå‹•é©—è­‰å’Œè§£æè³‡æ–™ã€‚\n",
        "\n",
        "ä½¿ç”¨ Pydantic å®šç¾©çš„æ¨¡å‹å¯ä»¥ç¢ºä¿è³‡æ–™çš„å®Œæ•´æ€§å’Œæ­£ç¢ºæ€§ï¼Œç‰¹åˆ¥æ˜¯åœ¨èˆ‡å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰äº’å‹•æ™‚ï¼Œèƒ½å¤ å°‡éçµæ§‹åŒ–çš„è¼¸å‡ºè½‰æ›ç‚ºçµæ§‹åŒ–çš„è³‡æ–™æ ¼å¼ã€‚https://www.youtube.com/watch?v=pZ4DIH2BVqg\n",
        "\n",
        "ä¾‹å¦‚ï¼Œç•¶æ‚¨ä½¿ç”¨ OpenAI çš„ API ä¸¦æŒ‡å®š `response_model=TravelPlan` æ™‚ï¼Œè¿”å›çš„è³‡æ–™å°‡è‡ªå‹•è¢«è§£æç‚º `TravelPlan` çš„å¯¦ä¾‹ï¼Œä¸¦é€²è¡Œé¡å‹é©—è­‰ã€‚\n",
        "\n",
        "é€™ç¨®æ–¹å¼çš„å„ªé»åŒ…æ‹¬ï¼š\n",
        "\n",
        "- **é¡å‹å®‰å…¨**ï¼šç¢ºä¿æ¯å€‹æ¬„ä½çš„è³‡æ–™é¡å‹æ­£ç¢ºï¼Œå¦å‰‡æœƒå¼•ç™¼éŒ¯èª¤ã€‚\n",
        "- **è³‡æ–™é©—è­‰**ï¼šå¯ä»¥è¨­ç½®æ¬„ä½çš„ç´„æŸæ¢ä»¶ï¼Œä¾‹å¦‚æ•¸å€¼ç¯„åœã€å­—ä¸²æ ¼å¼ç­‰ã€‚\n",
        "- **æ˜“æ–¼æ•´åˆ**ï¼šçµæ§‹åŒ–çš„è³‡æ–™æ›´å®¹æ˜“èˆ‡å…¶ä»–ç³»çµ±æˆ–è³‡æ–™åº«æ•´åˆã€‚\n",
        "\n",
        "ç¸½ä¹‹ï¼ŒPydantic æä¾›äº†ä¸€ç¨®å¼·å¤§ä¸”éˆæ´»çš„æ–¹å¼ä¾†è™•ç†å’Œé©—è­‰è³‡æ–™ï¼Œç‰¹åˆ¥é©åˆç”¨æ–¼éœ€è¦é«˜å¯é æ€§å’Œå¯ç¶­è­·æ€§çš„æ‡‰ç”¨å ´æ™¯ã€‚\n",
        "https://medium.com/%40bohachu/%E5%AB%8C%E6%A3%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9B%9E%E5%82%B3%E6%A0%BC%E5%BC%8F%E5%8F%AA%E6%9C%8980-%E6%A9%9F%E7%8E%87%E6%AD%A3%E7%A2%BA%E5%97%8E-python-instructor%E8%AE%93llm%E7%A9%A9%E5%AE%9A%E5%9B%9E%E5%82%B3pydantic%E7%B5%90%E6%A7%8B%E5%8C%96%E7%89%A9%E4%BB%B6-d5c4f7d909cc\n",
        "\n",
        "\n",
        "**æˆ‘å€‘åœ¨ Agent å®šç¾©äº† output_type=TravelPlan  ä¾†é™åˆ¶è¼¸å‡ºçš„æ ¼å¼**"
      ],
      "metadata": {
        "id": "hRQrQYDJILK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### v3_tool_calls"
      ],
      "metadata": {
        "id": "byMyfBLa7Ooh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "j6xDpYii7pz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import json\n",
        "from typing import List\n",
        "from pydantic import BaseModel, Field\n",
        "from agents import Agent, Runner, function_tool\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "model = os.getenv('MODEL_CHOICE', 'gpt-4o-mini')\n",
        "\n",
        "# --- Models for structured outputs ---\n",
        "\n",
        "class TravelPlan(BaseModel):\n",
        "    destination: str\n",
        "    duration_days: int\n",
        "    budget: float\n",
        "    activities: List[str] = Field(description=\"List of recommended activities\")\n",
        "    notes: str = Field(description=\"Additional notes or recommendations\")\n",
        "\n",
        "# --- Tools ---\n",
        "\n",
        "@function_tool\n",
        "def get_weather_forecast(city: str, date: str) -> str:\n",
        "    \"\"\"Get the weather forecast for a city on a specific date.\"\"\"\n",
        "    # In a real implementation, this would call a weather API\n",
        "    weather_data = {\n",
        "        \"New York\": {\"sunny\": 0.3, \"rainy\": 0.4, \"cloudy\": 0.3},\n",
        "        \"Los Angeles\": {\"sunny\": 0.8, \"rainy\": 0.1, \"cloudy\": 0.1},\n",
        "        \"Chicago\": {\"sunny\": 0.4, \"rainy\": 0.3, \"cloudy\": 0.3},\n",
        "        \"Miami\": {\"sunny\": 0.7, \"rainy\": 0.2, \"cloudy\": 0.1},\n",
        "        \"London\": {\"sunny\": 0.2, \"rainy\": 0.5, \"cloudy\": 0.3},\n",
        "        \"Paris\": {\"sunny\": 0.4, \"rainy\": 0.3, \"cloudy\": 0.3},\n",
        "        \"Tokyo\": {\"sunny\": 0.5, \"rainy\": 0.3, \"cloudy\": 0.2},\n",
        "    }\n",
        "\n",
        "    if city in weather_data:\n",
        "        conditions = weather_data[city]\n",
        "        # Simple simulation based on probabilities\n",
        "        highest_prob = max(conditions, key=conditions.get)\n",
        "        temp_range = {\n",
        "            \"New York\": \"15-25Â°C\",\n",
        "            \"Los Angeles\": \"20-30Â°C\",\n",
        "            \"Chicago\": \"10-20Â°C\",\n",
        "            \"Miami\": \"25-35Â°C\",\n",
        "            \"London\": \"10-18Â°C\",\n",
        "            \"Paris\": \"12-22Â°C\",\n",
        "            \"Tokyo\": \"15-25Â°C\",\n",
        "        }\n",
        "        return f\"The weather in {city} on {date} is forecasted to be {highest_prob} with temperatures around {temp_range.get(city, '15-25Â°C')}.\"\n",
        "    else:\n",
        "        return f\"Weather forecast for {city} is not available.\"\n",
        "\n",
        "# --- Main Travel Agent ---\n",
        "\n",
        "travel_agent = Agent(\n",
        "    name=\"Travel Planner\",\n",
        "    instructions=\"\"\"\n",
        "    You are a comprehensive travel planning assistant that helps users plan their perfect trip.\n",
        "\n",
        "    You can:\n",
        "    1. Provide weather information for destinations\n",
        "    2. Create personalized travel itineraries\n",
        "\n",
        "    Always be helpful, informative, and enthusiastic about travel. Provide specific recommendations\n",
        "    based on the user's interests and preferences.\n",
        "\n",
        "    When creating travel plans, consider:\n",
        "    - The weather at the destination\n",
        "    - Local attractions and activities\n",
        "    - Budget constraints\n",
        "    - Travel duration\n",
        "    \"\"\",\n",
        "    model=model,\n",
        "    tools=[get_weather_forecast],\n",
        "    output_type=TravelPlan\n",
        ")\n",
        "\n",
        "# --- Main Function ---\n",
        "\n",
        "async def main():\n",
        "    # Example queries to test the system\n",
        "    queries = [\n",
        "        \"I'm planning a trip to Miami for 5 days with a budget of $2000. What should I do there and what is the weather going to look like?\",\n",
        "        \"I want to visit Paris for a week with a budget of $3000. What activities do you recommend based on the weather?\"\n",
        "    ]\n",
        "\n",
        "    for query in queries:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"QUERY: {query}\")\n",
        "\n",
        "        result = await Runner.run(travel_agent, query)\n",
        "\n",
        "        print(\"\\nFINAL RESPONSE:\")\n",
        "        travel_plan = result.final_output\n",
        "\n",
        "        # Format the output in a nicer way\n",
        "        print(f\"\\nğŸŒ TRAVEL PLAN FOR {travel_plan.destination.upper()} ğŸŒ\")\n",
        "        print(f\"Duration: {travel_plan.duration_days} days\")\n",
        "        print(f\"Budget: ${travel_plan.budget}\")\n",
        "\n",
        "        print(\"\\nğŸ¯ RECOMMENDED ACTIVITIES:\")\n",
        "        for i, activity in enumerate(travel_plan.activities, 1):\n",
        "            print(f\"  {i}. {activity}\")\n",
        "\n",
        "        print(f\"\\nğŸ“ NOTES: {travel_plan.notes}\")\n",
        "\n",
        "'''\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n",
        "'''\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CmJte8F7Tir",
        "outputId": "783609b1-e8b8-4199-b839-7c614e661fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "QUERY: I'm planning a trip to Miami for 5 days with a budget of $2000. What should I do there and what is the weather going to look like?\n",
            "\n",
            "FINAL RESPONSE:\n",
            "\n",
            "ğŸŒ TRAVEL PLAN FOR MIAMI ğŸŒ\n",
            "Duration: 5 days\n",
            "Budget: $2000.0\n",
            "\n",
            "ğŸ¯ RECOMMENDED ACTIVITIES:\n",
            "  1. Relax on South Beach\n",
            "  2. Visit the Art Deco Historic District\n",
            "  3. Explore Little Havana and try Cuban cuisine\n",
            "  4. Take a boat tour of Biscayne Bay\n",
            "  5. Spend a day at the Vizcaya Museum and Gardens\n",
            "  6. Enjoy nightlife at Ocean Drive\n",
            "  7. Visit the Miami Seaquarium\n",
            "\n",
            "ğŸ“ NOTES: The weather will be sunny with temperatures ranging from 25-35Â°C throughout your trip. Pack light, breathable clothing and sunscreen. Consider renting a bike for easy transportation around the beach and city!\n",
            "\n",
            "==================================================\n",
            "QUERY: I want to visit Paris for a week with a budget of $3000. What activities do you recommend based on the weather?\n",
            "\n",
            "FINAL RESPONSE:\n",
            "\n",
            "ğŸŒ TRAVEL PLAN FOR PARIS ğŸŒ\n",
            "Duration: 7 days\n",
            "Budget: $3000.0\n",
            "\n",
            "ğŸ¯ RECOMMENDED ACTIVITIES:\n",
            "  1. Visit the Eiffel Tower and enjoy the views from the top\n",
            "  2. Explore the Louvre Museum to see the Mona Lisa\n",
            "  3. Take a Seine River cruise for a scenic view of the city\n",
            "  4. Stroll through Montmartre and visit the SacrÃ©-CÅ“ur Basilica\n",
            "  5. Enjoy a picnic in Luxembourg Gardens\n",
            "  6. Sample pastries at a local patisserie\n",
            "  7. Explore the vibrant streets of Le Marais district\n",
            "  8. Take a day trip to Versailles to see the grand palace and gardens\n",
            "\n",
            "ğŸ“ NOTES: The weather in Paris for your visit will be sunny with mild temperatures ranging from 12-22Â°C, perfect for outdoor activities!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### V3 function\n",
        "\n",
        "### ğŸ§­ åŠŸèƒ½æ¦‚è¿°\n",
        "\n",
        "- **ä»£ç†ï¼ˆAgentï¼‰è¨­å®š**îˆƒå®šç¾©äº†ä¸€å€‹åç‚ºã€ŒTravel Plannerã€çš„ä»£ç†ï¼Œå…·å‚™æä¾›å¤©æ°£è³‡è¨Šå’Œå€‹äººåŒ–æ—…éŠè¡Œç¨‹çš„èƒ½åŠ›îˆ„îˆ†\n",
        "\n",
        "- **å·¥å…·æ•´åˆ**îˆƒé€é `@function_tool` è£é£¾å™¨ï¼Œå°‡ `get_weather_forecast` å‡½å¼è¨»å†Šç‚ºä»£ç†å¯ç”¨çš„å·¥å…·ï¼Œæ¨¡æ“¬æä¾›ç‰¹å®šåŸå¸‚å’Œæ—¥æœŸçš„å¤©æ°£é å ±îˆ„îˆ†\n",
        "\n",
        "- **çµæ§‹åŒ–è¼¸å‡º**îˆƒä½¿ç”¨ Pydantic çš„ `TravelPlan` æ¨¡å‹ï¼Œç¢ºä¿ä»£ç†çš„è¼¸å‡ºç¬¦åˆé å®šçš„çµæ§‹ï¼ŒåŒ…æ‹¬ç›®çš„åœ°ã€æ—…éŠå¤©æ•¸ã€é ç®—ã€å»ºè­°æ´»å‹•å’Œå‚™è¨»îˆ„îˆ†\n",
        "\n",
        "- **éåŒæ­¥åŸ·è¡Œ**îˆƒåœ¨ `main` å‡½å¼ä¸­ï¼Œé€ééåŒæ­¥æ–¹å¼åŸ·è¡Œä»£ç†ï¼Œè™•ç†å¤šå€‹æŸ¥è©¢ï¼Œä¸¦æ ¼å¼åŒ–è¼¸å‡ºçµæœîˆ„îˆ†"
      ],
      "metadata": {
        "id": "p5uk6HYQF9Sw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `get_weather_forecast` `@function_tool`\n",
        "\n",
        "`@function_tool` æ˜¯ OpenAI Agents SDK æä¾›çš„è£é£¾å™¨ï¼Œç”¨æ–¼å°‡æ™®é€šçš„ Python å‡½å¼è½‰æ›ç‚ºä»£ç†å¯ç”¨çš„å·¥å…·ã€‚å®ƒæœƒè‡ªå‹•è§£æå‡½å¼çš„ç°½åå’Œæ–‡æª”å­—ä¸²ï¼ˆdocstringï¼‰ï¼Œç”Ÿæˆå°æ‡‰çš„ JSON æ¶æ§‹ï¼Œä¾›ä»£ç†åœ¨éœ€è¦æ™‚å‘¼å«ã€‚îˆ†\n",
        "\n",
        "ä»¥ä¸‹æ˜¯å°ç¨‹å¼ç¢¼çš„é€è¡Œè§£é‡‹ï¼š\n",
        "\n",
        "```python\n",
        "@function_tool\n",
        "def get_weather_forecast(city: str, date: str) -> str:\n",
        "    \"\"\"Get the weather forecast for a city on a specific date.\"\"\"\n",
        "```\n",
        "\n",
        "- é€™æ®µå®šç¾©äº†ä¸€å€‹åç‚º `get_weather_forecast` çš„å‡½å¼ï¼Œæ¥å—å…©å€‹åƒæ•¸ï¼š`city`ï¼ˆåŸå¸‚åç¨±ï¼‰å’Œ `date`ï¼ˆæ—¥æœŸï¼‰ï¼Œä¸¦è¿”å›ä¸€å€‹å­—ä¸²ã€‚\n",
        "- **å‡½å¼çš„æ–‡æª”å­—ä¸²æä¾›äº†å°å‡½å¼åŠŸèƒ½çš„ç°¡è¦èªªæ˜ï¼Œé€™äº›è³‡è¨Šæœƒè¢« `@function_tool` ç”¨ä¾†ç”Ÿæˆå·¥å…·çš„æè¿°ã€‚**\n",
        "\n",
        "```python\n",
        "    # In a real implementation, this would call a weather API\n",
        "    weather_data = {\n",
        "        \"New York\": {\"sunny\": 0.3, \"rainy\": 0.4, \"cloudy\": 0.3},\n",
        "        \"Tokyo\": {\"sunny\": 0.5, \"rainy\": 0.3, \"cloudy\": 0.2},\n",
        "    }\n",
        "```\n",
        "\n",
        "- é€™æ˜¯ä¸€å€‹æ¨¡æ“¬çš„å¤©æ°£è³‡æ–™å­—å…¸ï¼ŒåŒ…å«äº†å¤šå€‹åŸå¸‚åŠå…¶å°æ‡‰çš„å¤©æ°£ç‹€æ³æ©Ÿç‡åˆ†ä½ˆã€‚îˆ†\n",
        "- åœ¨å¯¦éš›æ‡‰ç”¨ä¸­ï¼Œé€™éƒ¨åˆ†æ‡‰è©²æ˜¯å‘¼å«å¤–éƒ¨çš„å¤©æ°£ API ä¾†ç²å–å³æ™‚çš„å¤©æ°£è³‡è¨Šã€‚îˆ†\n",
        "\n",
        "```python\n",
        "    if city in weather_data:\n",
        "        conditions = weather_data[city]\n",
        "        # Simple simulation based on probabilities\n",
        "        highest_prob = max(conditions, key=conditions.get)\n",
        "        temp_range = {\n",
        "            \"New York\": \"15-25Â°C\",\n",
        "            \"Tokyo\": \"15-25Â°C\",\n",
        "        }\n",
        "        return f\"The weather in {city} on {date} is forecasted to be {highest_prob} with temperatures around {temp_range.get(city, '15-25Â°C')}.\"\n",
        "    else:\n",
        "        return f\"Weather forecast for {city} is not available.\"\n",
        "```\n",
        "\n",
        "- é€™éƒ¨åˆ†ç¨‹å¼ç¢¼é¦–å…ˆæª¢æŸ¥æ‰€æä¾›çš„åŸå¸‚æ˜¯å¦åœ¨ `weather_data` ä¸­ã€‚îˆ†\n",
        "- å¦‚æœå­˜åœ¨ï¼Œå‰‡æ ¹æ“šå¤©æ°£ç‹€æ³çš„æ©Ÿç‡åˆ†ä½ˆï¼Œé¸æ“‡æ©Ÿç‡æœ€é«˜çš„å¤©æ°£ç‹€æ³ä½œç‚ºé å ±çµæœã€‚\n",
        "- ç„¶å¾Œï¼Œå¾ `temp_range` å­—å…¸ä¸­å–å¾—å°æ‡‰åŸå¸‚çš„æº«åº¦ç¯„åœï¼Œä¸¦çµ„åˆæˆä¸€å€‹å®Œæ•´çš„å¤©æ°£é å ±å­—ä¸²è¿”å›ã€‚\n",
        "- å¦‚æœåŸå¸‚ä¸åœ¨ `weather_data` ä¸­ï¼Œå‰‡è¿”å›ä¸€å€‹è¡¨ç¤ºç„¡æ³•æä¾›è©²åŸå¸‚å¤©æ°£é å ±çš„è¨Šæ¯ã€‚\n",
        "\n",
        "é€éé€™æ¨£çš„è¨­è¨ˆï¼Œä»£ç†åœ¨è™•ç†èˆ‡å¤©æ°£ç›¸é—œçš„æŸ¥è©¢æ™‚ï¼Œå¯ä»¥å‘¼å« `get_weather_forecast` å·¥å…·ï¼Œä¸¦æ ¹æ“šä½¿ç”¨è€…æä¾›çš„åŸå¸‚å’Œæ—¥æœŸï¼Œè¿”å›å°æ‡‰çš„å¤©æ°£é å ±è³‡è¨Šã€‚"
      ],
      "metadata": {
        "id": "pgYF9fNFGxs3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### v4_handoffs"
      ],
      "metadata": {
        "id": "wo41FGl-7zJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "pxihh0AO8PjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import json\n",
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "from agents import Agent, Runner, function_tool\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "model = os.getenv('MODEL_CHOICE', 'gpt-4o-mini')\n",
        "\n",
        "# --- Models for structured outputs ---\n",
        "\n",
        "class FlightRecommendation(BaseModel):\n",
        "    airline: str\n",
        "    departure_time: str\n",
        "    arrival_time: str\n",
        "    price: float\n",
        "    direct_flight: bool\n",
        "    recommendation_reason: str\n",
        "\n",
        "class HotelRecommendation(BaseModel):\n",
        "    name: str\n",
        "    location: str\n",
        "    price_per_night: float\n",
        "    amenities: List[str]\n",
        "    recommendation_reason: str\n",
        "\n",
        "class TravelPlan(BaseModel):\n",
        "    destination: str\n",
        "    duration_days: int\n",
        "    budget: float\n",
        "    activities: List[str] = Field(description=\"List of recommended activities\")\n",
        "    notes: str = Field(description=\"Additional notes or recommendations\")\n",
        "\n",
        "# --- Tools ---\n",
        "\n",
        "@function_tool\n",
        "def get_weather_forecast(city: str, date: str) -> str:\n",
        "    \"\"\"Get the weather forecast for a city on a specific date.\"\"\"\n",
        "    # In a real implementation, this would call a weather API\n",
        "    weather_data = {\n",
        "        \"New York\": {\"sunny\": 0.3, \"rainy\": 0.4, \"cloudy\": 0.3},\n",
        "        \"Los Angeles\": {\"sunny\": 0.8, \"rainy\": 0.1, \"cloudy\": 0.1},\n",
        "        \"Chicago\": {\"sunny\": 0.4, \"rainy\": 0.3, \"cloudy\": 0.3},\n",
        "        \"Miami\": {\"sunny\": 0.7, \"rainy\": 0.2, \"cloudy\": 0.1},\n",
        "        \"London\": {\"sunny\": 0.2, \"rainy\": 0.5, \"cloudy\": 0.3},\n",
        "        \"Paris\": {\"sunny\": 0.4, \"rainy\": 0.3, \"cloudy\": 0.3},\n",
        "        \"Tokyo\": {\"sunny\": 0.5, \"rainy\": 0.3, \"cloudy\": 0.2},\n",
        "    }\n",
        "\n",
        "    if city in weather_data:\n",
        "        conditions = weather_data[city]\n",
        "        # Simple simulation based on probabilities\n",
        "        highest_prob = max(conditions, key=conditions.get)\n",
        "        temp_range = {\n",
        "            \"New York\": \"15-25Â°C\",\n",
        "            \"Los Angeles\": \"20-30Â°C\",\n",
        "            \"Chicago\": \"10-20Â°C\",\n",
        "            \"Miami\": \"25-35Â°C\",\n",
        "            \"London\": \"10-18Â°C\",\n",
        "            \"Paris\": \"12-22Â°C\",\n",
        "            \"Tokyo\": \"15-25Â°C\",\n",
        "        }\n",
        "        return f\"The weather in {city} on {date} is forecasted to be {highest_prob} with temperatures around {temp_range.get(city, '15-25Â°C')}.\"\n",
        "    else:\n",
        "        return f\"Weather forecast for {city} is not available.\"\n",
        "\n",
        "@function_tool\n",
        "def search_flights(origin: str, destination: str, date: str) -> str:\n",
        "    \"\"\"Search for flights between two cities on a specific date.\"\"\"\n",
        "    # In a real implementation, this would call a flight search API\n",
        "    flight_options = [\n",
        "        {\n",
        "            \"airline\": \"SkyWays\",\n",
        "            \"departure_time\": \"08:00\",\n",
        "            \"arrival_time\": \"10:30\",\n",
        "            \"price\": 350.00,\n",
        "            \"direct\": True\n",
        "        },\n",
        "        {\n",
        "            \"airline\": \"OceanAir\",\n",
        "            \"departure_time\": \"12:45\",\n",
        "            \"arrival_time\": \"15:15\",\n",
        "            \"price\": 275.50,\n",
        "            \"direct\": True\n",
        "        },\n",
        "        {\n",
        "            \"airline\": \"MountainJet\",\n",
        "            \"departure_time\": \"16:30\",\n",
        "            \"arrival_time\": \"21:45\",\n",
        "            \"price\": 225.75,\n",
        "            \"direct\": False\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    return json.dumps(flight_options)\n",
        "\n",
        "@function_tool\n",
        "def search_hotels(city: str, check_in: str, check_out: str, max_price: Optional[float] = None) -> str:\n",
        "    \"\"\"Search for hotels in a city for specific dates within a price range.\"\"\"\n",
        "    # In a real implementation, this would call a hotel search API\n",
        "    hotel_options = [\n",
        "        {\n",
        "            \"name\": \"City Center Hotel\",\n",
        "            \"location\": \"Downtown\",\n",
        "            \"price_per_night\": 199.99,\n",
        "            \"amenities\": [\"WiFi\", \"Pool\", \"Gym\", \"Restaurant\"]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Riverside Inn\",\n",
        "            \"location\": \"Riverside District\",\n",
        "            \"price_per_night\": 149.50,\n",
        "            \"amenities\": [\"WiFi\", \"Free Breakfast\", \"Parking\"]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Luxury Palace\",\n",
        "            \"location\": \"Historic District\",\n",
        "            \"price_per_night\": 349.99,\n",
        "            \"amenities\": [\"WiFi\", \"Pool\", \"Spa\", \"Fine Dining\", \"Concierge\"]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Filter by max price if provided\n",
        "    if max_price is not None:\n",
        "        filtered_hotels = [hotel for hotel in hotel_options if hotel[\"price_per_night\"] <= max_price]\n",
        "    else:\n",
        "        filtered_hotels = hotel_options\n",
        "\n",
        "    return json.dumps(filtered_hotels)\n",
        "\n",
        "# --- Specialized Agents ---\n",
        "\n",
        "flight_agent = Agent(\n",
        "    name=\"Flight Specialist\",\n",
        "    handoff_description=\"Specialist agent for finding and recommending flights\",\n",
        "    instructions=\"\"\"\n",
        "    You are a flight specialist who helps users find the best flights for their trips.\n",
        "\n",
        "    Use the search_flights tool to find flight options, and then provide personalized recommendations\n",
        "    based on the user's preferences (price, time, direct vs. connecting).\n",
        "\n",
        "    Always explain the reasoning behind your recommendations.\n",
        "\n",
        "    Format your response in a clear, organized way with flight details and prices.\n",
        "    \"\"\",\n",
        "    model=model,\n",
        "    tools=[search_flights],\n",
        "    output_type=FlightRecommendation\n",
        ")\n",
        "\n",
        "hotel_agent = Agent(\n",
        "    name=\"Hotel Specialist\",\n",
        "    handoff_description=\"Specialist agent for finding and recommending hotels and accommodations\",\n",
        "    instructions=\"\"\"\n",
        "    You are a hotel specialist who helps users find the best accommodations for their trips.\n",
        "\n",
        "    Use the search_hotels tool to find hotel options, and then provide personalized recommendations\n",
        "    based on the user's preferences (location, price, amenities).\n",
        "\n",
        "    Always explain the reasoning behind your recommendations.\n",
        "\n",
        "    Format your response in a clear, organized way with hotel details, amenities, and prices.\n",
        "    \"\"\",\n",
        "    model=model,\n",
        "    tools=[search_hotels],\n",
        "    output_type=HotelRecommendation\n",
        ")\n",
        "\n",
        "# --- Main Travel Agent ---\n",
        "\n",
        "travel_agent = Agent(\n",
        "    name=\"Travel Planner\",\n",
        "    instructions=\"\"\"\n",
        "    You are a comprehensive travel planning assistant that helps users plan their perfect trip.\n",
        "\n",
        "    You can:\n",
        "    1. Provide weather information for destinations\n",
        "    2. Create personalized travel itineraries\n",
        "    3. Hand off to specialists for flights and hotels when needed\n",
        "\n",
        "    Always be helpful, informative, and enthusiastic about travel. Provide specific recommendations\n",
        "    based on the user's interests and preferences.\n",
        "\n",
        "    When creating travel plans, consider:\n",
        "    - The weather at the destination\n",
        "    - Local attractions and activities\n",
        "    - Budget constraints\n",
        "    - Travel duration\n",
        "\n",
        "    If the user asks specifically about flights or hotels, hand off to the appropriate specialist agent.\n",
        "    \"\"\",\n",
        "    model=model,\n",
        "    tools=[get_weather_forecast],\n",
        "    handoffs=[flight_agent, hotel_agent],\n",
        "    output_type=TravelPlan\n",
        ")\n",
        "\n",
        "# --- Main Function ---\n",
        "\n",
        "async def main():\n",
        "    # Example queries to test different aspects of the system\n",
        "    queries = [\n",
        "        \"I need a flight from New York to Chicago tomorrow\",\n",
        "        \"Find me a hotel in Paris with a pool for under $300 per night\"\n",
        "    ]\n",
        "\n",
        "    for query in queries:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"QUERY: {query}\")\n",
        "\n",
        "        result = await Runner.run(travel_agent, query)\n",
        "\n",
        "        print(\"\\nFINAL RESPONSE:\")\n",
        "\n",
        "        # Format the output based on the type of response\n",
        "        if hasattr(result.final_output, \"airline\"):  # Flight recommendation\n",
        "            flight = result.final_output\n",
        "            print(\"\\nâœˆï¸ FLIGHT RECOMMENDATION âœˆï¸\")\n",
        "            print(f\"Airline: {flight.airline}\")\n",
        "            print(f\"Departure: {flight.departure_time}\")\n",
        "            print(f\"Arrival: {flight.arrival_time}\")\n",
        "            print(f\"Price: ${flight.price}\")\n",
        "            print(f\"Direct Flight: {'Yes' if flight.direct_flight else 'No'}\")\n",
        "            print(f\"\\nWhy this flight: {flight.recommendation_reason}\")\n",
        "\n",
        "        elif hasattr(result.final_output, \"name\") and hasattr(result.final_output, \"amenities\"):  # Hotel recommendation\n",
        "            hotel = result.final_output\n",
        "            print(\"\\nğŸ¨ HOTEL RECOMMENDATION ğŸ¨\")\n",
        "            print(f\"Name: {hotel.name}\")\n",
        "            print(f\"Location: {hotel.location}\")\n",
        "            print(f\"Price per night: ${hotel.price_per_night}\")\n",
        "\n",
        "            print(\"\\nAmenities:\")\n",
        "            for i, amenity in enumerate(hotel.amenities, 1):\n",
        "                print(f\"  {i}. {amenity}\")\n",
        "\n",
        "            print(f\"\\nWhy this hotel: {hotel.recommendation_reason}\")\n",
        "\n",
        "        elif hasattr(result.final_output, \"destination\"):  # Travel plan\n",
        "            travel_plan = result.final_output\n",
        "            print(f\"\\nğŸŒ TRAVEL PLAN FOR {travel_plan.destination.upper()} ğŸŒ\")\n",
        "            print(f\"Duration: {travel_plan.duration_days} days\")\n",
        "            print(f\"Budget: ${travel_plan.budget}\")\n",
        "\n",
        "            print(\"\\nğŸ¯ RECOMMENDED ACTIVITIES:\")\n",
        "            for i, activity in enumerate(travel_plan.activities, 1):\n",
        "                print(f\"  {i}. {activity}\")\n",
        "\n",
        "            print(f\"\\nğŸ“ NOTES: {travel_plan.notes}\")\n",
        "\n",
        "        else:  # Generic response\n",
        "            print(result.final_output)\n",
        "\n",
        "'''\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n",
        "'''\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "id": "vwjSyqvS74hA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f593c33-d386-4f3d-d4d4-13ae885d192d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "QUERY: I need a flight from New York to Chicago tomorrow\n",
            "\n",
            "FINAL RESPONSE:\n",
            "\n",
            "âœˆï¸ FLIGHT RECOMMENDATION âœˆï¸\n",
            "Airline: OceanAir\n",
            "Departure: 12:45\n",
            "Arrival: 15:15\n",
            "Price: $275.5\n",
            "Direct Flight: Yes\n",
            "\n",
            "Why this flight: This flight is the most affordable direct option, with a reasonable departure time and a convenient arrival time.\n",
            "\n",
            "==================================================\n",
            "QUERY: Find me a hotel in Paris with a pool for under $300 per night\n",
            "\n",
            "FINAL RESPONSE:\n",
            "\n",
            "ğŸ¨ HOTEL RECOMMENDATION ğŸ¨\n",
            "Name: City Center Hotel\n",
            "Location: Downtown\n",
            "Price per night: $199.99\n",
            "\n",
            "Amenities:\n",
            "  1. WiFi\n",
            "  2. Pool\n",
            "  3. Gym\n",
            "  4. Restaurant\n",
            "\n",
            "Why this hotel: The City Center Hotel is a great option as it offers a pool and is centrally located, making it easy to explore Paris. Priced at $199.99 per night, it fits well within your budget while also providing additional amenities such as a gym and restaurant.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Handoff\n",
        "\n",
        "```python\n",
        "\n",
        "travel_agent = Agent(\n",
        "    name=\"Travel Planner\",\n",
        "    instructions=\"\"\"\n",
        "    You are a comprehensive travel planning assistant that helps users plan their perfect trip.\n",
        "\n",
        "    You can:\n",
        "\n",
        "    3. Hand off to specialists for flights and hotels when needed\n",
        "    \"\"\",\n",
        "\n",
        "    model=model,\n",
        "    tools=[get_weather_forecast],\n",
        "    handoffs=[flight_agent, hotel_agent],\n",
        "    output_type=TravelPlan\n",
        ")\n",
        "```\n",
        "\n",
        "åœ¨ Agent instruction è£æåˆ°é€™å€‹èƒ½åŠ›ï¼Œä»¥åŠåœ¨  `handoffs=[flight_agent, hotel_agent]`"
      ],
      "metadata": {
        "id": "fuf90HBPKwH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### v5_guardrails_and_context"
      ],
      "metadata": {
        "id": "ufCySx-V8Sin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "hYhc3CUrQ6jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q logfire"
      ],
      "metadata": {
        "id": "MGNAoF3AT6Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import json\n",
        "from datetime import datetime\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "from agents import Agent, RunContextWrapper, Runner, function_tool, ModelSettings, InputGuardrail, GuardrailFunctionOutput, InputGuardrailTripwireTriggered\n",
        "from dotenv import load_dotenv\n",
        "import logfire\n",
        "import os\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Comment these lines out if you don't want Logfire tracing\n",
        "from google.colab import userdata\n",
        "LOGFIRE_TOKEN = userdata.get('LOGFIRE_TOKEN')\n",
        "\n",
        "logfire.configure(token=LOGFIRE_TOKEN)\n",
        "\n",
        "logfire.instrument_openai_agents()\n",
        "\n",
        "model = os.getenv('MODEL_CHOICE', 'gpt-4o-mini')\n",
        "\n",
        "# --- Models for structured outputs ---\n",
        "\n",
        "class FlightRecommendation(BaseModel):\n",
        "    airline: str\n",
        "    departure_time: str\n",
        "    arrival_time: str\n",
        "    price: float\n",
        "    direct_flight: bool\n",
        "    recommendation_reason: str\n",
        "\n",
        "class HotelRecommendation(BaseModel):\n",
        "    name: str\n",
        "    location: str\n",
        "    price_per_night: float\n",
        "    amenities: List[str]\n",
        "    recommendation_reason: str\n",
        "\n",
        "class TravelPlan(BaseModel):\n",
        "    destination: str\n",
        "    duration_days: int\n",
        "    budget: float\n",
        "    activities: List[str] = Field(description=\"List of recommended activities\")\n",
        "    notes: str = Field(description=\"Additional notes or recommendations\")\n",
        "\n",
        "class BudgetAnalysis(BaseModel):\n",
        "    is_realistic: bool\n",
        "    reasoning: str\n",
        "    suggested_budget: Optional[float] = None\n",
        "\n",
        "# --- Context Class ---\n",
        "\n",
        "@dataclass\n",
        "class UserContext:\n",
        "    user_id: str\n",
        "    preferred_airlines: List[str] = None\n",
        "    hotel_amenities: List[str] = None\n",
        "    budget_level: str = None\n",
        "    session_start: datetime = None\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.preferred_airlines is None:\n",
        "            self.preferred_airlines = []\n",
        "        if self.hotel_amenities is None:\n",
        "            self.hotel_amenities = []\n",
        "        if self.session_start is None:\n",
        "            self.session_start = datetime.now()\n",
        "\n",
        "# --- Tools ---\n",
        "\n",
        "@function_tool\n",
        "def get_weather_forecast(city: str, date: str) -> str:\n",
        "    \"\"\"Get the weather forecast for a city on a specific date.\"\"\"\n",
        "    # In a real implementation, this would call a weather API\n",
        "    weather_data = {\n",
        "        \"New York\": {\"sunny\": 0.3, \"rainy\": 0.4, \"cloudy\": 0.3},\n",
        "        \"Los Angeles\": {\"sunny\": 0.8, \"rainy\": 0.1, \"cloudy\": 0.1},\n",
        "        \"Chicago\": {\"sunny\": 0.4, \"rainy\": 0.3, \"cloudy\": 0.3},\n",
        "        \"Miami\": {\"sunny\": 0.7, \"rainy\": 0.2, \"cloudy\": 0.1},\n",
        "        \"London\": {\"sunny\": 0.2, \"rainy\": 0.5, \"cloudy\": 0.3},\n",
        "        \"Paris\": {\"sunny\": 0.4, \"rainy\": 0.3, \"cloudy\": 0.3},\n",
        "        \"Tokyo\": {\"sunny\": 0.5, \"rainy\": 0.3, \"cloudy\": 0.2},\n",
        "    }\n",
        "\n",
        "    if city in weather_data:\n",
        "        conditions = weather_data[city]\n",
        "        # Simple simulation based on probabilities\n",
        "        highest_prob = max(conditions, key=conditions.get)\n",
        "        temp_range = {\n",
        "            \"New York\": \"15-25Â°C\",\n",
        "            \"Los Angeles\": \"20-30Â°C\",\n",
        "            \"Chicago\": \"10-20Â°C\",\n",
        "            \"Miami\": \"25-35Â°C\",\n",
        "            \"London\": \"10-18Â°C\",\n",
        "            \"Paris\": \"12-22Â°C\",\n",
        "            \"Tokyo\": \"15-25Â°C\",\n",
        "        }\n",
        "        return f\"The weather in {city} on {date} is forecasted to be {highest_prob} with temperatures around {temp_range.get(city, '15-25Â°C')}.\"\n",
        "    else:\n",
        "        return f\"Weather forecast for {city} is not available.\"\n",
        "\n",
        "@function_tool\n",
        "async def search_flights(wrapper: RunContextWrapper[UserContext], origin: str, destination: str, date: str) -> str:\n",
        "    \"\"\"Search for flights between two cities on a specific date, taking user preferences into account.\"\"\"\n",
        "    # In a real implementation, this would call a flight search API\n",
        "    flight_options = [\n",
        "        {\n",
        "            \"airline\": \"SkyWays\",\n",
        "            \"departure_time\": \"08:00\",\n",
        "            \"arrival_time\": \"10:30\",\n",
        "            \"price\": 350.00,\n",
        "            \"direct\": True\n",
        "        },\n",
        "        {\n",
        "            \"airline\": \"OceanAir\",\n",
        "            \"departure_time\": \"12:45\",\n",
        "            \"arrival_time\": \"15:15\",\n",
        "            \"price\": 275.50,\n",
        "            \"direct\": True\n",
        "        },\n",
        "        {\n",
        "            \"airline\": \"MountainJet\",\n",
        "            \"departure_time\": \"16:30\",\n",
        "            \"arrival_time\": \"21:45\",\n",
        "            \"price\": 225.75,\n",
        "            \"direct\": False\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Apply user preferences if available\n",
        "    if wrapper and wrapper.context:\n",
        "        preferred_airlines = wrapper.context.preferred_airlines\n",
        "        if preferred_airlines:\n",
        "            # Move preferred airlines to the top of the list\n",
        "            flight_options.sort(key=lambda x: x[\"airline\"] not in preferred_airlines)\n",
        "\n",
        "            # Add a note about preference matching\n",
        "            for flight in flight_options:\n",
        "                if flight[\"airline\"] in preferred_airlines:\n",
        "                    flight[\"preferred\"] = True\n",
        "\n",
        "    return json.dumps(flight_options)\n",
        "\n",
        "@function_tool\n",
        "async def search_hotels(wrapper: RunContextWrapper[UserContext], city: str, check_in: str, check_out: str, max_price: Optional[float] = None) -> str:\n",
        "    \"\"\"Search for hotels in a city for specific dates within a price range, taking user preferences into account.\"\"\"\n",
        "    # In a real implementation, this would call a hotel search API\n",
        "    hotel_options = [\n",
        "        {\n",
        "            \"name\": \"City Center Hotel\",\n",
        "            \"location\": \"Downtown\",\n",
        "            \"price_per_night\": 199.99,\n",
        "            \"amenities\": [\"WiFi\", \"Pool\", \"Gym\", \"Restaurant\"]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Riverside Inn\",\n",
        "            \"location\": \"Riverside District\",\n",
        "            \"price_per_night\": 149.50,\n",
        "            \"amenities\": [\"WiFi\", \"Free Breakfast\", \"Parking\"]\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Luxury Palace\",\n",
        "            \"location\": \"Historic District\",\n",
        "            \"price_per_night\": 349.99,\n",
        "            \"amenities\": [\"WiFi\", \"Pool\", \"Spa\", \"Fine Dining\", \"Concierge\"]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Filter by max price if provided\n",
        "    if max_price is not None:\n",
        "        filtered_hotels = [hotel for hotel in hotel_options if hotel[\"price_per_night\"] <= max_price]\n",
        "    else:\n",
        "        filtered_hotels = hotel_options\n",
        "\n",
        "    # Apply user preferences if available\n",
        "    if wrapper and wrapper.context:\n",
        "        preferred_amenities = wrapper.context.hotel_amenities\n",
        "        budget_level = wrapper.context.budget_level\n",
        "\n",
        "        # Sort hotels by preference match\n",
        "        if preferred_amenities:\n",
        "            # Calculate a score based on how many preferred amenities each hotel has\n",
        "            for hotel in filtered_hotels:\n",
        "                matching_amenities = [a for a in hotel[\"amenities\"] if a in preferred_amenities]\n",
        "                hotel[\"matching_amenities\"] = matching_amenities\n",
        "                hotel[\"preference_score\"] = len(matching_amenities)\n",
        "\n",
        "            # Sort by preference score (higher scores first)\n",
        "            filtered_hotels.sort(key=lambda x: x[\"preference_score\"], reverse=True)\n",
        "\n",
        "        # Apply budget level preferences if available\n",
        "        if budget_level:\n",
        "            if budget_level == \"budget\":\n",
        "                filtered_hotels.sort(key=lambda x: x[\"price_per_night\"])\n",
        "            elif budget_level == \"luxury\":\n",
        "                filtered_hotels.sort(key=lambda x: x[\"price_per_night\"], reverse=True)\n",
        "            # mid-range is already handled by the max_price filter\n",
        "\n",
        "    return json.dumps(filtered_hotels)\n",
        "\n",
        "# --- Guardrails ---\n",
        "\n",
        "budget_analysis_agent = Agent(\n",
        "    name=\"Budget Analyzer\",\n",
        "    instructions=\"\"\"\n",
        "    You analyze travel budgets to determine if they are realistic for the destination and duration.\n",
        "    Consider factors like:\n",
        "    - Average hotel costs in the destination\n",
        "    - Flight costs\n",
        "    - Food and entertainment expenses\n",
        "    - Local transportation\n",
        "\n",
        "    Provide a clear analysis of whether the budget is realistic and why.\n",
        "    If the budget is not realistic, suggest a more appropriate budget.\n",
        "    Don't be harsh at all, lean towards it being realistic unless it's really crazy.\n",
        "    If no budget was mentioned, just assume it is realistic.\n",
        "    \"\"\",\n",
        "    output_type=BudgetAnalysis,\n",
        "    model=model\n",
        ")\n",
        "\n",
        "async def budget_guardrail(ctx, agent, input_data):\n",
        "    \"\"\"Check if the user's travel budget is realistic.\"\"\"\n",
        "    # Parse the input to extract destination, duration, and budget\n",
        "    try:\n",
        "        analysis_prompt = f\"The user is planning a trip and said: {input_data}.\\nAnalyze if their budget is realistic for a trip to their destination for the length they mentioned.\"\n",
        "        result = await Runner.run(budget_analysis_agent, analysis_prompt, context=ctx.context)\n",
        "        final_output = result.final_output_as(BudgetAnalysis)\n",
        "\n",
        "        if not final_output.is_realistic:\n",
        "            print(f\"Your budget for your trip may not be realistic. {final_output.reasoning}\" if not final_output.is_realistic else None)\n",
        "\n",
        "        return GuardrailFunctionOutput(\n",
        "            output_info=final_output,\n",
        "            tripwire_triggered=not final_output.is_realistic,\n",
        "        )\n",
        "    except Exception as e:\n",
        "        # Handle any errors gracefully\n",
        "        return GuardrailFunctionOutput(\n",
        "            output_info=BudgetAnalysis(is_realistic=True, reasoning=f\"Error analyzing budget: {str(e)}\"),\n",
        "            tripwire_triggered=False\n",
        "        )\n",
        "\n",
        "# --- Specialized Agents ---\n",
        "\n",
        "flight_agent = Agent[UserContext](\n",
        "    name=\"Flight Specialist\",\n",
        "    handoff_description=\"Specialist agent for finding and recommending flights\",\n",
        "    instructions=\"\"\"\n",
        "    You are a flight specialist who helps users find the best flights for their trips.\n",
        "\n",
        "    Use the search_flights tool to find flight options, and then provide personalized recommendations\n",
        "    based on the user's preferences (price, time, direct vs. connecting).\n",
        "\n",
        "    The user's preferences are available in the context, including preferred airlines.\n",
        "\n",
        "    Always explain the reasoning behind your recommendations.\n",
        "\n",
        "    Format your response in a clear, organized way with flight details and prices.\n",
        "    \"\"\",\n",
        "    model=model,\n",
        "    tools=[search_flights],\n",
        "    output_type=FlightRecommendation\n",
        ")\n",
        "\n",
        "hotel_agent = Agent[UserContext](\n",
        "    name=\"Hotel Specialist\",\n",
        "    handoff_description=\"Specialist agent for finding and recommending hotels and accommodations\",\n",
        "    instructions=\"\"\"\n",
        "    You are a hotel specialist who helps users find the best accommodations for their trips.\n",
        "\n",
        "    Use the search_hotels tool to find hotel options, and then provide personalized recommendations\n",
        "    based on the user's preferences (location, amenities, price range).\n",
        "\n",
        "    The user's preferences are available in the context, including preferred amenities and budget level.\n",
        "\n",
        "    Always explain the reasoning behind your recommendations.\n",
        "\n",
        "    Format your response in a clear, organized way with hotel details, amenities, and prices.\n",
        "    \"\"\",\n",
        "    model=model,\n",
        "    tools=[search_hotels],\n",
        "    output_type=HotelRecommendation\n",
        ")\n",
        "\n",
        "conversational_agent = Agent[UserContext](\n",
        "    name=\"General Conversation Specialist\",\n",
        "    handoff_description=\"Specialist agent for giving basic responses to the user to carry out a normal conversation as opposed to structured output.\",\n",
        "    instructions=\"\"\"\n",
        "    You are a trip planning expert who answers basic user questions about their trip and offers any suggestions.\n",
        "    Act as a helpful assistant and be helpful in any way you can be.\n",
        "    \"\"\",\n",
        "    model=model\n",
        ")\n",
        "\n",
        "# --- Main Travel Agent ---\n",
        "\n",
        "travel_agent = Agent[UserContext](\n",
        "    name=\"Travel Planner\",\n",
        "    instructions=\"\"\"\n",
        "    You are a travel planning assistant who helps users plan their trips.\n",
        "\n",
        "    You can provide personalized travel recommendations based on the user's destination, duration, budget, and preferences.\n",
        "\n",
        "    The user's preferences are available in the context, which you can use to tailor your recommendations.\n",
        "\n",
        "    You can:\n",
        "    1. Get weather forecasts for destinations\n",
        "    2. Hand off to specialized agents for flight and hotel recommendations\n",
        "    3. Create comprehensive travel plans with activities and notes\n",
        "\n",
        "    Always be helpful, informative, and enthusiastic about travel.\n",
        "    \"\"\",\n",
        "    model=model,\n",
        "    tools=[get_weather_forecast],\n",
        "    handoffs=[flight_agent, hotel_agent, conversational_agent],\n",
        "    input_guardrails=[\n",
        "        InputGuardrail(guardrail_function=budget_guardrail),\n",
        "    ],\n",
        "    output_type=TravelPlan\n",
        ")\n",
        "\n",
        "# --- Main Function ---\n",
        "\n",
        "async def main():\n",
        "    # Create a user context with some preferences\n",
        "    user_context = UserContext(\n",
        "        user_id=\"user123\",\n",
        "        preferred_airlines=[\"SkyWays\", \"OceanAir\"],\n",
        "        hotel_amenities=[\"WiFi\", \"Pool\"],\n",
        "        budget_level=\"mid-range\"\n",
        "    )\n",
        "\n",
        "    # Example queries to test different aspects of the system\n",
        "    queries = [\n",
        "        \"I'm planning a trip to Miami for 5 days with a budget of $2000. What should I do there?\",\n",
        "        \"I'm planning a trip to Tokyo for a week, looking to spend under $5,000. Suggestions?\",\n",
        "        \"I need a flight from New York to Chicago tomorrow\",\n",
        "        \"Find me a hotel in Paris with a pool for under $400 per night\",\n",
        "        \"I want to go to Dubai for a week with only $300\"  # This should trigger the budget guardrail\n",
        "    ]\n",
        "\n",
        "    for query in queries:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"QUERY: {query}\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        try:\n",
        "            result = await Runner.run(travel_agent, query, context=user_context)\n",
        "\n",
        "            print(\"\\nFINAL RESPONSE:\")\n",
        "\n",
        "            # Format the output based on the type of response\n",
        "            if hasattr(result.final_output, \"airline\"):  # Flight recommendation\n",
        "                flight = result.final_output\n",
        "                print(\"\\nâœˆï¸ FLIGHT RECOMMENDATION âœˆï¸\")\n",
        "                print(f\"Airline: {flight.airline}\")\n",
        "                print(f\"Departure: {flight.departure_time}\")\n",
        "                print(f\"Arrival: {flight.arrival_time}\")\n",
        "                print(f\"Price: ${flight.price}\")\n",
        "                print(f\"Direct Flight: {'Yes' if flight.direct_flight else 'No'}\")\n",
        "                print(f\"\\nWhy this flight: {flight.recommendation_reason}\")\n",
        "\n",
        "                # Show user preferences that influenced this recommendation\n",
        "                airlines = user_context.preferred_airlines\n",
        "                if airlines and flight.airline in airlines:\n",
        "                    print(f\"\\nğŸ‘¤ NOTE: This matches your preferred airline: {flight.airline}\")\n",
        "\n",
        "            elif hasattr(result.final_output, \"name\") and hasattr(result.final_output, \"amenities\"):  # Hotel recommendation\n",
        "                hotel = result.final_output\n",
        "                print(\"\\nğŸ¨ HOTEL RECOMMENDATION ğŸ¨\")\n",
        "                print(f\"Name: {hotel.name}\")\n",
        "                print(f\"Location: {hotel.location}\")\n",
        "                print(f\"Price per night: ${hotel.price_per_night}\")\n",
        "\n",
        "                print(\"\\nAmenities:\")\n",
        "                for i, amenity in enumerate(hotel.amenities, 1):\n",
        "                    print(f\"  {i}. {amenity}\")\n",
        "\n",
        "                # Highlight matching amenities from user preferences\n",
        "                preferred_amenities = user_context.hotel_amenities\n",
        "                if preferred_amenities:\n",
        "                    matching = [a for a in hotel.amenities if a in preferred_amenities]\n",
        "                    if matching:\n",
        "                        print(\"\\nğŸ‘¤ MATCHING PREFERRED AMENITIES:\")\n",
        "                        for amenity in matching:\n",
        "                            print(f\"  âœ“ {amenity}\")\n",
        "\n",
        "                print(f\"\\nWhy this hotel: {hotel.recommendation_reason}\")\n",
        "\n",
        "            elif hasattr(result.final_output, \"destination\"):  # Travel plan\n",
        "                travel_plan = result.final_output\n",
        "                print(f\"\\nğŸŒ TRAVEL PLAN FOR {travel_plan.destination.upper()} ğŸŒ\")\n",
        "                print(f\"Duration: {travel_plan.duration_days} days\")\n",
        "                print(f\"Budget: ${travel_plan.budget}\")\n",
        "\n",
        "                # Show budget level context\n",
        "                budget_level = user_context.budget_level\n",
        "                if budget_level:\n",
        "                    print(f\"Budget Category: {budget_level.title()}\")\n",
        "\n",
        "                print(\"\\nğŸ¯ RECOMMENDED ACTIVITIES:\")\n",
        "                for i, activity in enumerate(travel_plan.activities, 1):\n",
        "                    print(f\"  {i}. {activity}\")\n",
        "\n",
        "                print(f\"\\nğŸ“ NOTES: {travel_plan.notes}\")\n",
        "\n",
        "            else:  # Generic response\n",
        "                print(result.final_output)\n",
        "\n",
        "        except InputGuardrailTripwireTriggered as e:\n",
        "            print(\"\\nâš ï¸ GUARDRAIL TRIGGERED âš ï¸\")\n",
        "\n",
        "'''\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n",
        "'''\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "id": "WBuj3oOv8X3A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7ad8127-7162-4f2d-8b5e-57ae609198e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19:32:24.049 Hello, World!\n",
            "\n",
            "==================================================\n",
            "QUERY: I'm planning a trip to Miami for 5 days with a budget of $2000. What should I do there?\n",
            "==================================================\n",
            "19:32:24.090 OpenAI Agents trace: Agent workflow\n",
            "19:32:24.095   Agent run: 'Travel Planner'\n",
            "19:32:24.097     Guardrail 'budget_guardrail' triggered=False\n",
            "19:32:24.099       Agent run: 'Budget Analyzer'\n",
            "19:32:24.104     Responses API with 'gpt-4o-mini'\n",
            "                 Guardrail 'budget_guardrail' triggered=False\n",
            "                   Agent run: 'Budget Analyzer'\n",
            "19:32:24.117         Responses API with 'gpt-4o-mini'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mLogfire\u001b[0m project URL: \u001b]8;id=338635;https://logfire-us.pydantic.dev/ssupinma/starter-project\u001b\\\u001b[4;36mhttps://logfire-us.pydantic.dev/ssupinma/starter-project\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Logfire</span> project URL: <a href=\"https://logfire-us.pydantic.dev/ssupinma/starter-project\" target=\"_blank\"><span style=\"color: #008080; text-decoration-color: #008080; text-decoration: underline\">https://logfire-us.pydantic.dev/ssupinma/starter-project</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FINAL RESPONSE:\n",
            "\n",
            "ğŸŒ TRAVEL PLAN FOR MIAMI ğŸŒ\n",
            "Duration: 5 days\n",
            "Budget: $2000.0\n",
            "Budget Category: Mid-Range\n",
            "\n",
            "ğŸ¯ RECOMMENDED ACTIVITIES:\n",
            "  1. Visit South Beach for sunbathing and swimming\n",
            "  2. Explore the Art Deco Historic District\n",
            "  3. Take a boat tour of Biscayne Bay\n",
            "  4. Visit Little Havana for Cuban culture and food\n",
            "  5. Spend a day at the Vizcaya Museum and Gardens\n",
            "  6. Enjoy nightlife in Wynwood and Brickell\n",
            "  7. Relax at Key Biscayne Beach\n",
            "  8. Discover the shops and restaurants at Lincoln Road Mall\n",
            "\n",
            "ğŸ“ NOTES: Consider renting a bike or scooter to explore the city easily. Book tours in advance for popular attractions. Check local events or festivals happening during your stay for additional entertainment options.\n",
            "\n",
            "==================================================\n",
            "QUERY: I'm planning a trip to Tokyo for a week, looking to spend under $5,000. Suggestions?\n",
            "==================================================\n",
            "19:32:31.224 OpenAI Agents trace: Agent workflow\n",
            "19:32:31.226   Agent run: 'Travel Planner'\n",
            "19:32:31.227     Guardrail 'budget_guardrail' triggered=False\n",
            "19:32:31.228       Agent run: 'Budget Analyzer'\n",
            "19:32:31.231     Responses API with 'gpt-4o-mini'\n",
            "                 Guardrail 'budget_guardrail' triggered=False\n",
            "                   Agent run: 'Budget Analyzer'\n",
            "19:32:31.242         Responses API with 'gpt-4o-mini'\n",
            "\n",
            "FINAL RESPONSE:\n",
            "\n",
            "ğŸŒ TRAVEL PLAN FOR TOKYO ğŸŒ\n",
            "Duration: 7 days\n",
            "Budget: $5000.0\n",
            "Budget Category: Mid-Range\n",
            "\n",
            "ğŸ¯ RECOMMENDED ACTIVITIES:\n",
            "  1. Visit the iconic Shibuya Crossing\n",
            "  2. Explore the historic Asakusa district and Senso-ji Temple\n",
            "  3. Shop in Harajuku and Omotesando\n",
            "  4. Experience the nightlife in Shinjuku\n",
            "  5. Visit Akihabara for electronic and anime culture\n",
            "  6. Take a day trip to Mount Fuji\n",
            "  7. Explore the Tokyo Skytree for panoramic views\n",
            "  8. Enjoy a traditional tea ceremony\n",
            "\n",
            "ğŸ“ NOTES: Consider purchasing a Japan Rail Pass for convenient travel across the city and beyond. Be mindful of peak tourist seasons to secure better deals on flights and accommodations.\n",
            "\n",
            "==================================================\n",
            "QUERY: I need a flight from New York to Chicago tomorrow\n",
            "==================================================\n",
            "19:32:34.486 OpenAI Agents trace: Agent workflow\n",
            "19:32:34.488   Agent run: 'Travel Planner'\n",
            "19:32:34.489     Guardrail 'budget_guardrail' triggered=False\n",
            "19:32:34.490       Agent run: 'Budget Analyzer'\n",
            "19:32:34.492     Responses API with 'gpt-4o-mini'\n",
            "                 Guardrail 'budget_guardrail' triggered=False\n",
            "                   Agent run: 'Budget Analyzer'\n",
            "19:32:34.501         Responses API with 'gpt-4o-mini'\n",
            "19:32:35.257     Handoff: Travel Planner â†’ None\n",
            "19:32:37.094   Agent run: 'Flight Specialist'\n",
            "19:32:37.096     Responses API with 'gpt-4o-mini'\n",
            "19:32:38.384     Function: search_flights\n",
            "19:32:38.386     Responses API with 'gpt-4o-mini'\n",
            "\n",
            "FINAL RESPONSE:\n",
            "\n",
            "âœˆï¸ FLIGHT RECOMMENDATION âœˆï¸\n",
            "Airline: OceanAir\n",
            "Departure: 12:45\n",
            "Arrival: 15:15\n",
            "Price: $275.5\n",
            "Direct Flight: Yes\n",
            "\n",
            "Why this flight: OceanAir offers the best balance of price and direct timing for your flight from New York to Chicago.\n",
            "\n",
            "ğŸ‘¤ NOTE: This matches your preferred airline: OceanAir\n",
            "\n",
            "==================================================\n",
            "QUERY: Find me a hotel in Paris with a pool for under $400 per night\n",
            "==================================================\n",
            "19:32:40.376 OpenAI Agents trace: Agent workflow\n",
            "19:32:40.378   Agent run: 'Travel Planner'\n",
            "19:32:40.379     Guardrail 'budget_guardrail' triggered=False\n",
            "19:32:40.380       Agent run: 'Budget Analyzer'\n",
            "19:32:40.382     Responses API with 'gpt-4o-mini'\n",
            "                 Guardrail 'budget_guardrail' triggered=False\n",
            "                   Agent run: 'Budget Analyzer'\n",
            "19:32:40.391         Responses API with 'gpt-4o-mini'\n",
            "19:32:41.183     Handoff: Travel Planner â†’ None\n",
            "19:32:43.777   Agent run: 'Hotel Specialist'\n",
            "19:32:43.779     Responses API with 'gpt-4o-mini'\n",
            "19:32:45.445     Function: search_hotels\n",
            "19:32:45.448     Responses API with 'gpt-4o-mini'\n",
            "\n",
            "FINAL RESPONSE:\n",
            "\n",
            "ğŸ¨ HOTEL RECOMMENDATION ğŸ¨\n",
            "Name: City Center Hotel\n",
            "Location: Downtown\n",
            "Price per night: $199.99\n",
            "\n",
            "Amenities:\n",
            "  1. WiFi\n",
            "  2. Pool\n",
            "  3. Gym\n",
            "  4. Restaurant\n",
            "\n",
            "ğŸ‘¤ MATCHING PREFERRED AMENITIES:\n",
            "  âœ“ WiFi\n",
            "  âœ“ Pool\n",
            "\n",
            "Why this hotel: Located in the heart of downtown Paris, this hotel features a pool and is well within your budget, offering great amenities for a comfortable stay.\n",
            "\n",
            "==================================================\n",
            "QUERY: I want to go to Dubai for a week with only $300\n",
            "==================================================\n",
            "19:32:47.802 OpenAI Agents trace: Agent workflow\n",
            "19:32:47.803   Agent run: 'Travel Planner'\n",
            "19:32:47.804     Guardrail 'budget_guardrail' triggered=False\n",
            "19:32:47.806       Agent run: 'Budget Analyzer'\n",
            "19:32:47.807     Responses API with 'gpt-4o-mini'\n",
            "                 Guardrail 'budget_guardrail' triggered=False\n",
            "                   Agent run: 'Budget Analyzer'\n",
            "19:32:47.817         Responses API with 'gpt-4o-mini'\n",
            "Your budget for your trip may not be realistic. Dubai is known for its luxury and high cost of living. The average cost for hotels can range from $50 to over $300 per night. For a week, even at the lower end, that totals about $350, which already exceeds the user's entire budget. Additionally, flights to Dubai, depending on the departure location, can be substantial, often starting around $500 to $700. Food and entertainment costs can also add up quickly, with meals often starting at $15 to $30 per person in a restaurant. Local transportation such as taxis or rideshares is another expense that would need to be considered. Overall, a budget of $300 is insufficient for a one-week trip to Dubai.\n",
            "\n",
            "âš ï¸ GUARDRAIL TRIGGERED âš ï¸\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### guardrail\n",
        "\n",
        "`budget_guardrail` æ˜¯ä¸€å€‹ã€Œè¼¸å…¥é˜²è­·æ¬„ã€ï¼ˆInput Guardrailï¼‰å‡½å¼ï¼Œå°ˆé–€ç”¨ä¾†æª¢æŸ¥ä½¿ç”¨è€…è¼¸å…¥çš„æ—…éŠé ç®—æ˜¯å¦åˆç†ã€‚é€™å€‹é˜²è­·æ¬„çš„è¨­è¨ˆç›®çš„æ˜¯åœ¨ä¸»ä»£ç†ï¼ˆ`travel_agent`ï¼‰è™•ç†ä½¿ç”¨è€…è«‹æ±‚ä¹‹å‰ï¼Œå…ˆé€²è¡Œé ç®—åˆç†æ€§çš„é©—è­‰ï¼Œå¾è€Œé¿å…ä¸åˆ‡å¯¦éš›çš„é ç®—å°è‡´å¾ŒçºŒçš„æ¨è–¦çµæœä¸æº–ç¢ºæˆ–ç„¡æ³•å¯¦ç¾ã€‚îˆ†\n",
        "\n",
        "### ğŸ§± `budget_guardrail` çš„é‹ä½œæµç¨‹\n",
        "\n",
        "1. **è¼¸å…¥è§£æèˆ‡åˆ†ææç¤ºç”Ÿæˆ**ï¼š\n",
        "   ç•¶ä½¿ç”¨è€…è¼¸å…¥æ—…éŠç›¸é—œçš„è«‹æ±‚çµ¦ Travel Agent æ™‚ï¼Œç”±æ–¼ Travel Agent æœ‰ Input Guardrails ï¼Œå› æ­¤è§¸ç™¼ `budget_guardrail` æœƒå°‡é€™äº›è¼¸å…¥äº¤çµ¦ `budget_analysis_agent` é€²è¡Œé ç®—åˆ†æ\n",
        "\n",
        "2. **å‘¼å« `budget_analysis_agent` é€²è¡Œé ç®—åˆ†æ**ï¼š\n",
        "   é€™å€‹åˆ†ææç¤ºæœƒè¢«å‚³éçµ¦ä¸€å€‹åç‚º `budget_analysis_agent` çš„ä»£ç†ã€‚è©²ä»£ç†çš„ä»»å‹™æ˜¯æ ¹æ“šæä¾›çš„æç¤ºï¼Œåˆ¤æ–·é ç®—æ˜¯å¦åˆç†ï¼Œä¸¦è¿”å›ä¸€å€‹çµæ§‹åŒ–çš„çµæœï¼ŒåŒ…å«ï¼š\n",
        "   -îˆƒ`is_realistic`ï¼šå¸ƒæ—å€¼ï¼Œè¡¨ç¤ºé ç®—æ˜¯å¦åˆç†îˆ„îˆ†\n",
        "   -îˆƒ`reasoning`ï¼šæ–‡å­—èªªæ˜ï¼Œè§£é‡‹ç‚ºä½•é ç®—è¢«åˆ¤å®šç‚ºåˆç†æˆ–ä¸åˆç†îˆ„îˆ†\n",
        "   -îˆƒ`suggested_budget`ï¼ˆå¯é¸ï¼‰ï¼šå¦‚æœé ç®—ä¸åˆç†ï¼Œå»ºè­°çš„åˆç†é ç®—é‡‘é¡îˆ„îˆ†\n",
        "\n",
        "3. **ç”Ÿæˆé˜²è­·æ¬„è¼¸å‡ºçµæœ**ï¼š\n",
        "   æ ¹æ“š `budget_analysis_agent` çš„åˆ†æçµæœï¼Œ`budget_guardrail` æœƒè¿”å›ä¸€å€‹ `GuardrailFunctionOutput` ç‰©ä»¶ã€‚å¦‚æœé ç®—è¢«åˆ¤å®šç‚ºä¸åˆç†ï¼Œå‰‡ `tripwire_triggered` å±¬æ€§æœƒè¢«è¨­ç‚º `True`ï¼Œè¡¨ç¤ºè§¸ç™¼äº†é˜²è­·æ¬„ã€‚\n",
        "\n",
        "### ğŸš¨ é˜²è­·æ¬„è§¸ç™¼çš„è™•ç†æ©Ÿåˆ¶\n",
        "îˆƒåœ¨ä¸»ç¨‹å¼ä¸­ï¼Œç•¶åŸ·è¡Œ `Runner.run(travel_agent, query, context=user_context)` æ™‚ï¼Œå¦‚æœ `budget_guardrail` åˆ¤å®šé ç®—ä¸åˆç†ä¸¦è§¸ç™¼äº†é˜²è­·æ¬„ï¼Œç³»çµ±æœƒæ‹‹å‡º `InputGuardrailTripwireTriggered` ä¾‹îˆ„îˆƒé€™å€‹ä¾‹å¤–æœƒè¢« `try-except` å€å¡Šæ•æ‰ï¼Œä¸¦è¼¸å‡ºè­¦å‘Šè¨Šæ¯ï¼Œä¾‹å¦‚ï¼šã€Œâš ï¸ GUARDRAIL TRIGGERED âš ï¸ã€‚îˆ„îˆ†\n",
        "\n",
        "### ğŸ§  ç‚ºä½•ä½¿ç”¨ä»£ç†é€²è¡Œé ç®—åˆ†æ\n",
        "\n",
        "îˆƒå°‡é ç®—åˆ†æçš„é‚è¼¯å°è£åœ¨ä¸€å€‹å°ˆé–€çš„ä»£ç†ï¼ˆ`budget_analysis_agent`ï¼‰ä¸­ï¼Œæœ‰ä»¥ä¸‹é»ï¼šîˆ„îˆ†\n",
        "\n",
        "- **æ¨¡çµ„åŒ–è¨­è¨ˆ*ï¼šîˆƒä½¿é ç®—åˆ†æé‚è¼¯èˆ‡ä¸»ä»£ç†åˆ†é›¢ï¼Œä¾¿æ–¼ç¶­è­·å’Œå±•ã€‚îˆ„îˆ†\n",
        "- **å¯é‡ç”¨æ€§*ï¼šîˆƒå…¶ä»–ä»£ç†æˆ–åŠŸèƒ½æ¨¡çµ„ä¹Ÿå¯ä»¥é‡ç”¨é€™å€‹é ç®—åˆ†æç†ã€‚îˆ„îˆ†\n",
        "- **éˆæ´»æ€§*ï¼šîˆƒå¯ä»¥æ ¹æ“šéœ€è¦èª¿æ•´åˆ†æé‚è¼¯æˆ–æ¨¡å‹ï¼Œè€Œä¸å½±éŸ¿ä¸»ä»£ç†çš„å…¶ä»–èƒ½ã€‚îˆ„îˆ†\n",
        "\n",
        "### ğŸ“Œ çµè«–\n",
        "\n",
        "îˆƒ`budget_guardrail` ä½œç‚ºä¸€å€‹è¼¸å…¥é˜²è­·æ¬„ï¼Œé€éå°ˆé–€çš„é ç®—åˆ†æä»£ç†ä¾†è©•ä¼°ä½¿ç”¨è€…çš„é ç®—æ˜¯ç†ã€‚îˆ„îˆƒé€™ç¨®è¨­è¨ˆä¸åƒ…æé«˜äº†ç³»çµ±çš„å¥å£¯æ€§ï¼Œé‚„æå‡äº†ä½¿ç”¨è€…é«”é©—ï¼Œç¢ºä¿å¾ŒçºŒçš„æ—…éŠå»ºè­°æ›´è²¼è¿‘å¯¦æƒ…æ³ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "åœ¨ OpenAI çš„ Responses API å’Œ Agents SDK ä¸­ï¼Œ**Guardrailsï¼ˆé˜²è­·æ¬„ï¼‰** æ˜¯ä¸€ç¨®å¯é…ç½®çš„å®‰å…¨æ©Ÿåˆ¶ï¼Œç”¨æ–¼åœ¨ä»£ç†ï¼ˆAgentï¼‰åŸ·è¡Œå‰å¾Œå°è¼¸å…¥å’Œè¼¸å‡ºé€²è¡Œé©—è­‰ã€‚é€™äº›é˜²è­·æ¬„æœ‰åŠ©æ–¼ç¢ºä¿ä»£ç†çš„è¡Œç‚ºç¬¦åˆé æœŸï¼Œä¸¦é˜²æ­¢æ½›åœ¨çš„éŒ¯èª¤æˆ–ä¸ç•¶æ“ä½œã€‚îˆ†\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ›¡ï¸ Guardrails çš„é¡å‹\n",
        "\n",
        "### 1. **è¼¸å…¥é˜²è­·æ¬„ï¼ˆInput Guardrailsï¼‰**\n",
        "- **ç›®çš„**îˆƒåœ¨ä»£ç†è™•ç†ç”¨æˆ¶è¼¸å…¥ä¹‹å‰ï¼Œæª¢æŸ¥è¼¸å…¥çš„æœ‰æ•ˆæ€§å’Œåˆç†æ€§îˆ„îˆ†\n",
        "- **æ‡‰ç”¨å ´æ™¯**îˆƒä¾‹å¦‚ï¼Œåœ¨æ—…éŠè¦åŠƒæ‡‰ç”¨ä¸­ï¼Œæª¢æŸ¥ç”¨æˆ¶æä¾›çš„é ç®—æ˜¯å¦åˆç†îˆ„îˆ†\n",
        "- **å¯¦ç¾æ–¹å¼**îˆƒä½¿ç”¨ `InputGuardrail` é¡åˆ¥ï¼Œä¸¦æŒ‡å®šä¸€å€‹æª¢æŸ¥å‡½æ•¸ï¼ˆå¦‚ `budget_guardrail`ï¼‰ï¼Œè©²å‡½æ•¸è¿”å›ä¸€å€‹ `GuardrailFunctionOutput` ç‰©ä»¶ï¼ŒæŒ‡ç¤ºæ˜¯å¦è§¸ç™¼é˜²è­·æ¬„îˆ„îˆ†\n",
        "\n",
        "### 2. **è¼¸å‡ºé˜²è­·æ¬„ï¼ˆOutput Guardrailsï¼‰**\n",
        "- **ç›®çš„**îˆƒåœ¨ä»£ç†ç”Ÿæˆå›æ‡‰å¾Œï¼Œæª¢æŸ¥è¼¸å‡ºçš„å…§å®¹æ˜¯å¦ç¬¦åˆé æœŸæˆ–å®‰å…¨æ¨™æº–îˆ„îˆ†\n",
        "- **æ‡‰ç”¨å ´æ™¯**îˆƒä¾‹å¦‚ï¼Œé˜²æ­¢ä»£ç†è¼¸å‡ºæ•æ„Ÿæˆ–ä¸é©ç•¶çš„å…§å®¹îˆ„îˆ†\n",
        "- **å¯¦ç¾æ–¹å¼**îˆƒé¡ä¼¼æ–¼è¼¸å…¥é˜²è­·æ¬„ï¼Œä½¿ç”¨ç›¸æ‡‰çš„é¡åˆ¥å’Œæª¢æŸ¥å‡½æ•¸å°è¼¸å‡ºé€²è¡Œé©—è­‰îˆ„îˆ†\n",
        "\n",
        "---\n",
        "\n",
        "## âš™ï¸ Guardrails çš„é‹ä½œæ©Ÿåˆ¶\n",
        "\n",
        "1. **å®šç¾©é˜²è­·æ¬„å‡½æ•¸**îˆƒé–‹ç™¼è€…å®šç¾©ä¸€å€‹å‡½æ•¸ï¼Œç”¨æ–¼æª¢æŸ¥ç‰¹å®šæ¢ä»¶ï¼ˆä¾‹å¦‚é ç®—åˆç†æ€§ï¼‰îˆ„îˆ†\n",
        "\n",
        "2. **é…ç½®ä»£ç†**îˆƒåœ¨å‰µå»ºä»£ç†æ™‚ï¼Œé€šé `input_guardrails` æˆ– `output_guardrails` åƒæ•¸ï¼Œå°‡é˜²è­·æ¬„å‡½æ•¸èˆ‡ä»£ç†é—œè¯îˆ„îˆ†\n",
        "\n",
        "3. **åŸ·è¡Œæµç¨‹**ï¼š\n",
        "   -îˆƒç•¶ä»£ç†æ¥æ”¶åˆ°è¼¸å…¥æ™‚ï¼Œé¦–å…ˆåŸ·è¡Œè¼¸å…¥é˜²è­·æ¬„å‡½æ•¸îˆ„îˆ†\n",
        "   -îˆƒå¦‚æœé˜²è­·æ¬„è¢«è§¸ç™¼ï¼ˆå³æª¢æŸ¥æœªé€šéï¼‰ï¼Œå‰‡ä»£ç†çš„åŸ·è¡Œæœƒè¢«ä¸­æ­¢ï¼Œä¸¦å¼•ç™¼ `InputGuardrailTripwireTriggered` ä¾‹å¤–îˆ„îˆ†\n",
        "   -îˆƒé–‹ç™¼è€…å¯ä»¥æ•æ‰é€™å€‹ä¾‹å¤–ï¼Œä¸¦æä¾›ç›¸æ‡‰çš„è™•ç†é‚è¼¯ï¼Œä¾‹å¦‚æç¤ºç”¨æˆ¶èª¿æ•´è¼¸å…¥îˆ„îˆ†\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## âœ… å„ªé»èˆ‡æ‡‰ç”¨å ´æ™¯\n",
        "\n",
        "- **æå‡å®‰å…¨æ€§*ï¼šîˆƒé˜²æ­¢ä»£ç†è™•ç†ä¸ç•¶æˆ–æ½›åœ¨å±éšªçš„è¼¸ã€‚îˆ„îˆ†\n",
        "- **æé«˜å¯é æ€§*ï¼šîˆƒç¢ºä¿ä»£ç†çš„è¼¸å‡ºç¬¦åˆé æœŸï¼Œé¿å…ä¸ä¸€è‡´æˆ–éŒ¯èª¤çš„å›ã€‚îˆ„îˆ†\n",
        "- **å¢å¼·ç”¨æˆ¶é«”é©—*ï¼šîˆƒæä¾›å³æ™‚çš„åé¥‹ï¼Œå¹«åŠ©ç”¨æˆ¶ä¿®æ­£è¼¸å…¥ï¼Œæé«˜äº’å‹•çš„æµæš¢ã€‚îˆ„îˆ†\n",
        "\n"
      ],
      "metadata": {
        "id": "mrc9TUa1jkQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `UserContext`\n",
        "\n",
        "`UserContext` é¡å’Œ `Agent` çš„çµåˆä½¿ç”¨æä¾›äº†å¼·å¤§çš„å€‹äººåŒ–èƒ½åŠ›ï¼Œä½¿å¾—ä»£ç†èƒ½å¤ æ ¹æ“šç”¨æˆ¶çš„åå¥½å’Œéœ€æ±‚æä¾›å®šåˆ¶åŒ–çš„å»ºè­°ã€‚ä»¥ä¸‹æ˜¯å°é€™äº›çµ„ä»¶çš„è©³ç´°è§£é‡‹ï¼šîˆ†\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  `UserContext` é¡ï¼šå°è£ç”¨æˆ¶åå¥½\n",
        "îˆƒ`UserContext` æ˜¯ä¸€å€‹ä½¿ç”¨ `@dataclass` è£é£¾å™¨å®šç¾©çš„æ•¸æ“šé¡ï¼Œç”¨æ–¼å­˜å„²èˆ‡ç”¨æˆ¶ç›¸é—œçš„åå¥½å’Œè³‡è¨Šã€‚é€™äº›è³‡è¨ŠåŒ…æ‹¬îˆ„îˆ†\n",
        "\n",
        "- **`user_id`**îˆƒç”¨æˆ¶çš„å”¯ä¸€è­˜åˆ¥ç¢¼îˆ„îˆ†\n",
        "- **`preferred_airlines`**îˆƒç”¨æˆ¶åå¥½çš„èˆªç©ºå…¬å¸åˆ—è¡¨îˆ„îˆ†\n",
        "- **`hotel_amenities`**îˆƒç”¨æˆ¶åå¥½çš„é£¯åº—è¨­æ–½åˆ—è¡¨îˆ„îˆ†\n",
        "- **`budget_level`**îˆƒç”¨æˆ¶çš„é ç®—ç­‰ç´šï¼ˆå¦‚ \"budget\"ã€\"mid-range\"ã€\"luxury\"ï¼‰îˆ„îˆ†\n",
        "- **`session_start`**îˆƒæœƒè©±é–‹å§‹çš„æ™‚é–“æˆ³îˆ„îˆ†\n",
        "îˆƒ`@dataclass` è£é£¾å™¨è‡ªå‹•ç‚ºé€™å€‹é¡ç”Ÿæˆåˆå§‹åŒ–æ–¹æ³•å’Œå…¶ä»–å¯¦ç”¨æ–¹æ³•ï¼Œç°¡åŒ–äº†ä»£ç¢¼çš„æ’°å¯«å’Œç¶­è­·îˆ„îˆ†\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§© `Agent` å¦‚ä½•ä½¿ç”¨ `UserContext`\n",
        "îˆƒåœ¨é€™å€‹ç³»çµ±ä¸­ï¼Œ`Agent` æ˜¯è™•ç†ç‰¹å®šä»»å‹™çš„æ™ºèƒ½ä»£ç†ï¼Œä¾‹å¦‚æœå°‹èˆªç­æˆ–é£¯åº—ã€‚æ¯å€‹ä»£ç†éƒ½å¯ä»¥è¨ªå• `UserContext`ï¼Œå¾è€Œæ ¹æ“šç”¨æˆ¶çš„åå¥½æä¾›å€‹æ€§åŒ–çš„å»ºã€‚îˆ„îˆ†\n",
        "\n",
        "### âœˆï¸ èˆªç­ä»£ç† (`flight_agent`)\n",
        "îˆƒ`flight_agent` ä½¿ç”¨ `search_flights` å·¥å…·ä¾†æœå°‹èˆªç­ã€‚åœ¨æœå°‹éç¨‹ä¸­ï¼Œå®ƒæœƒè€ƒæ…® `UserContext` ä¸­çš„ `preferred_airlines`ï¼Œå°‡ç”¨æˆ¶åå¥½çš„èˆªç©ºå…¬å¸æ’åœ¨æœå°‹çµæœçš„å‰åˆ—ï¼Œä¸¦æ¨™è¨˜ç‚ºåå¥½é¸ã€‚îˆ„îˆ†\n",
        "\n",
        "### ğŸ¨ é£¯åº—ä»£ç† (`hotel_agent`\n",
        "\n",
        "îˆƒ`hotel_agent` ä½¿ç”¨ `search_hotels` å·¥å…·ä¾†æœå°‹é£¯åº—ã€‚å®ƒæœƒæ ¹æ“š `UserContext` ä¸­çš„ `hotel_amenities` å’Œ `budget_level`ï¼Œç¯©é¸ä¸¦æ’åºæœå°‹çµæœã€‚ä¾‹å¦‚ï¼Œè‹¥ç”¨æˆ¶åå¥½æœ‰æ¸¸æ³³æ± çš„é£¯åº—ï¼Œä»£ç†æœƒå„ªå…ˆæ¨è–¦åŒ…å«è©²è¨­æ–½çš„åº—ã€‚îˆ„îˆ†\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”„ `RunContextWrapper` çš„è‰²\n",
        "\n",
        "îˆƒ`RunContextWrapper` æ˜¯ä¸€å€‹å°è£å™¨ï¼Œç”¨æ–¼åœ¨å·¥å…·å‡½æ•¸ä¸­å‚³é `UserContext`ã€‚ç•¶å·¥å…·å‡½æ•¸ï¼ˆå¦‚ `search_flights` æˆ– `search_hotels`ï¼‰è¢«å‘¼å«æ™‚ï¼Œå®ƒå€‘å¯ä»¥é€šéé€™å€‹å°è£å™¨è¨ªå•ç”¨æˆ¶çš„åå¥½è³‡è¨Šï¼Œå¾è€Œæä¾›æ›´ç¬¦åˆç”¨æˆ¶éœ€æ±‚çµæœã€‚îˆ„îˆ†\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§­ `travel_agent` æ•´åˆ\n",
        "\n",
        "îˆƒ`travel_agent` æ˜¯ä¸€å€‹ç¶œåˆæ€§çš„ä»£ç†ï¼Œè² è²¬æ•´é«”çš„æ—…éŠè¦åŠƒã€‚å®ƒæœƒæ ¹æ“šç”¨æˆ¶çš„è¼¸å…¥å’Œ `UserContext`ï¼Œæ±ºå®šæ˜¯å¦éœ€è¦å°‡ä»»å‹™äº¤ç”±å°ˆé–€çš„ä»£ç†ï¼ˆå¦‚ `flight_agent` æˆ– `hotel_agent`ï¼‰è™•ç†ï¼Œæˆ–è€…ç›´æ¥æä¾›å»ºè­°ã€‚é€™ç¨®è¨­è¨ˆä½¿å¾—ç³»çµ±èƒ½å¤ éˆæ´»åœ°è™•ç†å„ç¨®æ—…éŠç›¸é—œçš„æŸ¥è©¢ï¼Œä¸¦æä¾›å€‹æ€§çš„å»ºè­°ã€‚îˆ„îˆ†\n",
        "\n",
        "--\n",
        "\n",
        "åœ¨ Python çš„ `@dataclass` è£é£¾å™¨ä¸­ï¼Œ`__post_init__` æ–¹æ³•æ˜¯ä¸€å€‹ç‰¹æ®Šçš„åˆå§‹åŒ–é‰¤å­ï¼ˆhookï¼‰ï¼Œå®ƒæœƒåœ¨è‡ªå‹•ç”Ÿæˆçš„ `__init__` æ–¹æ³•åŸ·è¡Œå®Œç•¢å¾Œè‡ªå‹•è¢«å‘¼å«ã€‚é€™ä½¿å¾—æˆ‘å€‘å¯ä»¥åœ¨ç‰©ä»¶åˆå§‹åŒ–å¾Œé€²è¡Œé¡å¤–çš„è™•ç†ï¼Œä¾‹å¦‚è¨­å®šé è¨­å€¼ã€é©—è­‰è¼¸å…¥æˆ–æ ¹æ“šå…¶ä»–æ¬„ä½è¨ˆç®—è¡ç”Ÿå±¬æ€§ã€‚\n",
        "\n",
        "### ç‚ºä»€éº¼ä½¿ç”¨ `__post_init__` è€Œä¸æ˜¯è‡ªå®šç¾© `__init__`ï¼Ÿ\n",
        "\n",
        "ç•¶æˆ‘å€‘ä½¿ç”¨ `@dataclass` æ™‚ï¼ŒPython æœƒè‡ªå‹•ç‚ºæˆ‘å€‘ç”Ÿæˆ `__init__` æ–¹æ³•ï¼Œé€™å€‹æ–¹æ³•æœƒæ ¹æ“šé¡åˆ¥ä¸­å®šç¾©çš„æ¬„ä½ä¾†åˆå§‹åŒ–ç‰©ä»¶ã€‚å¦‚æœæˆ‘å€‘æ‰‹å‹•å®šç¾©äº† `__init__` æ–¹æ³•ï¼Œé€™å°‡æœƒè¦†è“‹è‡ªå‹•ç”Ÿæˆçš„ç‰ˆæœ¬ï¼Œå°è‡´æˆ‘å€‘å¤±å» `@dataclass` æ‰€å¸¶ä¾†çš„ä¾¿åˆ©æ€§ã€‚\n",
        "\n",
        "ä½¿ç”¨ `__post_init__` å¯ä»¥è®“æˆ‘å€‘åœ¨ä¿ç•™è‡ªå‹•ç”Ÿæˆçš„ `__init__` æ–¹æ³•çš„åŒæ™‚ï¼Œæ·»åŠ è‡ªå®šç¾©çš„åˆå§‹åŒ–é‚è¼¯ã€‚é€™ç¨®æ–¹å¼ä¸åƒ…ç°¡æ½”ï¼Œè€Œä¸”èƒ½å¤ ä¿æŒä»£ç¢¼çš„ä¸€è‡´æ€§å’Œå¯è®€æ€§ã€‚\n",
        "\n",
        "### `__post_init__` çš„ä½¿ç”¨æƒ…å¢ƒ\n",
        "\n",
        "1. **è¨­å®šé è¨­å€¼æˆ–è™•ç†å¯è®Šé è¨­å€¼**ï¼šé¿å…æ‰€æœ‰å¯¦ä¾‹å…±äº«åŒä¸€å€‹å¯è®Šç‰©ä»¶ã€‚\n",
        "   ```python\n",
        "   from dataclasses import dataclass, field\n",
        "   from typing import List\n",
        "\n",
        "   @dataclass\n",
        "   class MyClass:\n",
        "       items: List[int] = field(default_factory=list)\n",
        "\n",
        "       def __post_init__(self):\n",
        "           # ç¢ºä¿ items æ˜¯ä¸€å€‹æ–°çš„åˆ—è¡¨å¯¦ä¾‹\n",
        "           self.items = list(self.items)\n",
        "   ```\n",
        "\n",
        "2. **æ ¹æ“šå…¶ä»–æ¬„ä½è¨ˆç®—è¡ç”Ÿå±¬æ€§**ï¼šä¾‹å¦‚è¨ˆç®—å…©å€‹æ¬„ä½çš„ç¸½å’Œã€‚\n",
        "   ```python\n",
        "   @dataclass\n",
        "   class Point:\n",
        "       x: int\n",
        "       y: int\n",
        "       distance: float = 0.0\n",
        "\n",
        "       def __post_init__(self):\n",
        "           self.distance = (self.x ** 2 + self.y ** 2) ** 0.5\n",
        "   ```\n",
        "\n",
        "3. **é©—è­‰è¼¸å…¥è³‡æ–™çš„æœ‰æ•ˆæ€§**ï¼šä¾‹å¦‚æª¢æŸ¥æŸå€‹æ¬„ä½çš„å€¼æ˜¯å¦åœ¨åˆç†ç¯„åœå…§ã€‚\n",
        "   ```python\n",
        "   @dataclass\n",
        "   class Product:\n",
        "       name: str\n",
        "       price: float\n",
        "\n",
        "       def __post_init__(self):\n",
        "           if self.price < 0:\n",
        "               raise ValueError(\"Price cannot be negative\")\n",
        "   ```\n",
        "\n",
        "4. **è™•ç†åˆå§‹åŒ–å°ˆç”¨è®Šæ•¸ï¼ˆInitVarï¼‰**ï¼šé€™äº›è®Šæ•¸åªåœ¨åˆå§‹åŒ–æœŸé–“ä½¿ç”¨ï¼Œä¸æœƒæˆç‚ºå¯¦ä¾‹çš„å±¬æ€§ã€‚\n",
        "   ```python\n",
        "   from dataclasses import dataclass, InitVar\n",
        "\n",
        "   @dataclass\n",
        "   class Example:\n",
        "       data: int\n",
        "       factor: InitVar[int]\n",
        "\n",
        "       def __post_init__(self, factor):\n",
        "           self.data *= factor\n",
        "   ```\n",
        "\n",
        "### å°çµ\n",
        "\n",
        "ä½¿ç”¨ `__post_init__` æ–¹æ³•å¯ä»¥è®“æˆ‘å€‘åœ¨ä¿ç•™ `@dataclass` è‡ªå‹•ç”ŸæˆåŠŸèƒ½çš„åŒæ™‚ï¼Œæ·»åŠ è‡ªå®šç¾©çš„åˆå§‹åŒ–é‚è¼¯ã€‚é€™ç¨®æ–¹å¼ç‰¹åˆ¥é©åˆéœ€è¦åœ¨ç‰©ä»¶åˆå§‹åŒ–å¾Œé€²è¡Œé¡å¤–è™•ç†çš„æƒ…å¢ƒï¼Œèƒ½å¤ æå‡ä»£ç¢¼çš„å¯ç¶­è­·æ€§å’Œå¯è®€æ€§ã€‚\n"
      ],
      "metadata": {
        "id": "CfpzFsavp8Lh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### wrapper: RunContextWrapper\n",
        "\n",
        "`wrapper: RunContextWrapper[UserContext]` æ˜¯ä¸€å€‹åƒæ•¸ï¼Œå‚³éçµ¦åƒ `search_flights` é€™æ¨£çš„å·¥å…·å‡½æ•¸ã€‚é€™å€‹ `wrapper` æ˜¯ `RunContextWrapper` é¡å‹çš„å¯¦ä¾‹ï¼Œä¸¦ä¸”æ³›å‹åƒæ•¸ç‚º `UserContext`ã€‚îˆ†\n",
        "\n",
        "### `RunContextWrapper[UserContext]` çš„è§’è‰²\n",
        "\n",
        "`RunContextWrapper` æ˜¯ä¸€å€‹å°è£å™¨ï¼ŒåŒ…å«äº†é‹è¡Œæ™‚çš„ä¸Šä¸‹æ–‡è³‡è¨Šã€‚åœ¨é€™å€‹ä¾‹å­ä¸­ï¼Œå®ƒåŒ…å«äº† `UserContext` çš„å¯¦ä¾‹ã€‚é€™ä½¿å¾—åœ¨åŸ·è¡Œå·¥å…·å‡½æ•¸æ™‚ï¼Œå¯ä»¥å­˜å–ä½¿ç”¨è€…çš„åå¥½è¨­å®šï¼Œä¾‹å¦‚ï¼šîˆ†\n",
        "\n",
        "- `preferred_airlines`ï¼šä½¿ç”¨è€…åå¥½çš„èˆªç©ºå…¬å¸îˆ†\n",
        "- `hotel_amenities`ï¼šä½¿ç”¨è€…åå¥½çš„é£¯åº—è¨­æ–½îˆ†\n",
        "- `budget_level`ï¼šä½¿ç”¨è€…çš„é ç®—ç­‰ç´šîˆ†\n",
        "\n",
        "é€™äº›è³‡è¨Šå¯ä»¥ç”¨ä¾†å€‹æ€§åŒ–æœå°‹çµæœã€‚ä¾‹å¦‚ï¼Œåœ¨ `search_flights` å‡½æ•¸ä¸­ï¼Œæ ¹æ“š `preferred_airlines` å°èˆªç­é¸é …é€²è¡Œæ’åºï¼Œå°‡ä½¿ç”¨è€…åå¥½çš„èˆªç©ºå…¬å¸æ’åœ¨å‰é¢ã€‚îˆ†\n",
        "\n",
        "### ä½¿ç”¨ `wrapper.context` çš„å¥½è™•\n",
        "\n",
        "é€é `wrapper.context`ï¼Œå·¥å…·å‡½æ•¸å¯ä»¥å­˜å–ä½¿ç”¨è€…çš„ä¸Šä¸‹æ–‡è³‡è¨Šï¼Œå¯¦ç¾æ›´å€‹æ€§åŒ–çš„åŠŸèƒ½ã€‚é€™ç¨®è¨­è¨ˆä½¿å¾—å·¥å…·å‡½æ•¸å…·æœ‰æ›´é«˜çš„éˆæ´»æ€§å’Œå¯é‡ç”¨æ€§ï¼Œå› ç‚ºå®ƒå€‘å¯ä»¥æ ¹æ“šä¸åŒçš„ä½¿ç”¨è€…ä¸Šä¸‹æ–‡é€²è¡Œèª¿æ•´ï¼Œè€Œä¸éœ€è¦ç¡¬ç·¨ç¢¼ä½¿ç”¨è€…åå¥½ã€‚îˆ†\n",
        "\n",
        "### ç¸½çµ\n",
        "\n",
        "`RunContextWrapper[UserContext]` æä¾›äº†ä¸€ç¨®æ©Ÿåˆ¶ï¼Œè®“å·¥å…·å‡½æ•¸åœ¨åŸ·è¡Œæ™‚èƒ½å¤ å­˜å–ä½¿ç”¨è€…çš„ä¸Šä¸‹æ–‡è³‡è¨Šï¼Œå¾è€Œå¯¦ç¾å€‹æ€§åŒ–çš„åŠŸèƒ½ã€‚é€™ç¨®è¨­è¨ˆæé«˜äº†ç³»çµ±çš„éˆæ´»æ€§å’Œå¯ç¶­è­·æ€§ã€‚îˆ†"
      ],
      "metadata": {
        "id": "Q073f_RxrF7w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Logfire\n",
        "\n",
        "https://www.youtube.com/watch?v=gkHSIOxh60s\n",
        "\n",
        "https://pydantic.dev/pricing\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l8IaOgP1Sftt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### v6_streamlit_agent"
      ],
      "metadata": {
        "id": "caNjpJ-jm81U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit openai langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNc2biuwnHmL",
        "outputId": "82a7bf24-3a25-4b3a-f64c-0ef96e0455f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import asyncio\n",
        "import uuid\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Any\n",
        "import os\n",
        "\n",
        "# Import the travel agent from v5\n",
        "from v5_guardrails_and_context import (\n",
        "    travel_agent,\n",
        "    UserContext,\n",
        "    TravelPlan,\n",
        "    FlightRecommendation,\n",
        "    HotelRecommendation\n",
        ")\n",
        "\n",
        "from agents import Runner\n",
        "\n",
        "# Page configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"Travel Planner Assistant\",\n",
        "    page_icon=\"âœˆï¸\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Custom CSS for better styling\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    .chat-message {\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 0.5rem;\n",
        "        margin-bottom: 1rem;\n",
        "        display: flex;\n",
        "        flex-direction: column;\n",
        "    }\n",
        "    .chat-message.user {\n",
        "        background-color: #e6f7ff;\n",
        "        border-left: 5px solid #2196F3;\n",
        "    }\n",
        "    .chat-message.assistant {\n",
        "        background-color: #f0f0f0;\n",
        "        border-left: 5px solid #4CAF50;\n",
        "    }\n",
        "    .chat-message .content {\n",
        "        display: flex;\n",
        "        margin-top: 0.5rem;\n",
        "    }\n",
        "    .avatar {\n",
        "        width: 40px;\n",
        "        height: 40px;\n",
        "        border-radius: 50%;\n",
        "        object-fit: cover;\n",
        "        margin-right: 1rem;\n",
        "    }\n",
        "    .message {\n",
        "        flex: 1;\n",
        "        color: #000000;\n",
        "    }\n",
        "    .timestamp {\n",
        "        font-size: 0.8rem;\n",
        "        color: #888;\n",
        "        margin-top: 0.2rem;\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Initialize session state for chat history and user context\n",
        "if \"chat_history\" not in st.session_state:\n",
        "    st.session_state.chat_history = []\n",
        "\n",
        "if \"thread_id\" not in st.session_state:\n",
        "    st.session_state.thread_id = str(uuid.uuid4())\n",
        "\n",
        "if \"user_context\" not in st.session_state:\n",
        "    st.session_state.user_context = UserContext(\n",
        "        user_id=str(uuid.uuid4())\n",
        "    )\n",
        "\n",
        "if \"processing_message\" not in st.session_state:\n",
        "    st.session_state.processing_message = None\n",
        "\n",
        "# Function to format agent responses based on output type\n",
        "def format_agent_response(output):\n",
        "    # Check if output is a Pydantic model and convert to dict\n",
        "    if hasattr(output, \"model_dump\"):\n",
        "        output = output.model_dump()\n",
        "\n",
        "    if isinstance(output, dict):\n",
        "        # Handle structured outputs\n",
        "        if \"destination\" in output:  # TravelPlan\n",
        "            html = f\"\"\"\n",
        "            <h3>Travel Plan for {output.get('destination', 'Your Trip')}</h3>\n",
        "            <p><strong>Duration:</strong> {output.get('duration_days', 'N/A')} days</p>\n",
        "            <p><strong>Budget:</strong> ${output.get('budget', 'N/A')}</p>\n",
        "\n",
        "            <h4>Recommended Activities:</h4>\n",
        "            <ul>\n",
        "            \"\"\"\n",
        "            for activity in output.get('activities', []):\n",
        "                html += f\"<li>{activity}</li>\"\n",
        "            html += \"</ul>\"\n",
        "\n",
        "            html += f\"<p><strong>Notes:</strong> {output.get('notes', '')}</p>\"\n",
        "            return html\n",
        "\n",
        "        elif \"airline\" in output:  # FlightRecommendation\n",
        "            html = f\"\"\"\n",
        "            <h3>Flight Recommendation</h3>\n",
        "            <p><strong>Airline:</strong> {output.get('airline', 'N/A')}</p>\n",
        "            <p><strong>Departure:</strong> {output.get('departure_time', 'N/A')}</p>\n",
        "            <p><strong>Arrival:</strong> {output.get('arrival_time', 'N/A')}</p>\n",
        "            <p><strong>Price:</strong> ${output.get('price', 'N/A')}</p>\n",
        "            <p><strong>Direct Flight:</strong> {'Yes' if output.get('direct_flight', False) else 'No'}</p>\n",
        "            <p><strong>Why this flight:</strong> {output.get('recommendation_reason', '')}</p>\"\"\"\n",
        "            return html\n",
        "\n",
        "        elif \"name\" in output and \"amenities\" in output:  # HotelRecommendation\n",
        "            html = f\"\"\"\n",
        "            <h3>Hotel Recommendation: {output.get('name', 'N/A')}</h3>\n",
        "            <p><strong>Location:</strong> {output.get('location', 'N/A')}</p>\n",
        "            <p><strong>Price per night:</strong> ${output.get('price_per_night', 'N/A')}</p>\n",
        "\n",
        "            <h4>Amenities:</h4>\n",
        "            <ul>\n",
        "            \"\"\"\n",
        "            for amenity in output.get('amenities', []):\n",
        "                html += f\"<li>{amenity}</li>\"\n",
        "            html += \"</ul>\"\n",
        "\n",
        "            html += f\"<p><strong>Why this hotel:</strong> {output.get('recommendation_reason', '')}</p>\"\n",
        "            return html\n",
        "\n",
        "    # Default: return as string\n",
        "    return str(output)\n",
        "\n",
        "# Function to handle user input\n",
        "def handle_user_message(user_input: str):\n",
        "    # Add user message to chat history immediately\n",
        "    timestamp = datetime.now().strftime(\"%I:%M %p\")\n",
        "    st.session_state.chat_history.append({\n",
        "        \"role\": \"user\",\n",
        "        \"content\": user_input,\n",
        "        \"timestamp\": timestamp\n",
        "    })\n",
        "\n",
        "    # Set the message for processing in the next rerun\n",
        "    st.session_state.processing_message = user_input\n",
        "\n",
        "# Sidebar for user preferences\n",
        "with st.sidebar:\n",
        "    st.title(\"Travel Preferences\")\n",
        "\n",
        "    st.subheader(\"About You\")\n",
        "    traveler_name = st.text_input(\"Your Name\", value=\"Traveler\")\n",
        "\n",
        "    st.subheader(\"Travel Preferences\")\n",
        "    preferred_airlines = st.multiselect(\n",
        "        \"Preferred Airlines\",\n",
        "        [\"SkyWays\", \"OceanAir\", \"MountainJet\", \"Delta\", \"United\", \"American\", \"Southwest\"],\n",
        "        default=st.session_state.user_context.preferred_airlines\n",
        "    )\n",
        "\n",
        "    preferred_amenities = st.multiselect(\n",
        "        \"Must-have Hotel Amenities\",\n",
        "        [\"WiFi\", \"Pool\", \"Gym\", \"Free Breakfast\", \"Restaurant\", \"Spa\", \"Parking\"],\n",
        "        default=st.session_state.user_context.hotel_amenities\n",
        "    )\n",
        "\n",
        "    budget_level = st.select_slider(\n",
        "        \"Budget Level\",\n",
        "        options=[\"budget\", \"mid-range\", \"luxury\"],\n",
        "        value=st.session_state.user_context.budget_level or \"mid-range\"\n",
        "    )\n",
        "\n",
        "    if st.button(\"Save Preferences\"):\n",
        "        st.session_state.user_context.preferred_airlines = preferred_airlines\n",
        "        st.session_state.user_context.hotel_amenities = preferred_amenities\n",
        "        st.session_state.user_context.budget_level = budget_level\n",
        "        st.success(\"Preferences saved!\")\n",
        "\n",
        "    st.divider()\n",
        "\n",
        "    if st.button(\"Start New Conversation\"):\n",
        "        st.session_state.chat_history = []\n",
        "        st.session_state.thread_id = str(uuid.uuid4())\n",
        "        st.success(\"New conversation started!\")\n",
        "\n",
        "# Main chat interface\n",
        "st.title(\"âœˆï¸ Travel Planner Assistant\")\n",
        "st.caption(\"Ask me about travel destinations, flight options, hotel recommendations, and more!\")\n",
        "\n",
        "# Display chat messages\n",
        "for message in st.session_state.chat_history:\n",
        "    with st.container():\n",
        "        if message[\"role\"] == \"user\":\n",
        "            st.markdown(f\"\"\"\n",
        "            <div class=\"chat-message user\">\n",
        "                <div class=\"content\">\n",
        "                    <img src=\"https://api.dicebear.com/7.x/avataaars/svg?seed={st.session_state.user_context.user_id}\" class=\"avatar\" />\n",
        "                    <div class=\"message\">\n",
        "                        {message[\"content\"]}\n",
        "                        <div class=\"timestamp\">{message[\"timestamp\"]}</div>\n",
        "                    </div>\n",
        "                </div>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "        else:\n",
        "            st.markdown(f\"\"\"\n",
        "            <div class=\"chat-message assistant\">\n",
        "                <div class=\"content\">\n",
        "                    <img src=\"https://api.dicebear.com/7.x/bottts/svg?seed=travel-agent\" class=\"avatar\" />\n",
        "                    <div class=\"message\">\n",
        "                        {message[\"content\"]}\n",
        "                        <div class=\"timestamp\">{message[\"timestamp\"]}</div>\n",
        "                    </div>\n",
        "                </div>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# User input\n",
        "user_input = st.chat_input(\"Ask about travel plans...\")\n",
        "if user_input:\n",
        "    handle_user_message(user_input)\n",
        "    st.rerun()\n",
        "\n",
        "# Process message if needed\n",
        "if st.session_state.processing_message:\n",
        "    user_input = st.session_state.processing_message\n",
        "    st.session_state.processing_message = None\n",
        "\n",
        "    # Process the message asynchronously\n",
        "    with st.spinner(\"Thinking...\"):\n",
        "        try:\n",
        "            # Prepare input for the agent using chat history\n",
        "            if len(st.session_state.chat_history) > 1:\n",
        "                # Convert chat history to input list format for the agent\n",
        "                input_list = []\n",
        "                for msg in st.session_state.chat_history:\n",
        "                    input_list.append({\"role\": msg[\"role\"], \"content\": msg[\"content\"]})\n",
        "            else:\n",
        "                # First message\n",
        "                input_list = user_input\n",
        "\n",
        "            # Run the agent with the input\n",
        "            result = asyncio.run(Runner.run(\n",
        "                travel_agent,\n",
        "                input_list,\n",
        "                context=st.session_state.user_context\n",
        "            ))\n",
        "\n",
        "            # Format the response based on output type\n",
        "            response_content = format_agent_response(result.final_output)\n",
        "\n",
        "            # Add assistant response to chat history\n",
        "            st.session_state.chat_history.append({\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": response_content,\n",
        "                \"timestamp\": datetime.now().strftime(\"%I:%M %p\")\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            error_message = f\"Sorry, I encountered an error: {str(e)}\"\n",
        "            st.session_state.chat_history.append({\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": error_message,\n",
        "                \"timestamp\": datetime.now().strftime(\"%I:%M %p\")\n",
        "            })\n",
        "\n",
        "        # Force a rerun to display the AI response\n",
        "        st.rerun()\n",
        "\n",
        "# Footer\n",
        "st.divider()\n",
        "st.caption(\"Powered by OpenAI Agents SDK | Built with Streamlit\")"
      ],
      "metadata": {
        "id": "HavoANie8e3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc2321d-30c1-405e-c1c7-a449ba986d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-11 20:50:24.263 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.265 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.332 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-04-11 20:50:24.334 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.336 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.339 Session state does not function when running a script without `streamlit run`\n",
            "2025-04-11 20:50:24.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.342 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.343 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.345 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.346 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.347 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.348 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.350 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.351 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.353 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.355 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.357 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.359 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.360 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.361 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.362 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.363 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.364 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.365 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.365 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.366 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.367 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.367 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.368 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.369 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.370 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.370 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.371 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.372 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.373 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.377 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.378 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.379 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.379 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.380 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.382 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.383 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.383 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.384 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.387 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.388 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.388 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.389 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.390 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.390 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.391 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.392 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.392 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.393 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.394 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.394 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.395 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.396 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.397 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.397 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.398 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.399 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.400 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.400 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.401 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.402 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.403 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.404 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.404 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.405 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-11 20:50:24.406 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trace\n",
        "\n",
        "Log in OpenAI account, projects, logs, Traces\n",
        "\n",
        "https://platform.openai.com/logs"
      ],
      "metadata": {
        "id": "licHo8Fj92Cf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXJKldzYs9ni"
      },
      "source": [
        "# Courses of next Week\n",
        "\n",
        "Week 46 OpenAI Agent SDK 2/2 advance\n",
        "\n",
        "1. Responses API Walkthrough https://www.youtube.com/watch?v=0pGxoubWI6s\n",
        "  - https://github.com/daveebbelaar/ai-cookbook/tree/main/models/openai/05-responses\n",
        "\n",
        "2. Automate Your Browser with AI! Build a Computer Using Agent (OpenAI API) https://www.youtube.com/watch?v=Tm1_KHdh_kA\n",
        "  - https://github.com/leonvanzyl/openai-responses-api-tutorial-python/blob/master/lesson-9.py\n",
        "\n",
        "\n",
        "3. How To Build An OpenAI Computer-Using Agent (CUA Model) https://www.youtube.com/watch?v=9hkjq6hQTYo\n",
        "\n",
        "\n",
        "---\n",
        "Playwright: https://www.youtube.com/watch?v=RGR5Xj0Qqfs\n",
        "\n",
        "Playwright MCP: https://www.youtube.com/watch?v=2716IUeCIQo\n",
        "\n",
        "Browser Use https://www.youtube.com/watch?v=zGkVKix_CRU\n",
        "\n",
        "\n",
        "\n",
        "https://www.youtube.com/watch?v=gyFu6xubdEk\n",
        "  - https://www.youtube.com/watch?v=gyFu6xubdEk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3YyD0hHjM91"
      },
      "source": [
        "#Colab files of this Study Group\n",
        "\n",
        "\n",
        "1.   [20240531 Hugging Face & LLM Tools - Transformer Introduction Pipeline.ipynb](https://colab.research.google.com/drive/10DuI2Evk_w1ebe4gIgaTQlYMOafUN3z4?usp=sharing)\n",
        "\n",
        "2. [20240607 Hugging Face & LLM Tools - Transformer Encoder Decoder Encoder-Decoder.ipynb](https://colab.research.google.com/drive/1PDj5kbZu2whF8ASXR3IeQZfBYjwvc9ib?usp=sharing)\n",
        "\n",
        "3. [20240614 Hugging Face & LLM Tools - USING TRANSFORMERS.ipynb](https://colab.research.google.com/drive/1H02fg2lDaEuCUFmY8Fzr45uftga0IFJy?usp=sharing)\n",
        "\n",
        "4. [20240621 Hugging Face & LLM Tools - Fine-Tuning A Pretrained Model.ipynb](https://colab.research.google.com/drive/1pQxFFnBFVoOBuGPYp0d6Nih8TFeAk4k7?usp=sharing)\n",
        "\n",
        "5. [20240628 Hugging Face & LLM Tools - Sharing Models and Tokenizer.ipynb](https://colab.research.google.com/drive/1XGY2wRzPelaw-evSPTH8EJ_L-LUutP7y?usp=sharing)\n",
        "\n",
        "6. [20240705 Hugging Face & LLM Tools - Dataset 1/2.ipynb](https://colab.research.google.com/drive/1TjQ9lR-YIbWYT5J9cWJ1L2qghMnid7HX?usp=sharing)\n",
        "\n",
        "7. [20240712 Hugging Face & LLM Tools - Dataset 2/2.ipynb](https://colab.research.google.com/drive/1BgMzO5mTdqK68MCMYX89gpX3wwJsxSRQ?usp=sharing)\n",
        "\n",
        "8. [20240719 Hugging Face & LLM Tools - TOKENIZERS LIBRARY 1/2.ipynb](https://colab.research.google.com/drive/1b1k5AM34gOibFcu9BwddIV_NpApW9ORR?usp=sharing)\n",
        "\n",
        "9. [20240726 Hugging Face & LLM Tools - TOKENIZERS LIBRARY 2/2.ipynb](https://colab.research.google.com/drive/1hCQkn53Gf8vrM33cy2MNNtiotoVBweYA?usp=sharing)\n",
        "\n",
        "10. [20240802 Hugging Face & LLM Tools - MAIN NLP TASKS 1/2.ipynb]( https://colab.research.google.com/drive/1QvyzWlG3K0NOLkOEVzhQL6oGMHsO2Lr3?usp=sharing )\n",
        "\n",
        "11. [20240809 Hugging Face & LLM Tools - MAIN NLP TASKS 2/2.ipynb]( https://colab.research.google.com/drive/13Lfk4tmm9MUCEO5TcZygljAQV_yyp1CM?usp=sharing )\n",
        "\n",
        "12. [20240816 Hugging Face & LLM Tools - How to Ask Help.ipynb]( https://colab.research.google.com/drive/1dCkDVlSBSxQom9M8jEyy_Zk2KocWtMRR?usp=sharing )\n",
        "\n",
        "13. [20240823 Hugging Face & LLM Tools - Building and sharing demos 1/2.ipynb]( https://colab.research.google.com/drive/1VaNWjH_oTqBVxG1K7d8J4_rClyqUcS7W?usp=sharing )\n",
        "\n",
        "14. [20240830 Hugging Face & LLM Tools - Building and sharing demos 2/2.ipynb]( https://colab.research.google.com/drive/15nXSphf9qG02ReTs36CWczPx2g9tU28R?usp=sharing )\n",
        "\n",
        "15. [20240906 Hugging Face & LLM Tools - API.ipynb]( https://colab.research.google.com/drive/1RjtuOignulPp2ewcRXE53CPI-qso-vwA?usp=sharing )\n",
        "\n",
        "16. [20240913 Hugging Face & LLM Tools - Local Server 1/2.ipynb]( https://colab.research.google.com/drive/1gd55wakcBN1LfL7NQGe4ALYmwHvZM0yG?usp=sharing )\n",
        "\n",
        "17. [20240920 Hugging Face & LLM Tools - Local Server 2/2 NIM & LLaMA C++.ipynb]( https://colab.research.google.com/drive/1dMM7NfryclLmqKYMhbEY-z9nZooR492J?usp=sharing )\n",
        "\n",
        "18. [20240927  Hugging Face & LLM Tools - LangChain 1/2 DeepLearning.ipynb]( https://colab.research.google.com/drive/1yQjUlFXRc8JqPzgw7rHOU-_nfqSganNS?usp=sharing )\n",
        "\n",
        "19. [20241004  Hugging Face & LLM Tools - LangChain 2/2 with llama3d2.ipynb]( https://colab.research.google.com/drive/1JPTH4t1USSekFrfxyI7lOWEK0HOOMMcQ?usp=sharing )\n",
        "\n",
        "20. [20241011  Hugging Face & LLM Tools - RAG 1/2 with llamaindex Truera.ipynb]( https://colab.research.google.com/drive/1lSz6H5kgwB08PoFz3K8dYEHZJgkKzDaO?usp=sharing )\n",
        "\n",
        "21. Gap week\n",
        "\n",
        "22. [20241025  Hugging Face & LLM Tools - RAG 2/2 with llamaindex & Agent.ipynb]( https://colab.research.google.com/drive/1PeKC2UVcHS7v0DKtuxq9SfFvyNqbTydO?usp=sharing )\n",
        "\n",
        "23. [20241101  Hugging Face & LLM Tools - Dify 1/3.ipynb]( https://colab.research.google.com/drive/1afJdk5qlw8IqyYkYN0MmT7wVBCBO-1iP?usp=sharing )\n",
        "\n",
        "24. [20241108  Hugging Face & LLM Tools - Dify 2/3.ipynb]( https://colab.research.google.com/drive/1Efz35MYweXE1BveFIxr_0WTMcgHXIixC?usp=sharing )\n",
        "\n",
        "25. [2024115 Hugging Face & LLM Tools - Dify 3/3.ipynb]( https://colab.research.google.com/drive/1CDa6QK7Yl7CADYvAqrh-9xB1R02Lg30D?usp=sharing )\n",
        "\n",
        "26. [20241122 Hugging Face & LLM Tools - Vector DB 1/2 Milvus pgvector .ipynb]( https://colab.research.google.com/drive/1UfFuedpk8aMxqt6OTEdX4_Ap7vmUSLd8?usp=sharing )\n",
        "\n",
        "27. [20241129 Hugging Face & LLM Tools - Vector DB 2/2 Qdrant ChromaDB.ipynb]( https://colab.research.google.com/drive/1piGVevD9FDWJCuYTsdJKkvEsLl2rOkYh?usp=sharing )\n",
        "\n",
        "28. [20241206  Hugging Face & LLM Tools - Graph RAG 1/2 Microsoft GraphRAG.ipynb]( https://colab.research.google.com/drive/1qb2H_EgTccVNUj2M9U-nC-4LmBCyuJjN?usp=sharing )\n",
        "\n",
        "29. [20241213  Hugging Face & LLM Tools - Graph RAG 2/2 code of GraphRAG Sciphi Triplex LightRAG.ipynb]( https://colab.research.google.com/drive/1PTJvst7rkhNiIX0kAWuu7SBDPpRWc2DY?usp=sharing )\n",
        "\n",
        "30. [20241220   Huging Face & LLM Tools - Graph Database 1/2 Neo4j.ipynb]( https://colab.research.google.com/drive/1YG4OwbtQJ7ONULR1lBm9FjXrLG9mqTn4?usp=sharing )\n",
        "\n",
        "31. [20241227   Huging Face & LLM Tools - Graph Database 2/2 Neo4j continue.ipynb]( https://colab.research.google.com/drive/1j-DwNMGEDeh4dJARJ0Zcg1v3BMcAsU4Y?usp=sharing )\n",
        "\n",
        "32. [20250103   Huging Face & LLM Tools - NotebookLM.ipynb]( https://colab.research.google.com/drive/1KAQC8t9Z0AmB3O6qiEQmTc6fzFRtjGGo?usp=sharing )\n",
        "\n",
        "33. Gap week\n",
        "\n",
        "34. [20250117   Huging Face & LLM Tools - Gemini Deep Research.ipynb]( https://colab.research.google.com/drive/139r3EQRK8k0YvZHOyQP4nEcZzyA4nkhY?usp=sharing )\n",
        "\n",
        "35. [20250124    Huging Face & LLM Tools - CrewAI 1/2 Begining.ipynb]( https://colab.research.google.com/drive/1P2CaVTw1RaElFp5LU2eadaIzgGbbAJj2?usp=sharing )\n",
        "\n",
        "36. [20250131 Huging Face & LLM Tools - CrewAI 2/2 Advance.ipynb]( https://colab.research.google.com/drive/1J6JewQwHAO6Av3SnmsVlNofr5RrYeB22?usp=sharing )\n",
        "\n",
        "37. [20250207 Huging Face & LLM Tools LangGraph 1/3 Deeplearning.ipynb]( https://colab.research.google.com/drive/1XR77zFZdUOa_-PoQHZnGWKG8KSRzt2Me?usp=sharing )\n",
        "\n",
        "38. [20250214 Huging Face & LLM Tools LangGraph 2/3 LangChain Academy & LangSmith.ipynb]( https://colab.research.google.com/drive/1Ip7KT3FZZAWfJv3UZRfPxvBjSym7tRaN?usp=sharing )\n",
        "\n",
        "\n",
        "39. [20250221  Huging Face & LLM Tools LangGraph 3/3 LangChain Academy & Open Deep Research.ipynb]( https://colab.research.google.com/drive/1kGbcSs77ZtfSyrZDgywNU2UoG_84srEU?usp=sharing )\n",
        "\n",
        "40. [20250228  Huging Face & LLM Tools Microsoft AutoGen 1/2 DeeplearningAI.ipynb]( https://colab.research.google.com/drive/1dXdbB4ScHcWGAcC3MliL8IjPsvTF9Jsl?usp=sharing )\n",
        "\n",
        "41. [20250307   Huging Face & LLM Tools Microsoft AutoGen 2/2 AutoGen v0.4 MCP AutoGen Studio.ipynb]( https://colab.research.google.com/drive/1vX1AAfvcW9PTHkNN4hW6cExlxKg3Yeyx?usp=sharing )\n",
        "\n",
        "42. [20250314   Huging Face & LLM Tools n8n 1/2 Beginner.ipynb]( https://colab.research.google.com/drive/1Vk0fAginKDWOK_hJosCxXSq1xqejyraQ?usp=sharing )\n",
        "\n",
        "43. [20250321   Huging Face & LLM Tools n8n 2/2 Advance self hosting community nodes MPC.ipynb]( https://colab.research.google.com/drive/1whNl7nu1nJN8hY_IS6zz2BUm9RBqDfzU?usp=sharing )\n",
        "\n",
        "44. [20250328   Huging Face & LLM Tools Dify Plugin.ipynb]( https://colab.research.google.com/drive/1-4qNbhwsi4HyO7BrsmeC2-GHYCsMA2-q?usp=sharing )\n",
        "\n",
        "45. [20250404   Huging Face & LLM Tools Replit Vibe Coding.ipynb]( https://colab.research.google.com/drive/1rxIc4rJxvKvB4jXaj4dIhpugTBhyZFDk?usp=sharing )\n",
        "\n",
        "46. [20250411   Huging Face & LLM Tools OpenAI Agent SDK 1/2 .ipynb]( https://colab.research.google.com/drive/1rDqF8g-02vjLsW5v9fcCEXNQ6aF7_pAG?usp=sharing )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Appendix"
      ],
      "metadata": {
        "id": "Qkkq6_QmPApc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Responses API Walkthrough\n",
        "\n",
        "https://www.youtube.com/watch?v=0pGxoubWI6s\n",
        "https://github.com/daveebbelaar/ai-cookbook/tree/main/models/openai/05-responses\n",
        "\n",
        "https://www.youtube.com/watch?v=gyFu6xubdEk"
      ],
      "metadata": {
        "id": "97HiZ0TiYM9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI Agents SDK Cheatsheet\n",
        "\n",
        "## Installation & Setup\n",
        "\n",
        "```bash\n",
        "# Create a project and virtual environment\n",
        "mkdir my_project\n",
        "cd my_project\n",
        "python -m venv .venv\n",
        "\n",
        "# Activate the virtual environment\n",
        "source .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n",
        "\n",
        "# Install the Agents SDK\n",
        "pip install openai-agents\n",
        "\n",
        "# Set OpenAI API key\n",
        "export OPENAI_API_KEY=sk-...  # On Windows: set OPENAI_API_KEY=sk-...\n",
        "```\n",
        "\n",
        "## Agent Basics\n",
        "\n",
        "### Creating a Simple Agent\n",
        "\n",
        "```python\n",
        "from agents import Agent, Runner\n",
        "import asyncio\n",
        "\n",
        "# Define a basic agent\n",
        "agent = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=\"You are a helpful assistant that provides clear, concise answers.\"\n",
        ")\n",
        "\n",
        "# Run the agent\n",
        "async def main():\n",
        "    result = await Runner.run(agent, \"What is the capital of France?\")\n",
        "    print(result.final_output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n",
        "```\n",
        "\n",
        "### Agent with Tools\n",
        "\n",
        "```python\n",
        "from agents import Agent, function_tool\n",
        "\n",
        "# Define a tool using the decorator\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Get the current weather for a city.\n",
        "    \n",
        "    Args:\n",
        "        city: The name of the city to get weather for.\n",
        "    \"\"\"\n",
        "    # In a real app, call a weather API here\n",
        "    return f\"The weather in {city} is sunny and 75Â°F\"\n",
        "\n",
        "# Create agent with the tool\n",
        "agent = Agent(\n",
        "    name=\"Weather Assistant\",\n",
        "    instructions=\"Help users with weather-related queries.\",\n",
        "    tools=[get_weather]\n",
        ")\n",
        "```\n",
        "\n",
        "### Agent with Output Type\n",
        "\n",
        "```python\n",
        "from pydantic import BaseModel\n",
        "from agents import Agent\n",
        "\n",
        "class CalendarEvent(BaseModel):\n",
        "    name: str\n",
        "    date: str\n",
        "    participants: list[str]\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Calendar Assistant\",\n",
        "    instructions=\"Extract calendar events from user messages.\",\n",
        "    output_type=CalendarEvent\n",
        ")\n",
        "```\n",
        "\n",
        "## Agent Orchestration\n",
        "\n",
        "### Creating Agents with Handoffs\n",
        "\n",
        "```python\n",
        "from agents import Agent\n",
        "\n",
        "# Create specialist agents\n",
        "history_agent = Agent(\n",
        "    name=\"History Tutor\",\n",
        "    handoff_description=\"Specialist for historical questions\",\n",
        "    instructions=\"You provide assistance with historical queries. Explain important events and context clearly.\"\n",
        ")\n",
        "\n",
        "math_agent = Agent(\n",
        "    name=\"Math Tutor\",\n",
        "    handoff_description=\"Specialist for math questions\",\n",
        "    instructions=\"You provide help with math problems. Explain your reasoning at each step.\"\n",
        ")\n",
        "\n",
        "# Create a triage agent with handoffs\n",
        "triage_agent = Agent(\n",
        "    name=\"Triage Agent\",\n",
        "    instructions=\"Determine which specialist to use based on the user's question\",\n",
        "    handoffs=[history_agent, math_agent]\n",
        ")\n",
        "```\n",
        "\n",
        "### Customizing Handoffs\n",
        "\n",
        "```python\n",
        "from agents import Agent, handoff\n",
        "from agents.extensions import handoff_filters\n",
        "\n",
        "# Create a specialized agent\n",
        "faq_agent = Agent(\n",
        "    name=\"FAQ Agent\",\n",
        "    instructions=\"Answer frequently asked questions about our product.\"\n",
        ")\n",
        "\n",
        "# Create customized handoff\n",
        "handoff_obj = handoff(\n",
        "    agent=faq_agent,\n",
        "    tool_name_override=\"transfer_to_faq_specialist\",\n",
        "    tool_description_override=\"Transfer to the FAQ specialist for product questions\",\n",
        "    input_filter=handoff_filters.remove_all_tools\n",
        ")\n",
        "\n",
        "# Use the handoff in another agent\n",
        "main_agent = Agent(\n",
        "    name=\"Main Agent\",\n",
        "    instructions=\"Help users with their queries. Transfer to specialists as needed.\",\n",
        "    handoffs=[handoff_obj]\n",
        ")\n",
        "```\n",
        "\n",
        "## Tools\n",
        "\n",
        "### Function Tools\n",
        "\n",
        "```python\n",
        "from agents import Agent, function_tool\n",
        "from typing import Dict, List\n",
        "\n",
        "@function_tool\n",
        "def search_database(query: str) -> List[Dict]:\n",
        "    \"\"\"Search the database for information.\n",
        "    \n",
        "    Args:\n",
        "        query: The search query string.\n",
        "    \"\"\"\n",
        "    # Implement database search here\n",
        "    return [{\"title\": \"Sample result\", \"content\": \"Sample content\"}]\n",
        "\n",
        "@function_tool\n",
        "def calculate_total(items: List[Dict[str, float]]) -> float:\n",
        "    \"\"\"Calculate the total price of multiple items.\n",
        "    \n",
        "    Args:\n",
        "        items: List of items with their prices.\n",
        "    \"\"\"\n",
        "    return sum(item[\"price\"] for item in items)\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Database Assistant\",\n",
        "    instructions=\"Help users search the database and calculate totals.\",\n",
        "    tools=[search_database, calculate_total]\n",
        ")\n",
        "```\n",
        "\n",
        "### OpenAI Hosted Tools\n",
        "\n",
        "```python\n",
        "from agents import Agent, WebSearchTool, FileSearchTool\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Research Assistant\",\n",
        "    instructions=\"Help users find information online and from our knowledge base.\",\n",
        "    tools=[\n",
        "        WebSearchTool(),\n",
        "        FileSearchTool(\n",
        "            max_num_results=3,\n",
        "            vector_store_ids=[\"YOUR_VECTOR_STORE_ID\"]\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "```\n",
        "\n",
        "### Agents as Tools\n",
        "\n",
        "```python\n",
        "from agents import Agent\n",
        "\n",
        "translator_spanish = Agent(\n",
        "    name=\"Spanish Translator\",\n",
        "    instructions=\"Translate text to Spanish accurately and naturally.\"\n",
        ")\n",
        "\n",
        "translator_french = Agent(\n",
        "    name=\"French Translator\",\n",
        "    instructions=\"Translate text to French accurately and naturally.\"\n",
        ")\n",
        "\n",
        "orchestrator = Agent(\n",
        "    name=\"Translation Hub\",\n",
        "    instructions=\"Help users translate text to different languages.\",\n",
        "    tools=[\n",
        "        translator_spanish.as_tool(\n",
        "            tool_name=\"translate_to_spanish\",\n",
        "            tool_description=\"Translate the user's text to Spanish\"\n",
        "        ),\n",
        "        translator_french.as_tool(\n",
        "            tool_name=\"translate_to_french\",\n",
        "            tool_description=\"Translate the user's text to French\"\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "```\n",
        "\n",
        "## Guardrails\n",
        "\n",
        "```python\n",
        "from agents import Agent, InputGuardrail, GuardrailFunctionOutput, Runner\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# Define output structure for guardrail\n",
        "class HomeworkCheck(BaseModel):\n",
        "    is_homework: bool\n",
        "    reasoning: str\n",
        "\n",
        "# Create guardrail agent\n",
        "guardrail_agent = Agent(\n",
        "    name=\"Guardrail Check\",\n",
        "    instructions=\"Check if the user is asking about homework.\",\n",
        "    output_type=HomeworkCheck\n",
        ")\n",
        "\n",
        "# Define guardrail function\n",
        "async def homework_guardrail(ctx, agent, input_data):\n",
        "    result = await Runner.run(guardrail_agent, input_data, context=ctx.context)\n",
        "    final_output = result.final_output_as(HomeworkCheck)\n",
        "    \n",
        "    return GuardrailFunctionOutput(\n",
        "        output_info=final_output,\n",
        "        tripwire_triggered=not final_output.is_homework\n",
        "    )\n",
        "\n",
        "# Apply guardrail to agent\n",
        "agent_with_guardrail = Agent(\n",
        "    name=\"Homework Helper\",\n",
        "    instructions=\"Help with legitimate educational questions, not just giving homework answers.\",\n",
        "    input_guardrails=[\n",
        "        InputGuardrail(guardrail_function=homework_guardrail)\n",
        "    ]\n",
        ")\n",
        "```\n",
        "\n",
        "## Context Management\n",
        "\n",
        "```python\n",
        "from dataclasses import dataclass\n",
        "from agents import Agent, RunContextWrapper, function_tool, Runner\n",
        "\n",
        "# Define context structure\n",
        "@dataclass\n",
        "class UserContext:\n",
        "    user_id: str\n",
        "    username: str\n",
        "    is_premium: bool\n",
        "\n",
        "# Create a tool that uses context\n",
        "@function_tool\n",
        "def get_user_info(ctx: RunContextWrapper[UserContext]) -> str:\n",
        "    \"\"\"Get information about the current user.\"\"\"\n",
        "    user = ctx.context\n",
        "    return f\"User: {user.username} (ID: {user.user_id}), Premium: {user.is_premium}\"\n",
        "\n",
        "# Create agent with context type\n",
        "agent = Agent[UserContext](\n",
        "    name=\"User-Aware Assistant\",\n",
        "    instructions=\"Provide personalized assistance based on the user's information.\",\n",
        "    tools=[get_user_info]\n",
        ")\n",
        "\n",
        "# Use the agent with context\n",
        "async def main():\n",
        "    user_context = UserContext(\n",
        "        user_id=\"12345\",\n",
        "        username=\"john_doe\",\n",
        "        is_premium=True\n",
        "    )\n",
        "    \n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"Tell me about my account\",\n",
        "        context=user_context\n",
        "    )\n",
        "    print(result.final_output)\n",
        "```\n",
        "\n",
        "## Running Agents\n",
        "\n",
        "### Basic Running\n",
        "\n",
        "```python\n",
        "from agents import Agent, Runner\n",
        "import asyncio\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Assistant\",\n",
        "        instructions=\"You are a helpful assistant.\"\n",
        "    )\n",
        "    \n",
        "    # Async run\n",
        "    result = await Runner.run(agent, \"Write a haiku about programming.\")\n",
        "    print(result.final_output)\n",
        "    \n",
        "    # For synchronous code, use run_sync instead\n",
        "    # result = Runner.run_sync(agent, \"Write a haiku about programming.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n",
        "```\n",
        "\n",
        "### Streaming\n",
        "\n",
        "```python\n",
        "from agents import Agent, Runner\n",
        "import asyncio\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Storyteller\",\n",
        "        instructions=\"You create engaging short stories.\"\n",
        "    )\n",
        "    \n",
        "    # Get streaming result\n",
        "    result = Runner.run_streamed(\n",
        "        agent,\n",
        "        input=\"Tell me a short story about a robot learning to paint.\"\n",
        "    )\n",
        "    \n",
        "    # Print content as it's generated\n",
        "    print(\"Story is being written...\")\n",
        "    async for event in result.stream_events():\n",
        "        if event.type == \"raw_response_event\":\n",
        "            if hasattr(event.data, \"delta\"):\n",
        "                print(event.data.delta, end=\"\", flush=True)\n",
        "    \n",
        "    print(\"\\n\\nStory complete!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n",
        "```\n",
        "\n",
        "### Multi-turn Conversations\n",
        "\n",
        "```python\n",
        "from agents import Agent, Runner\n",
        "import asyncio\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Conversation Agent\",\n",
        "        instructions=\"You are a helpful assistant that maintains context throughout a conversation.\"\n",
        "    )\n",
        "    \n",
        "    # First turn\n",
        "    result = await Runner.run(agent, \"What's the capital of Japan?\")\n",
        "    print(f\"Agent: {result.final_output}\")\n",
        "    \n",
        "    # Second turn (using previous context)\n",
        "    new_input = result.to_input_list() + [{\"role\": \"user\", \"content\": \"What about South Korea?\"}]\n",
        "    result = await Runner.run(agent, new_input)\n",
        "    print(f\"Agent: {result.final_output}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n",
        "```\n",
        "\n",
        "## Model Configuration\n",
        "\n",
        "```python\n",
        "from agents import Agent, ModelSettings, Runner\n",
        "\n",
        "# Configure model settings\n",
        "agent = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=\"You are a helpful, concise assistant.\",\n",
        "    model=\"o3-mini\",  # Specify model name\n",
        "    model_settings=ModelSettings(\n",
        "        temperature=0.7,\n",
        "        top_p=0.95,\n",
        "        max_tokens=1000\n",
        "    )\n",
        ")\n",
        "\n",
        "# Or override at runtime\n",
        "async def main():\n",
        "    result = await Runner.run(\n",
        "        agent,\n",
        "        \"Explain quantum computing briefly\",\n",
        "        run_config=RunConfig(\n",
        "            model=\"gpt-4o\",\n",
        "            model_settings=ModelSettings(temperature=0)\n",
        "        )\n",
        "    )\n",
        "    print(result.final_output)\n",
        "```\n",
        "\n",
        "## Dynamic Instructions\n",
        "\n",
        "```python\n",
        "from agents import Agent, RunContextWrapper\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class UserProfile:\n",
        "    name: str\n",
        "    language: str\n",
        "    expertise_level: str\n",
        "\n",
        "def dynamic_instructions(\n",
        "    context: RunContextWrapper[UserProfile],\n",
        "    agent: Agent[UserProfile]\n",
        ") -> str:\n",
        "    profile = context.context\n",
        "    return f\"\"\"\n",
        "    You are a helpful assistant for {profile.name}.\n",
        "    Communicate in {profile.language}.\n",
        "    Adjust explanations to a {profile.expertise_level} level of expertise.\n",
        "    Be friendly, clear, and concise in your responses.\n",
        "    \"\"\"\n",
        "\n",
        "agent = Agent[UserProfile](\n",
        "    name=\"Adaptive Assistant\",\n",
        "    instructions=dynamic_instructions\n",
        ")\n",
        "```\n",
        "\n",
        "## Error Handling\n",
        "\n",
        "```python\n",
        "from agents import Agent, function_tool, Runner\n",
        "import asyncio\n",
        "\n",
        "# Custom error handler for tools\n",
        "def handle_tool_error(error, function_name, args):\n",
        "    if isinstance(error, ValueError):\n",
        "        return f\"I couldn't process your request. The value provided was invalid: {str(error)}\"\n",
        "    return f\"An unexpected error occurred: {str(error)}\"\n",
        "\n",
        "@function_tool(failure_error_function=handle_tool_error)\n",
        "def divide_numbers(a: float, b: float) -> float:\n",
        "    \"\"\"Divide two numbers.\n",
        "    \n",
        "    Args:\n",
        "        a: The dividend\n",
        "        b: The divisor (must not be zero)\n",
        "    \"\"\"\n",
        "    if b == 0:\n",
        "        raise ValueError(\"Cannot divide by zero\")\n",
        "    return a / b\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Calculator\",\n",
        "    instructions=\"Help users with mathematical calculations.\",\n",
        "    tools=[divide_numbers]\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    try:\n",
        "        result = await Runner.run(agent, \"What is 10 divided by 0?\")\n",
        "        print(result.final_output)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n",
        "```\n",
        "\n",
        "## Tracing\n",
        "\n",
        "```python\n",
        "from agents import Agent, Runner, trace, set_tracing_disabled\n",
        "\n",
        "# Disable tracing globally\n",
        "# set_tracing_disabled(True)\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Assistant\",\n",
        "        instructions=\"You are a helpful assistant.\"\n",
        "    )\n",
        "    \n",
        "    # Add trace information for this run\n",
        "    with trace(\n",
        "        workflow_name=\"Customer Support\",\n",
        "        group_id=\"user_session_123\",\n",
        "        trace_metadata={\"customer_id\": \"cust_123\", \"channel\": \"chat\"}\n",
        "    ):\n",
        "        result = await Runner.run(agent, \"I need help with my order\")\n",
        "        print(result.final_output)\n",
        "    \n",
        "    # View traces in the OpenAI Dashboard: https://platform.openai.com/traces\n",
        "```\n",
        "\n",
        "## Complete Example: Multi-Agent System\n",
        "\n",
        "```python\n",
        "from agents import Agent, Runner, function_tool, InputGuardrail, GuardrailFunctionOutput\n",
        "from pydantic import BaseModel\n",
        "import asyncio\n",
        "\n",
        "# 1. Define tools\n",
        "@function_tool\n",
        "def get_product_info(product_id: str) -> dict:\n",
        "    \"\"\"Get information about a product.\n",
        "    \n",
        "    Args:\n",
        "        product_id: The unique identifier for the product\n",
        "    \"\"\"\n",
        "    # Mock database lookup\n",
        "    products = {\n",
        "        \"p123\": {\"name\": \"Wireless Headphones\", \"price\": 99.99, \"in_stock\": True},\n",
        "        \"p456\": {\"name\": \"Smart Watch\", \"price\": 249.99, \"in_stock\": False}\n",
        "    }\n",
        "    return products.get(product_id, {\"error\": \"Product not found\"})\n",
        "\n",
        "# 2. Define guardrail check\n",
        "class ProfanityCheck(BaseModel):\n",
        "    contains_profanity: bool\n",
        "    reasoning: str\n",
        "\n",
        "profanity_agent = Agent(\n",
        "    name=\"Profanity Check\",\n",
        "    instructions=\"Check if the user's message contains profanity or inappropriate language.\",\n",
        "    output_type=ProfanityCheck\n",
        ")\n",
        "\n",
        "async def profanity_guardrail(ctx, agent, input_data):\n",
        "    result = await Runner.run(profanity_agent, input_data, context=ctx.context)\n",
        "    final_output = result.final_output_as(ProfanityCheck)\n",
        "    \n",
        "    return GuardrailFunctionOutput(\n",
        "        output_info=final_output,\n",
        "        tripwire_triggered=final_output.contains_profanity\n",
        "    )\n",
        "\n",
        "# 3. Create specialized agents\n",
        "product_agent = Agent(\n",
        "    name=\"Product Specialist\",\n",
        "    handoff_description=\"Specialist for product-related questions\",\n",
        "    instructions=\"You help customers with product information, features, and comparisons.\",\n",
        "    tools=[get_product_info]\n",
        ")\n",
        "\n",
        "support_agent = Agent(\n",
        "    name=\"Support Specialist\",\n",
        "    handoff_description=\"Specialist for customer support issues\",\n",
        "    instructions=\"You help customers with order issues, returns, and technical support.\"\n",
        ")\n",
        "\n",
        "# 4. Create main triage agent\n",
        "triage_agent = Agent(\n",
        "    name=\"Customer Service\",\n",
        "    instructions=\"\"\"\n",
        "    You are the initial point of contact for customer inquiries.\n",
        "    Analyze the customer's question and route to the appropriate specialist:\n",
        "    - Route product questions to the Product Specialist\n",
        "    - Route support issues to the Support Specialist\n",
        "    - For simple questions, answer directly\n",
        "    \"\"\",\n",
        "    handoffs=[product_agent, support_agent],\n",
        "    input_guardrails=[\n",
        "        InputGuardrail(guardrail_function=profanity_guardrail)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 5. Run the system\n",
        "async def main():\n",
        "    # Run with a product question\n",
        "    result = await Runner.run(\n",
        "        triage_agent,\n",
        "        \"Can you tell me more about the wireless headphones with product ID p123?\"\n",
        "    )\n",
        "    print(\"RESULT 1:\\n\", result.final_output)\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "    \n",
        "    # Run with a support question\n",
        "    result = await Runner.run(\n",
        "        triage_agent,\n",
        "        \"I ordered something 3 days ago but haven't received a shipping confirmation.\"\n",
        "    )\n",
        "    print(\"RESULT 2:\\n\", result.final_output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n",
        "```\n"
      ],
      "metadata": {
        "id": "GyobHqGIzi-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI Agents SDK Cheat Sheet\n",
        "\n",
        "## AGENT BASICS\n",
        "Creating and configuring agents\n",
        "```python\n",
        "# Create a simple agent\n",
        "agent = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=\"You are a helpful assistant.\",\n",
        "    model=\"o3-mini\"  # Optional model specification\n",
        ")\n",
        "\n",
        "# Agent with output type\n",
        "agent = Agent(\n",
        "    name=\"Calendar Assistant\",\n",
        "    instructions=\"Extract calendar events.\",\n",
        "    output_type=CalendarEvent  # Pydantic model\n",
        ")\n",
        "\n",
        "# Clone and modify an agent\n",
        "robot_agent = pirate_agent.clone(\n",
        "    name=\"Robot\",\n",
        "    instructions=\"Write like a robot\"\n",
        ")\n",
        "```\n",
        "\n",
        "## TOOLS\n",
        "Enabling agents to take actions\n",
        "```python\n",
        "# Function tool using decorator\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Get weather for a city.\"\"\"\n",
        "    return f\"The weather in {city} is sunny\"\n",
        "\n",
        "# Hosted tools from OpenAI\n",
        "agent = Agent(\n",
        "    tools=[\n",
        "        WebSearchTool(),\n",
        "        FileSearchTool(vector_store_ids=[\"STORE_ID\"])\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Agent as a tool\n",
        "orchestrator = Agent(\n",
        "    tools=[\n",
        "        spanish_agent.as_tool(\n",
        "            tool_name=\"translate_to_spanish\",\n",
        "            tool_description=\"Translate to Spanish\"\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "```\n",
        "\n",
        "## HANDOFFS\n",
        "Delegating tasks between agents\n",
        "```python\n",
        "# Basic handoff\n",
        "triage_agent = Agent(\n",
        "    handoffs=[support_agent, billing_agent]\n",
        ")\n",
        "\n",
        "# Customized handoff\n",
        "handoff_obj = handoff(\n",
        "    agent=faq_agent,\n",
        "    tool_name_override=\"transfer_to_faq\",\n",
        "    input_filter=handoff_filters.remove_all_tools\n",
        ")\n",
        "\n",
        "# Handoff with input data\n",
        "class EscalationData(BaseModel):\n",
        "    reason: str\n",
        "\n",
        "handoff_obj = handoff(\n",
        "    agent=escalation_agent,\n",
        "    input_type=EscalationData\n",
        ")\n",
        "```\n",
        "\n",
        "## CONTEXT MANAGEMENT\n",
        "Working with context and state\n",
        "```python\n",
        "# Define context type\n",
        "@dataclass\n",
        "class UserContext:\n",
        "    user_id: str\n",
        "    username: str\n",
        "    is_premium: bool\n",
        "\n",
        "# Create agent with context\n",
        "agent = Agent[UserContext](\n",
        "    name=\"User-Aware Assistant\",\n",
        "    instructions=\"Provide personalized help.\"\n",
        ")\n",
        "\n",
        "# Access context in tools\n",
        "@function_tool\n",
        "def get_user_info(ctx: RunContextWrapper[UserContext]) -> str:\n",
        "    return f\"User: {ctx.context.username}\"\n",
        "\n",
        "# Run with context\n",
        "result = await Runner.run(\n",
        "    agent, \"Help me\",\n",
        "    context=UserContext(user_id=\"123\", username=\"john\", is_premium=True)\n",
        ")\n",
        "```\n",
        "\n",
        "## GUARDRAILS\n",
        "Protecting and validating inputs/outputs\n",
        "```python\n",
        "# Create guardrail check\n",
        "class ContentCheck(BaseModel):\n",
        "    is_appropriate: bool\n",
        "    reasoning: str\n",
        "\n",
        "guardrail_agent = Agent(\n",
        "    output_type=ContentCheck\n",
        ")\n",
        "\n",
        "# Define guardrail function\n",
        "async def content_guardrail(ctx, agent, input_data):\n",
        "    result = await Runner.run(guardrail_agent, input_data)\n",
        "    output = result.final_output_as(ContentCheck)\n",
        "    \n",
        "    return GuardrailFunctionOutput(\n",
        "        output_info=output,\n",
        "        tripwire_triggered=not output.is_appropriate\n",
        "    )\n",
        "\n",
        "# Apply guardrail to agent\n",
        "agent = Agent(\n",
        "    input_guardrails=[\n",
        "        InputGuardrail(guardrail_function=content_guardrail)\n",
        "    ]\n",
        ")\n",
        "```\n",
        "\n",
        "## RUNNING AGENTS\n",
        "Executing and managing agent runs\n",
        "```python\n",
        "# Basic run (async)\n",
        "result = await Runner.run(agent, \"What is the capital of France?\")\n",
        "print(result.final_output)\n",
        "\n",
        "# Sync run\n",
        "result = Runner.run_sync(agent, \"Tell me a joke\")\n",
        "\n",
        "# Streaming run\n",
        "result = Runner.run_streamed(agent, \"Write a story\")\n",
        "async for event in result.stream_events():\n",
        "    # Process streaming events\n",
        "    pass\n",
        "\n",
        "# Multi-turn conversations\n",
        "new_input = result.to_input_list() + [\n",
        "    {\"role\": \"user\", \"content\": \"Follow-up question\"}\n",
        "]\n",
        "result = await Runner.run(agent, new_input)\n",
        "```\n",
        "\n",
        "## MODELS & CONFIGURATION\n",
        "Configuring models and run settings\n",
        "```python\n",
        "# Set model and settings on agent\n",
        "agent = Agent(\n",
        "    model=\"o3-mini\",\n",
        "    model_settings=ModelSettings(\n",
        "        temperature=0.7,\n",
        "        top_p=0.95\n",
        "    )\n",
        ")\n",
        "\n",
        "# Configure run settings\n",
        "result = await Runner.run(\n",
        "    agent, \"Question\",\n",
        "    run_config=RunConfig(\n",
        "        model=\"gpt-4o\",\n",
        "        workflow_name=\"Customer Support\",\n",
        "        trace_id=\"session_123\",\n",
        "        trace_metadata={\"customer_id\": \"cust_123\"}\n",
        "    )\n",
        ")\n",
        "```\n",
        "\n",
        "## DYNAMIC INSTRUCTIONS\n",
        "Context-aware prompting\n",
        "```python\n",
        "def dynamic_instructions(\n",
        "    context: RunContextWrapper[UserProfile],\n",
        "    agent: Agent[UserProfile]\n",
        ") -> str:\n",
        "    profile = context.context\n",
        "    return f\"\"\"\n",
        "    You are helping {profile.name}.\n",
        "    Communicate in {profile.language}.\n",
        "    \"\"\"\n",
        "\n",
        "agent = Agent[UserProfile](\n",
        "    instructions=dynamic_instructions\n",
        ")\n",
        "```\n",
        "\n",
        "## COMPLETE WORKFLOW EXAMPLE\n",
        "Putting it all together\n",
        "```python\n",
        "# 1. Create specialist agents\n",
        "product_agent = Agent(\n",
        "    name=\"Product Specialist\",\n",
        "    handoff_description=\"For product questions\",\n",
        "    tools=[get_product_info]\n",
        ")\n",
        "\n",
        "support_agent = Agent(\n",
        "    name=\"Support Specialist\",\n",
        "    handoff_description=\"For customer support issues\"\n",
        ")\n",
        "\n",
        "# 2. Create triage agent with handoffs\n",
        "triage_agent = Agent(\n",
        "    name=\"Customer Service\",\n",
        "    instructions=\"Route to appropriate specialist\",\n",
        "    handoffs=[product_agent, support_agent],\n",
        "    input_guardrails=[\n",
        "        InputGuardrail(guardrail_function=profanity_guardrail)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 3. Run the system\n",
        "async def main():\n",
        "    result = await Runner.run(\n",
        "        triage_agent,\n",
        "        \"Can you tell me about product p123?\"\n",
        "    )\n",
        "    print(result.final_output)\n",
        "```\n",
        "\n",
        "OpenAI Agents SDK is a Python toolkit for creating and orchestrating LLM-powered agents. This cheat sheet covers the most important commands and patterns for quick reference.\n"
      ],
      "metadata": {
        "id": "ewDFo2-Cz61I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## level3"
      ],
      "metadata": {
        "id": "KKEIzEFQr5wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import asyncio\n",
        "import os\n",
        "import time\n",
        "from typing import List, Optional, Tuple, Dict, Any\n",
        "from pydantic import BaseModel, Field\n",
        "from datetime import datetime\n",
        "\n",
        "# Try importing the agents SDK components\n",
        "try:\n",
        "    from agents import Agent, Runner, WebSearchTool, trace\n",
        "    from openai import OpenAI, APIError, AuthenticationError\n",
        "    AGENTS_SDK_AVAILABLE = True\n",
        "except ImportError:\n",
        "    AGENTS_SDK_AVAILABLE = False\n",
        "    st.error(\"Agents SDK not found. Some functionality will be simulated.\")\n",
        "\n",
        "# Define ReportData as a global model - simplified for robustness\n",
        "class ReportData(BaseModel):\n",
        "    short_summary: str = Field(..., description=\"A concise summary of the research findings (1-2 paragraphs)\")\n",
        "    markdown_report: str = Field(..., description=\"Brief markdown-formatted report (500-800 words)\")\n",
        "    follow_up_questions: List[str] = Field(default_factory=list, description=\"2-3 suggested follow-up questions\")\n",
        "\n",
        "# Planner Agent\n",
        "class WebSearchItem(BaseModel):\n",
        "    reason: str\n",
        "    query: str\n",
        "\n",
        "class WebSearchPlan(BaseModel):\n",
        "    searches: List[WebSearchItem]\n",
        "\n",
        "# Handoff tracking\n",
        "class HandoffEvent(BaseModel):\n",
        "    from_agent: str\n",
        "    to_agent: str\n",
        "    reason: str\n",
        "    input: str\n",
        "    output: str\n",
        "    timestamp: str\n",
        "\n",
        "    @classmethod\n",
        "    def create(cls, from_agent, to_agent, reason, input_data, output_data):\n",
        "        # Truncate long inputs/outputs for display\n",
        "        input_str = str(input_data)\n",
        "        output_str = str(output_data)\n",
        "\n",
        "        if len(input_str) > 200:\n",
        "            input_str = input_str[:197] + \"...\"\n",
        "        if len(output_str) > 200:\n",
        "            output_str = output_str[:197] + \"...\"\n",
        "\n",
        "        return cls(\n",
        "            from_agent=from_agent,\n",
        "            to_agent=to_agent,\n",
        "            reason=reason,\n",
        "            input=input_str,\n",
        "            output=output_str,\n",
        "            timestamp=datetime.now().strftime(\"%H:%M:%S\")\n",
        "        )\n",
        "\n",
        "# Function to validate API key\n",
        "def validate_openai_key(api_key: str) -> Tuple[bool, Optional[str]]:\n",
        "    \"\"\"\n",
        "    Validate the OpenAI API key\n",
        "\n",
        "    Returns:\n",
        "    - Tuple of (is_valid, error_message)\n",
        "    - is_valid: Boolean indicating if the key is valid\n",
        "    - error_message: Detailed error message if validation fails\n",
        "    \"\"\"\n",
        "    if not api_key or api_key.strip() == \"\":\n",
        "        return False, \"API Key cannot be empty.\"\n",
        "\n",
        "    try:\n",
        "        if AGENTS_SDK_AVAILABLE:\n",
        "            client = OpenAI(api_key=api_key)\n",
        "            # Light validation check - just checking if the key format is valid\n",
        "            # Don't actually call the API to avoid unnecessary costs\n",
        "            if api_key.startswith(\"sk-\") and len(api_key) > 20:\n",
        "                return True, None\n",
        "            else:\n",
        "                return False, \"Invalid API key format. OpenAI API keys typically start with 'sk-'\"\n",
        "        else:\n",
        "            # When SDK not available, just do format validation\n",
        "            if api_key.startswith(\"sk-\") and len(api_key) > 20:\n",
        "                return True, None\n",
        "            else:\n",
        "                return False, \"Invalid API key format. OpenAI API keys typically start with 'sk-'\"\n",
        "    except AuthenticationError:\n",
        "        return False, (\n",
        "            \"Authentication failed. Possible reasons:\\n\"\n",
        "            \"- Incorrect API key\\n\"\n",
        "            \"- Key has been revoked\\n\"\n",
        "            \"- Billing issues with your OpenAI account\"\n",
        "        )\n",
        "    except APIError as e:\n",
        "        return False, (\n",
        "            f\"API Error: {str(e)}\\n\"\n",
        "            \"Possible reasons:\\n\"\n",
        "            \"- Network connectivity issue\\n\"\n",
        "            \"- Temporary OpenAI service disruption\\n\"\n",
        "            \"- Invalid API key format\"\n",
        "        )\n",
        "    except Exception as e:\n",
        "        return False, (\n",
        "            f\"Unexpected error: {str(e)}\\n\"\n",
        "            \"Please check your API key and network connection.\"\n",
        "        )\n",
        "def setup_agents(api_key: str, num_searches: int, writer_model: str):\n",
        "    \"\"\"Set up agents with the provided API key and configuration\"\"\"\n",
        "    if not AGENTS_SDK_AVAILABLE:\n",
        "        # Return mock agents when SDK isn't available (unchanged)\n",
        "        class MockAgent:\n",
        "            def __init__(self, name, instructions=\"\", model=\"\"):\n",
        "                self.name = name\n",
        "                self.instructions = instructions\n",
        "                self.model = model\n",
        "\n",
        "        # Mock agent setup (unchanged)\n",
        "        # ...\n",
        "\n",
        "        return runner_agent\n",
        "\n",
        "    # Real implementation with Agents SDK\n",
        "    # Configure the OpenAI client globally\n",
        "    os.environ['OPENAI_API_KEY'] = api_key\n",
        "\n",
        "    # Writer Agent - Simple prompt with clear instructions\n",
        "    WRITER_PROMPT = (\n",
        "        \"You are a research writer creating a report from search results. \"\n",
        "        \"You will receive a query and search results from the SearchAgent. \"\n",
        "        \"Your task is to compile the findings into a comprehensive report with: \"\n",
        "        \"1. A concise summary (1-2 paragraphs) \"\n",
        "        \"2. A markdown-formatted report (500-800 words) \"\n",
        "        \"3. 2-3 follow-up questions\\n\\n\"\n",
        "        \"Do NOT hand off to any other agent. You are the final step in the research process.\"\n",
        "    )\n",
        "\n",
        "    # Create the writer agent with standard settings - no handoffs needed as it's the final agent\n",
        "    writer_agent = Agent(\n",
        "        name=\"WriterAgent\",\n",
        "        instructions=WRITER_PROMPT,\n",
        "        model=writer_model,\n",
        "        output_type=ReportData,\n",
        "    )\n",
        "\n",
        "    # Search Agent - Simplified and more focused instructions with explicit handoff\n",
        "    SEARCH_INSTRUCTIONS = (\n",
        "        \"You are a research assistant performing web searches. \"\n",
        "        \"You will receive search queries from the PlannerAgent. \"\n",
        "        \"For each search term:\\n\"\n",
        "        \"1. Extract key facts and insights relevant to the query\\n\"\n",
        "        \"2. Focus on objective information from reliable sources\\n\"\n",
        "        \"3. Create a brief summary (150-200 words maximum)\\n\"\n",
        "        \"4. Format information as bullet points whenever possible\\n\"\n",
        "        \"5. Prioritize recent and factual information\\n\\n\"\n",
        "        \"After completing ALL searches, you MUST hand off to the WriterAgent by using the transfer_to_writeragent function. \"\n",
        "        \"Do NOT hand off after each individual search - only after all searches are complete.\"\n",
        "    )\n",
        "\n",
        "    # Create the search agent with handoff to writer\n",
        "    search_agent = Agent(\n",
        "        name=\"SearchAgent\",\n",
        "        instructions=SEARCH_INSTRUCTIONS,\n",
        "        tools=[WebSearchTool(user_location={\"type\": \"approximate\", \"city\": \"New York\"})],\n",
        "        handoffs=[writer_agent],  # Search hands off to Writer\n",
        "    )\n",
        "\n",
        "    # Updated Planner Prompt with explicit handoff instructions\n",
        "    PLANNER_PROMPT = (\n",
        "        \"You are a helpful research assistant. Given a query from the RunnerAgent, \"\n",
        "        f\"come up with a set of web searches to perform to best answer the query. \"\n",
        "        f\"Output between 1-{num_searches} search terms to query for.\\n\\n\"\n",
        "        \"IMPORTANT: You MUST output your search plan in the format required by WebSearchPlan, with a 'searches' array \"\n",
        "        \"containing objects with 'reason' and 'query' fields.\\n\\n\"\n",
        "        \"AFTER creating your search plan, you MUST ALWAYS hand off to the SearchAgent by using the transfer_to_searchagent \"\n",
        "        \"function call. Do NOT try to conduct the searches yourself.\\n\\n\"\n",
        "        \"Workflow steps:\\n\"\n",
        "        \"1. Create your search plan\\n\"\n",
        "        \"2. Output the search plan in the required format\\n\"\n",
        "        \"3. Call the transfer_to_searchagent function to hand off\"\n",
        "    )\n",
        "\n",
        "    # Create the planner agent with handoff to search\n",
        "    planner_agent = Agent(\n",
        "        name=\"PlannerAgent\",\n",
        "        instructions=PLANNER_PROMPT,\n",
        "        model=\"gpt-4o\",\n",
        "        output_type=WebSearchPlan,\n",
        "        handoffs=[search_agent],  # Planner hands off to Search\n",
        "    )\n",
        "\n",
        "    # Runner Agent with explicit sequential instructions\n",
        "    RUNNER_PROMPT = (\n",
        "        \"You are a research workflow coordinator. Your job is to start a sequential research process. \"\n",
        "        \"For any research query, IMMEDIATELY hand off to the PlannerAgent by using the transfer_to_planneragent function. \"\n",
        "        \"The research process will then follow this exact sequence:\\n\"\n",
        "        \"1. PlannerAgent will create search queries and hand off to SearchAgent\\n\"\n",
        "        \"2. SearchAgent will execute searches and hand off to WriterAgent\\n\"\n",
        "        \"3. WriterAgent will compile the findings into a final report\\n\\n\"\n",
        "        \"Your only task is to start this process by handing off to the PlannerAgent.\"\n",
        "    )\n",
        "\n",
        "    # Create the runner agent with initial handoff only to the planner\n",
        "    runner_agent = Agent(\n",
        "        name=\"RunnerAgent\",\n",
        "        instructions=RUNNER_PROMPT,\n",
        "        model=\"gpt-4o\",\n",
        "        handoffs=[planner_agent],  # Runner hands off to Planner\n",
        "    )\n",
        "\n",
        "    return runner_agent\n",
        "async def perform_research(query: str, runner_agent, session_state):\n",
        "    \"\"\"Async function to perform the research workflow using a runner agent\"\"\"\n",
        "    handoff_details = []\n",
        "    search_details = []\n",
        "\n",
        "    # Initialize the progress container\n",
        "    progress_container = st.empty()\n",
        "    progress_bar = progress_container.progress(0)\n",
        "    status_text = st.empty()\n",
        "    error_container = st.empty()\n",
        "\n",
        "    if not AGENTS_SDK_AVAILABLE:\n",
        "        # Simulate the research process\n",
        "        status_text.text(\"Runner agent coordinating research workflow...\")\n",
        "        await asyncio.sleep(1.5)\n",
        "\n",
        "        # First handoff to planner agent\n",
        "        status_text.text(\"Handing off to planning agent...\")\n",
        "        progress_bar.progress(0.2)\n",
        "        await asyncio.sleep(1.5)\n",
        "\n",
        "        # Mock search plan\n",
        "        search_plan = WebSearchPlan(searches=[\n",
        "            WebSearchItem(reason=\"To get latest information\", query=f\"latest developments in {query}\"),\n",
        "            WebSearchItem(reason=\"To get historical context\", query=f\"history of {query}\"),\n",
        "            WebSearchItem(reason=\"To get expert opinions\", query=f\"expert analysis {query}\"),\n",
        "        ])\n",
        "\n",
        "        # Record handoff details\n",
        "        handoff_details.append(HandoffEvent.create(\n",
        "            from_agent=\"RunnerAgent\",\n",
        "            to_agent=\"PlannerAgent\",\n",
        "            reason=\"Planning search strategy\",\n",
        "            input_data=query,\n",
        "            output_data=f\"Created search plan with {len(search_plan.searches)} queries\"\n",
        "        ))\n",
        "\n",
        "        # Second handoff to search agent\n",
        "        status_text.text(\"Handing off to search agent...\")\n",
        "        progress_bar.progress(0.4)\n",
        "        await asyncio.sleep(1.5)\n",
        "\n",
        "        # Mock search results\n",
        "        for i, item in enumerate(search_plan.searches):\n",
        "            status_text.text(f\"Searching: {item.query}\")\n",
        "            await asyncio.sleep(1)\n",
        "\n",
        "            # Mock search result\n",
        "            search_result = f\"Found information about {item.query}. This includes various sources and citations relevant to the query.\"\n",
        "\n",
        "            # Collect detailed run information\n",
        "            search_details.append({\n",
        "                \"query\": item.query,\n",
        "                \"reason\": item.reason,\n",
        "                \"result\": search_result,\n",
        "            })\n",
        "\n",
        "            # Update progress\n",
        "            progress = 0.4 + (0.3 * (i+1) / len(search_plan.searches))\n",
        "            progress_bar.progress(progress)\n",
        "\n",
        "        # Record combined handoff details for search\n",
        "        handoff_details.append(HandoffEvent.create(\n",
        "            from_agent=\"PlannerAgent\",\n",
        "            to_agent=\"SearchAgent\",\n",
        "            reason=\"Execute web searches\",\n",
        "            input_data=\"Search plan with queries\",\n",
        "            output_data=f\"Completed {len(search_plan.searches)} searches\"\n",
        "        ))\n",
        "\n",
        "        # Third handoff to writer agent\n",
        "        status_text.text(\"Handing off to writer agent...\")\n",
        "        progress_bar.progress(0.8)\n",
        "        await asyncio.sleep(2)\n",
        "\n",
        "        # Mock report\n",
        "        report = ReportData(\n",
        "            short_summary=f\"This is a summary of research findings about {query}.\",\n",
        "            markdown_report=f\"\"\"\n",
        "# Comprehensive Research: {query}\n",
        "\n",
        "## Introduction\n",
        "This research explores {query} in depth, analyzing various aspects and perspectives.\n",
        "\n",
        "## Key Findings\n",
        "1. The first major finding about {query}\n",
        "2. The second major finding about {query}\n",
        "3. The third major finding about {query}\n",
        "\n",
        "## Historical Context\n",
        "{query} has a rich history dating back to its origins.\n",
        "\n",
        "## Expert Analysis\n",
        "Experts in the field suggest that {query} will continue to evolve.\n",
        "\n",
        "## Conclusion\n",
        "In conclusion, {query} represents an important area for further study.\n",
        "            \"\"\",\n",
        "            follow_up_questions=[\n",
        "                f\"What are the future trends for {query}?\",\n",
        "                f\"How does {query} compare to similar topics?\",\n",
        "                f\"What are the practical applications of {query}?\"\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Record handoff details\n",
        "        handoff_details.append(HandoffEvent.create(\n",
        "            from_agent=\"SearchAgent\",\n",
        "            to_agent=\"WriterAgent\",\n",
        "            reason=\"Compile research report\",\n",
        "            input_data=\"Collected search results\",\n",
        "            output_data=\"Creating comprehensive report\"\n",
        "        ))\n",
        "\n",
        "        # Update progress\n",
        "        progress_bar.progress(1.0)\n",
        "        status_text.text(\"Research complete!\")\n",
        "\n",
        "    else:\n",
        "        # Use actual Agents SDK with the runner agent\n",
        "        try:\n",
        "            # Start the research process\n",
        "            status_text.text(\"Starting research workflow with runner agent...\")\n",
        "            progress_bar.progress(0.1)\n",
        "\n",
        "            # Add first handoff for UI display (User to Runner)\n",
        "            handoff_details.append(HandoffEvent.create(\n",
        "                from_agent=\"User\",\n",
        "                to_agent=\"RunnerAgent\",\n",
        "                reason=\"Initial query submission\",\n",
        "                input_data=query,\n",
        "                output_data=\"Initiating research workflow\"\n",
        "            ))\n",
        "\n",
        "            # Update UI for first handoff\n",
        "            status_text.text(\"Runner agent analyzing query...\")\n",
        "            progress_bar.progress(0.2)\n",
        "\n",
        "            # Run the entire agent chain\n",
        "            formatted_query = f\"Research Query: {query}\"\n",
        "            with trace(\"Research Workflow\"):\n",
        "                runner_result = await Runner.run(\n",
        "                    runner_agent,\n",
        "                    formatted_query\n",
        "                )\n",
        "\n",
        "            # Process all items to track handoffs and search operations\n",
        "            current_agent = \"RunnerAgent\"\n",
        "            current_search_query = None\n",
        "            search_queries = []\n",
        "            search_plans = []\n",
        "\n",
        "            # First pass: extract search queries from planner output\n",
        "            for item in runner_result.new_items:\n",
        "                # Look for search plans in message output\n",
        "                if item.type == \"message_output_item\":\n",
        "                    output_text = None\n",
        "                    # Try different ways to get output text based on SDK version\n",
        "                    if hasattr(item, 'output_text'):\n",
        "                        output_text = item.output_text\n",
        "                    elif hasattr(item, 'raw_item') and hasattr(item.raw_item, 'content'):\n",
        "                        output_text = item.raw_item.content\n",
        "\n",
        "                    if output_text and isinstance(output_text, str):\n",
        "                        # Look for JSON content with searches\n",
        "                        if '\"searches\"' in output_text or \"'searches'\" in output_text:\n",
        "                            # Clean up JSON content\n",
        "                            content = output_text.strip()\n",
        "                            if \"```json\" in content:\n",
        "                                content = content.split(\"```json\")[1].split(\"```\")[0]\n",
        "                            elif \"```\" in content:\n",
        "                                content = content.split(\"```\")[1].split(\"```\")[0]\n",
        "                            try:\n",
        "                                import json\n",
        "                                data = json.loads(content)\n",
        "                                if \"searches\" in data:\n",
        "                                    search_plans.append(data)\n",
        "                                    for search in data[\"searches\"]:\n",
        "                                        if \"query\" in search and \"reason\" in search:\n",
        "                                            search_queries.append({\n",
        "                                                \"query\": search[\"query\"],\n",
        "                                                \"reason\": search.get(\"reason\", \"Search query\")\n",
        "                                            })\n",
        "                            except json.JSONDecodeError:\n",
        "                                pass\n",
        "\n",
        "            # Second pass: process handoffs and tool calls\n",
        "            for idx, item in enumerate(runner_result.new_items):\n",
        "                # Process handoffs\n",
        "                if item.type == \"handoff_call_item\":\n",
        "                    # Extract target agent name from handoff call\n",
        "                    target_agent = None\n",
        "                    try:\n",
        "                        # Try different ways to get the target agent name based on SDK version\n",
        "                        if hasattr(item.raw_item, 'function'):\n",
        "                            target_agent = item.raw_item.function.name.replace(\"transfer_to_\", \"\")\n",
        "                        elif hasattr(item.raw_item, 'name'):\n",
        "                            target_agent = item.raw_item.name.replace(\"transfer_to_\", \"\")\n",
        "                        else:\n",
        "                            raw_str = str(item.raw_item)\n",
        "                            if \"transfer_to_\" in raw_str:\n",
        "                                target_agent = raw_str.split(\"transfer_to_\")[1].split(\"(\")[0]\n",
        "                    except:\n",
        "                        target_agent = \"Unknown\"\n",
        "\n",
        "                    # Update UI for handoff\n",
        "                    if target_agent:\n",
        "                        if \"planner\" in target_agent.lower():\n",
        "                            status_text.text(\"Planning agent creating search strategy...\")\n",
        "                            progress_bar.progress(0.3)\n",
        "                        elif \"search\" in target_agent.lower():\n",
        "                            status_text.text(\"Search agent executing web searches...\")\n",
        "                            progress_bar.progress(0.5)\n",
        "                        elif \"writer\" in target_agent.lower():\n",
        "                            status_text.text(\"Writer agent creating final report...\")\n",
        "                            progress_bar.progress(0.8)\n",
        "\n",
        "                elif item.type == \"handoff_output_item\":\n",
        "                    # Extract source and target agent names\n",
        "                    source_agent = current_agent\n",
        "                    target_agent = None\n",
        "\n",
        "                    try:\n",
        "                        # Try different ways to get the target agent name\n",
        "                        if hasattr(item, 'target_agent') and item.target_agent:\n",
        "                            target_agent = item.target_agent.name\n",
        "                        elif hasattr(item, 'raw_item'):\n",
        "                            raw_content = str(item.raw_item)\n",
        "                            if \"'assistant':\" in raw_content:\n",
        "                                target_agent = raw_content.split(\"'assistant': '\")[1].split(\"'\")[0]\n",
        "                    except:\n",
        "                        target_agent = \"Unknown\"\n",
        "\n",
        "                    # Add to handoff details\n",
        "                    if target_agent:\n",
        "                        # Determine handoff reason\n",
        "                        reason = \"Agent handoff\"\n",
        "                        if \"planner\" in target_agent.lower():\n",
        "                            reason = \"Planning search strategy\"\n",
        "                        elif \"search\" in target_agent.lower():\n",
        "                            reason = \"Execute web searches\"\n",
        "                        elif \"writer\" in target_agent.lower():\n",
        "                            reason = \"Compile research report\"\n",
        "\n",
        "                        handoff_details.append(HandoffEvent.create(\n",
        "                            from_agent=source_agent,\n",
        "                            to_agent=target_agent,\n",
        "                            reason=reason,\n",
        "                            input_data=\"Processing query\",\n",
        "                            output_data=\"Handling specialized task\"\n",
        "                        ))\n",
        "\n",
        "                        current_agent = target_agent\n",
        "\n",
        "                # Process tool calls to identify web searches\n",
        "                elif item.type == \"tool_call_item\" and \"web_search\" in str(item.raw_item):\n",
        "                    try:\n",
        "                        args = None\n",
        "                        # Try different ways to get the arguments based on SDK version\n",
        "                        if hasattr(item.raw_item, 'function') and hasattr(item.raw_item.function, 'arguments'):\n",
        "                            args = item.raw_item.function.arguments\n",
        "                        elif hasattr(item.raw_item, 'arguments'):\n",
        "                            args = item.raw_item.arguments\n",
        "\n",
        "                        if args:\n",
        "                            import json\n",
        "                            try:\n",
        "                                arg_dict = json.loads(args)\n",
        "                                if \"query\" in arg_dict:\n",
        "                                    current_search_query = arg_dict[\"query\"]\n",
        "                            except:\n",
        "                                current_search_query = str(args)\n",
        "                        else:\n",
        "                            current_search_query = str(item.raw_item)\n",
        "                    except:\n",
        "                        current_search_query = \"Unknown search query\"\n",
        "\n",
        "                # Process tool outputs to capture search results\n",
        "                elif item.type == \"tool_call_output_item\" and current_search_query:\n",
        "                    try:\n",
        "                        # Get result text\n",
        "                        result_text = None\n",
        "                        if hasattr(item, 'output'):\n",
        "                            result_text = str(item.output)\n",
        "                        elif hasattr(item, 'raw_item'):\n",
        "                            result_text = str(item.raw_item)\n",
        "\n",
        "                        if result_text:\n",
        "                            # Try to match with a query from the search plan\n",
        "                            matching_query = None\n",
        "                            for sq in search_queries:\n",
        "                                if sq[\"query\"] in current_search_query or current_search_query in sq[\"query\"]:\n",
        "                                    matching_query = sq\n",
        "                                    break\n",
        "\n",
        "                            # If no match found, create a basic entry\n",
        "                            if not matching_query:\n",
        "                                matching_query = {\"query\": current_search_query, \"reason\": \"Search query\"}\n",
        "\n",
        "                            # Add to search details\n",
        "                            search_details.append({\n",
        "                                \"query\": matching_query[\"query\"],\n",
        "                                \"reason\": matching_query[\"reason\"],\n",
        "                                \"result\": result_text\n",
        "                            })\n",
        "                    except:\n",
        "                        # Fallback for error\n",
        "                        search_details.append({\n",
        "                            \"query\": current_search_query,\n",
        "                            \"reason\": \"Unknown reason\",\n",
        "                            \"result\": \"Error retrieving search result\"\n",
        "                        })\n",
        "\n",
        "            # Final step: process the report\n",
        "            status_text.text(\"Finalizing research report...\")\n",
        "            progress_bar.progress(0.9)\n",
        "\n",
        "            # Process the final output\n",
        "            try:\n",
        "                raw_output = runner_result.final_output\n",
        "\n",
        "                # Handle different output types\n",
        "                if isinstance(raw_output, ReportData):\n",
        "                    report = raw_output\n",
        "                elif isinstance(raw_output, dict):\n",
        "                    # Convert dictionary to ReportData\n",
        "                    report = ReportData(\n",
        "                        short_summary=raw_output.get('short_summary', f\"Summary of research on {query}\"),\n",
        "                        markdown_report=raw_output.get('markdown_report', f\"# Research on {query}\"),\n",
        "                        follow_up_questions=raw_output.get('follow_up_questions', [f\"What more can we learn about {query}?\"])\n",
        "                    )\n",
        "                else:\n",
        "                    # Create a fallback report\n",
        "                    report = ReportData(\n",
        "                        short_summary=f\"Research on '{query}' completed successfully.\",\n",
        "                        markdown_report=(\n",
        "                            f\"# Research on: {query}\\n\\n\"\n",
        "                            f\"The research workflow has completed. Here's what was found:\\n\\n\"\n",
        "                            + str(raw_output)\n",
        "                        ),\n",
        "                        follow_up_questions=[\n",
        "                            f\"What are the most important aspects of {query}?\",\n",
        "                            f\"What future developments are expected in {query}?\"\n",
        "                        ]\n",
        "                    )\n",
        "\n",
        "                # If we have no search details but have search queries, generate basic search details\n",
        "                if not search_details and search_queries:\n",
        "                    for query_item in search_queries:\n",
        "                        search_details.append({\n",
        "                            \"query\": query_item[\"query\"],\n",
        "                            \"reason\": query_item[\"reason\"],\n",
        "                            \"result\": \"Search results were used to generate the report, but detailed results weren't captured.\"\n",
        "                        })\n",
        "\n",
        "            except Exception as report_err:\n",
        "                error_container.error(f\"Error processing final output: {str(report_err)}\")\n",
        "                # Create a fallback report\n",
        "                report = ReportData(\n",
        "                    short_summary=f\"Research on '{query}' was conducted, but there was an issue formatting the final report.\",\n",
        "                    markdown_report=(\n",
        "                        f\"# Research on: {query}\\n\\n\"\n",
        "                        f\"## Research Process\\n\\n\"\n",
        "                        f\"The research process was completed, but there was an error formatting the final report: {str(report_err)}\\n\\n\"\n",
        "                    ),\n",
        "                    follow_up_questions=[\n",
        "                        f\"What are the key aspects of {query}?\",\n",
        "                        f\"What are expert opinions on {query}?\"\n",
        "                    ]\n",
        "                )\n",
        "\n",
        "        except Exception as e:\n",
        "            error_container.error(f\"Error in research workflow: {str(e)}. Creating a simplified report instead.\")\n",
        "            # Create a fallback report\n",
        "            report = ReportData(\n",
        "                short_summary=f\"Research on '{query}' encountered an issue but found some information.\",\n",
        "                markdown_report=(\n",
        "                    f\"# Research on: {query}\\n\\n\"\n",
        "                    f\"## Research Process\\n\\n\"\n",
        "                    f\"The research workflow encountered an issue: {str(e)}\\n\\n\"\n",
        "                ),\n",
        "                follow_up_questions=[\n",
        "                    f\"What are the key aspects of {query}?\",\n",
        "                    f\"What are expert opinions on {query}?\"\n",
        "                ]\n",
        "            )\n",
        "\n",
        "        # Update progress\n",
        "        progress_bar.progress(1.0)\n",
        "        status_text.text(\"Research complete!\")\n",
        "\n",
        "    # Clean up progress display\n",
        "    await asyncio.sleep(1)\n",
        "    progress_container.empty()\n",
        "    status_text.empty()\n",
        "\n",
        "    # Store handoff details and search details in session state\n",
        "    session_state.handoff_details = handoff_details\n",
        "    session_state.search_details = search_details\n",
        "\n",
        "    return report, handoff_details\n",
        "\n",
        "def render_handoff_chain(handoff_details):\n",
        "    \"\"\"Render the handoff chain as a visual flow\"\"\"\n",
        "    if not handoff_details:\n",
        "        return\n",
        "\n",
        "    st.subheader(\"Agent Handoff Chain\", divider=\"blue\")\n",
        "\n",
        "    for i, handoff in enumerate(handoff_details):\n",
        "        col1, col2, col3 = st.columns([2, 1, 2])\n",
        "\n",
        "        with col1:\n",
        "            st.markdown(f\"\"\"\n",
        "            <div style='background-color:var(--bg-card); padding:15px; border-radius:5px; border-left:5px solid var(--primary-color);'>\n",
        "                <strong>{handoff.from_agent}</strong><br>\n",
        "                <small>Input: {handoff.input}</small>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        with col2:\n",
        "            st.markdown(f\"\"\"\n",
        "            <div style='text-align:center; padding:10px;'>\n",
        "                <span style='font-size:20px; color:var(--primary-color);'>â†“</span><br>\n",
        "                <small style='color:var(--text-color);'>{handoff.reason}</small><br>\n",
        "                <small style='color:var(--text-color); opacity:0.7;'>{handoff.timestamp}</small>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        with col3:\n",
        "            st.markdown(f\"\"\"\n",
        "            <div style='background-color:var(--bg-card); padding:15px; border-radius:5px; border-left:5px solid var(--secondary-color);'>\n",
        "                <strong>{handoff.to_agent}</strong><br>\n",
        "                <small>Output: {handoff.output}</small>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        if i < len(handoff_details) - 1:\n",
        "            st.markdown(\"<div style='height:20px;'></div>\", unsafe_allow_html=True)\n",
        "\n",
        "def main():\n",
        "    # Set page configuration\n",
        "    st.set_page_config(\n",
        "        page_title=\"AI Research Assistant\",\n",
        "        page_icon=\"ğŸ”\",\n",
        "        layout=\"wide\",\n",
        "        initial_sidebar_state=\"expanded\"\n",
        "    )\n",
        "\n",
        "    # CSS styling (unchanged)\n",
        "    st.markdown(\"\"\"\n",
        "    <style>\n",
        "    /* Only style the custom components in the main content area */\n",
        "    .main-header {\n",
        "        font-size: 2.5rem;\n",
        "        color: #1E88E5;\n",
        "        margin-bottom: 1rem;\n",
        "    }\n",
        "\n",
        "    .sub-header {\n",
        "        font-size: 1.5rem;\n",
        "        color: #1E88E5;\n",
        "        margin: 1rem 0;\n",
        "    }\n",
        "\n",
        "    .info-box {\n",
        "        background-color: #F0F7FF;\n",
        "        padding: 1rem;\n",
        "        border-radius: 0.5rem;\n",
        "        border-left: 5px solid #1E88E5;\n",
        "        margin-bottom: 1rem;\n",
        "    }\n",
        "\n",
        "    .success-box {\n",
        "        background-color: #F0FFF0;\n",
        "        padding: 1rem;\n",
        "        border-radius: 0.5rem;\n",
        "        border-left: 5px solid #43A047;\n",
        "        margin-bottom: 1rem;\n",
        "    }\n",
        "\n",
        "    .warning-box {\n",
        "        background-color: #FFFAF0;\n",
        "        padding: 1rem;\n",
        "        border-radius: 0.5rem;\n",
        "        border-left: 5px solid #FFA000;\n",
        "        margin-bottom: 1rem;\n",
        "    }\n",
        "\n",
        "    .error-box {\n",
        "        background-color: #FFF0F0;\n",
        "        padding: 1rem;\n",
        "        border-radius: 0.5rem;\n",
        "        border-left: 5px solid #E53935;\n",
        "        margin-bottom: 1rem;\n",
        "    }\n",
        "\n",
        "    .stButton button {\n",
        "        background-color: #1E88E5;\n",
        "        color: white;\n",
        "        font-weight: bold;\n",
        "        padding: 0.5rem 2rem;\n",
        "        border-radius: 0.3rem;\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    # Initialize session state for storing persistent data\n",
        "    if 'api_key_valid' not in st.session_state:\n",
        "        st.session_state.api_key_valid = False\n",
        "    if 'handoff_details' not in st.session_state:\n",
        "        st.session_state.handoff_details = []\n",
        "    if 'search_details' not in st.session_state:\n",
        "        st.session_state.search_details = []\n",
        "    if 'report' not in st.session_state:\n",
        "        st.session_state.report = None\n",
        "\n",
        "    # App Header\n",
        "    col1, col2 = st.columns([3, 1])\n",
        "    with col1:\n",
        "        st.markdown(\"<h1 class='main-header'>ğŸ” AI Research Assistant</h1>\", unsafe_allow_html=True)\n",
        "        st.markdown(\"<p style='color:var(--text-color);'>Powered by OpenAI Agents SDK</p>\", unsafe_allow_html=True)\n",
        "    with col2:\n",
        "        if AGENTS_SDK_AVAILABLE:\n",
        "            st.markdown(\"<div class='success-box'>Agents SDK Loaded âœ“</div>\", unsafe_allow_html=True)\n",
        "        else:\n",
        "            st.markdown(\"<div class='warning-box'>Agents SDK Not Found - Using Simulation</div>\", unsafe_allow_html=True)\n",
        "\n",
        "    # Sidebar for configuration\n",
        "    with st.sidebar:\n",
        "        st.markdown(\"<h2 class='sub-header'>Research Configuration</h2>\", unsafe_allow_html=True)\n",
        "\n",
        "        # Display agent workflow\n",
        "        st.markdown(\"<h3 style='color:var(--text-color);'>Agent Workflow</h3>\", unsafe_allow_html=True)\n",
        "\n",
        "        with st.container():\n",
        "            # Show runner agent at the top\n",
        "            st.markdown(\"\"\"\n",
        "            <div class='agent-card'>\n",
        "                <h4 style='color:var(--text-color);'>ğŸ§  Runner Agent</h4>\n",
        "                <p style='color:var(--text-color);'>Orchestrates the entire research process by delegating to specialized agents in sequence.</p>\n",
        "                <small style='color:var(--text-color); opacity:0.8;'>Model: GPT-4o</small>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "            st.markdown(\"<div style='text-align:center; padding:5px;'><span style='color:var(--primary-color);'>â†“ First</span></div>\", unsafe_allow_html=True)\n",
        "\n",
        "            st.markdown(\"\"\"\n",
        "            <div class='agent-card'>\n",
        "                <h4 style='color:var(--text-color);'>ğŸ“‹ Planner Agent</h4>\n",
        "                <p style='color:var(--text-color);'>Analyzes your query and designs a research strategy with targeted search queries.</p>\n",
        "                <small style='color:var(--text-color); opacity:0.8;'>Model: GPT-4o</small>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "            st.markdown(\"<div style='text-align:center; padding:5px;'><span style='color:var(--primary-color);'>â†“ Second</span></div>\", unsafe_allow_html=True)\n",
        "\n",
        "            st.markdown(\"\"\"\n",
        "            <div class='agent-card'>\n",
        "                <h4 style='color:var(--text-color);'>ğŸ” Search Agent</h4>\n",
        "                <p style='color:var(--text-color);'>Performs web searches based on the planned queries and summarizes the findings.</p>\n",
        "                <small style='color:var(--text-color); opacity:0.8;'>Tools: Web Search</small>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "            st.markdown(\"<div style='text-align:center; padding:5px;'><span style='color:var(--primary-color);'>â†“ Third</span></div>\", unsafe_allow_html=True)\n",
        "\n",
        "            st.markdown(\"\"\"\n",
        "            <div class='agent-card'>\n",
        "                <h4 style='color:var(--text-color);'>âœï¸ Writer Agent</h4>\n",
        "                <p style='color:var(--text-color);'>Synthesizes search results into a cohesive, detailed research report.</p>\n",
        "                <small style='color:var(--text-color); opacity:0.8;'>Output: Formatted Report</small>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        # API Key Input\n",
        "        st.markdown(\"<h3>OpenAI API Key</h3>\", unsafe_allow_html=True)\n",
        "\n",
        "        # Check if API key is already set in environment\n",
        "        existing_key = os.environ.get('OPENAI_API_KEY', '')\n",
        "\n",
        "        api_key = st.text_input(\n",
        "            \"Enter your OpenAI API Key\",\n",
        "            value=existing_key,\n",
        "            type=\"password\",\n",
        "            help=\"Your API key will be used to authenticate with OpenAI services.\"\n",
        "        )\n",
        "\n",
        "        # Number of Searches Slider\n",
        "        num_searches = st.slider(\n",
        "            \"Number of Web Searches\",\n",
        "            min_value=1,\n",
        "            max_value=10,\n",
        "            value=5,\n",
        "            step=1,\n",
        "            help=\"Maximum number of web searches to perform for your query.\"\n",
        "        )\n",
        "\n",
        "        # Writer Model Selection\n",
        "        writer_model = st.radio(\n",
        "            \"Report Writer Model\",\n",
        "           [\"gpt-4o\", \"gpt-3.5-turbo\"],\n",
        "           index=0,\n",
        "           help=\"Select the model to use for writing the final research report.\"\n",
        "       )\n",
        "\n",
        "       # Validate and save API key\n",
        "    if api_key:\n",
        "        if st.button(\"Validate API Key\"):\n",
        "            is_valid, error_message = validate_openai_key(api_key)\n",
        "\n",
        "            if is_valid:\n",
        "                st.session_state.api_key_valid = True\n",
        "                st.markdown(\"<div class='success-box'>API Key validated successfully! âœ“</div>\", unsafe_allow_html=True)\n",
        "            else:\n",
        "                st.session_state.api_key_valid = False\n",
        "                st.markdown(f\"<div class='error-box'>Invalid API Key: {error_message}</div>\", unsafe_allow_html=True)\n",
        "\n",
        "    # Troubleshooting Information (unchanged)\n",
        "    with st.expander(\"Troubleshooting\"):\n",
        "        st.markdown(\"\"\"\n",
        "        ### ğŸ”‘ API Key Issues\n",
        "\n",
        "        1. **Invalid format** - OpenAI API keys start with `sk-`\n",
        "        2. **Authentication failed** - Check your OpenAI account status\n",
        "        3. **Billing issues** - Ensure your OpenAI account has valid billing\n",
        "        4. **Usage limits** - You may have hit your usage cap\n",
        "\n",
        "        ### ğŸ“¡ Connection Issues\n",
        "\n",
        "        1. **Network problems** - Check your internet connection\n",
        "        2. **Timeouts** - The request might be taking too long\n",
        "        3. **Service disruption** - OpenAI services might be experiencing issues\n",
        "\n",
        "        For more help, visit [OpenAI Support](https://help.openai.com/)\n",
        "        \"\"\")\n",
        "\n",
        "   # Main content area\n",
        "    if api_key and st.session_state.api_key_valid:\n",
        "        # Setup only the runner agent with the validated key\n",
        "        try:\n",
        "            runner_agent = setup_agents(\n",
        "                api_key,\n",
        "                num_searches,\n",
        "                writer_model\n",
        "            )\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error setting up agents: {e}\")\n",
        "\n",
        "        # Query input\n",
        "        st.markdown(\"<h2 class='sub-header'>Research Query</h2>\", unsafe_allow_html=True)\n",
        "        query = st.text_input(\n",
        "            \"What would you like to research?\",\n",
        "            placeholder=\"E.g., 'The impact of artificial intelligence on healthcare'\"\n",
        "        )\n",
        "\n",
        "        # Research button\n",
        "        if st.button(\"Start Research\"):\n",
        "            if query:\n",
        "                try:\n",
        "                    # Reset previous results\n",
        "                    st.session_state.report = None\n",
        "                    st.session_state.handoff_details = []\n",
        "                    st.session_state.search_details = []\n",
        "\n",
        "                    # Use asyncio to run the async function with just the runner agent\n",
        "                    report, handoff_details = asyncio.run(perform_research(\n",
        "                        query,\n",
        "                        runner_agent,\n",
        "                        st.session_state\n",
        "                    ))\n",
        "\n",
        "                    # Store the report in session state\n",
        "                    st.session_state.report = report\n",
        "\n",
        "                    # Force a rerun to show the new content\n",
        "                    st.rerun()\n",
        "\n",
        "                except Exception as e:\n",
        "                    st.error(f\"An error occurred during research: {e}\")\n",
        "            else:\n",
        "                st.warning(\"Please enter a research query.\")\n",
        "\n",
        "        # Display results if available (same as original)\n",
        "        if st.session_state.report:\n",
        "            report = st.session_state.report\n",
        "\n",
        "            # Research Results\n",
        "            st.markdown(\"<h2 class='sub-header'>Research Results</h2>\", unsafe_allow_html=True)\n",
        "\n",
        "            # Display summary in a nice box\n",
        "            st.markdown(f\"\"\"\n",
        "            <div class='info-box'>\n",
        "                <h3>Summary</h3>\n",
        "                <p>{report.short_summary}</p>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "            # Render the handoff chain\n",
        "            render_handoff_chain(st.session_state.handoff_details)\n",
        "\n",
        "            # Tabs for detailed content\n",
        "            tab1, tab2, tab3 = st.tabs([\"ğŸ“ Full Report\", \"ğŸ” Search Details\", \"â“ Follow-up Questions\"])\n",
        "\n",
        "            with tab1:\n",
        "                st.markdown(report.markdown_report)\n",
        "\n",
        "            with tab2:\n",
        "                if st.session_state.search_details:\n",
        "                    for i, detail in enumerate(st.session_state.search_details):\n",
        "                        with st.expander(f\"Search {i+1}: {detail['query']}\"):\n",
        "                            st.markdown(f\"**Reason:** {detail['reason']}\")\n",
        "                            st.markdown(f\"**Result:** {detail['result']}\")\n",
        "                else:\n",
        "                    st.info(\"No search details available.\")\n",
        "\n",
        "            with tab3:\n",
        "                if report.follow_up_questions:\n",
        "                    for question in report.follow_up_questions:\n",
        "                        st.markdown(f\"- {question}\")\n",
        "                else:\n",
        "                    st.info(\"No follow-up questions generated.\")\n",
        "    else:\n",
        "        # When no API key is present or valid (same as original)\n",
        "        st.markdown(\"\"\"\n",
        "        <div class='info-box'>\n",
        "            <h3>Getting Started</h3>\n",
        "            <p>To use the AI Research Assistant, please follow these steps:</p>\n",
        "            <ol>\n",
        "                <li>Enter your OpenAI API Key in the sidebar</li>\n",
        "                <li>Click \"Validate API Key\" to verify your credentials</li>\n",
        "                <li>Enter your research query and start researching!</li>\n",
        "            </ol>\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        # Sample queries to help users get started\n",
        "        st.markdown(\"<h3>Sample Research Topics</h3>\", unsafe_allow_html=True)\n",
        "        sample_queries = [\n",
        "            \"The environmental impact of electric vehicles\",\n",
        "            \"Advancements in quantum computing in the last 5 years\",\n",
        "            \"The role of gut microbiome in human health\",\n",
        "            \"The economic effects of remote work\"\n",
        "        ]\n",
        "\n",
        "        for query in sample_queries:\n",
        "            st.markdown(f\"- {query}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "oPYexgfFr_Hf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}